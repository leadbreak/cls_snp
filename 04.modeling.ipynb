{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a692d368-9d9d-4336-b2a3-5b5446b2ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6503c9-2742-492a-bb2d-f664e77c1b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0da33db-2d37-45e5-a90f-fe2271509fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 41\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(seed=random_seed) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cdca6a-a6e7-4426-9ddf-575ed6f4ee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262, 48), (175, 47))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/df_train.csv\")\n",
    "test = pd.read_csv(\"./data/df_test.csv\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17f8ebe-5b08-4c99-826a-53b1d2e898e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encodings_0</th>\n",
       "      <th>encodings_1</th>\n",
       "      <th>encodings_2</th>\n",
       "      <th>encodings_3</th>\n",
       "      <th>encodings_4</th>\n",
       "      <th>encodings_5</th>\n",
       "      <th>encodings_6</th>\n",
       "      <th>encodings_7</th>\n",
       "      <th>encodings_8</th>\n",
       "      <th>encodings_9</th>\n",
       "      <th>...</th>\n",
       "      <th>encodings_18</th>\n",
       "      <th>encodings_19</th>\n",
       "      <th>encodings_20</th>\n",
       "      <th>encodings_21</th>\n",
       "      <th>encodings_22</th>\n",
       "      <th>encodings_23</th>\n",
       "      <th>encodings_24</th>\n",
       "      <th>encodings_25</th>\n",
       "      <th>encodings_26</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.235218</td>\n",
       "      <td>4.172423</td>\n",
       "      <td>-3.853053</td>\n",
       "      <td>-1.533935</td>\n",
       "      <td>2.644730</td>\n",
       "      <td>3.716698</td>\n",
       "      <td>-0.299315</td>\n",
       "      <td>-2.650086</td>\n",
       "      <td>0.783824</td>\n",
       "      <td>-0.406989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082240</td>\n",
       "      <td>-1.530903</td>\n",
       "      <td>-1.215420</td>\n",
       "      <td>-3.295104</td>\n",
       "      <td>0.245303</td>\n",
       "      <td>-0.055747</td>\n",
       "      <td>-1.089265</td>\n",
       "      <td>-1.649269</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.008067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.164804</td>\n",
       "      <td>6.937546</td>\n",
       "      <td>-0.615424</td>\n",
       "      <td>0.798070</td>\n",
       "      <td>-2.365728</td>\n",
       "      <td>-1.246152</td>\n",
       "      <td>0.571691</td>\n",
       "      <td>0.340047</td>\n",
       "      <td>-0.374678</td>\n",
       "      <td>2.935323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065099</td>\n",
       "      <td>-0.072708</td>\n",
       "      <td>-2.343938</td>\n",
       "      <td>0.866952</td>\n",
       "      <td>-0.382145</td>\n",
       "      <td>-2.748686</td>\n",
       "      <td>0.459386</td>\n",
       "      <td>0.983944</td>\n",
       "      <td>3.129371</td>\n",
       "      <td>0.009998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.450719</td>\n",
       "      <td>6.478036</td>\n",
       "      <td>-4.994792</td>\n",
       "      <td>-1.083578</td>\n",
       "      <td>-1.050726</td>\n",
       "      <td>-0.028033</td>\n",
       "      <td>-1.456105</td>\n",
       "      <td>-1.262530</td>\n",
       "      <td>-1.064003</td>\n",
       "      <td>2.599940</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.403145</td>\n",
       "      <td>-1.100375</td>\n",
       "      <td>-1.358432</td>\n",
       "      <td>-1.019482</td>\n",
       "      <td>3.274151</td>\n",
       "      <td>3.080497</td>\n",
       "      <td>2.445034</td>\n",
       "      <td>1.530065</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.040302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.078038</td>\n",
       "      <td>10.407413</td>\n",
       "      <td>-5.961476</td>\n",
       "      <td>-0.954541</td>\n",
       "      <td>-2.045539</td>\n",
       "      <td>0.913142</td>\n",
       "      <td>3.408923</td>\n",
       "      <td>-2.241139</td>\n",
       "      <td>1.254574</td>\n",
       "      <td>1.749235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.824590</td>\n",
       "      <td>1.962076</td>\n",
       "      <td>-0.140499</td>\n",
       "      <td>-1.557903</td>\n",
       "      <td>3.796697</td>\n",
       "      <td>3.281870</td>\n",
       "      <td>3.378306</td>\n",
       "      <td>1.271765</td>\n",
       "      <td>-2.542374</td>\n",
       "      <td>0.008206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.685338</td>\n",
       "      <td>6.908415</td>\n",
       "      <td>-5.594373</td>\n",
       "      <td>1.017355</td>\n",
       "      <td>-2.475780</td>\n",
       "      <td>1.170744</td>\n",
       "      <td>-1.731986</td>\n",
       "      <td>2.448224</td>\n",
       "      <td>-0.242145</td>\n",
       "      <td>-0.236407</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.392161</td>\n",
       "      <td>-1.289728</td>\n",
       "      <td>-2.297753</td>\n",
       "      <td>2.706107</td>\n",
       "      <td>0.366826</td>\n",
       "      <td>1.816569</td>\n",
       "      <td>1.143190</td>\n",
       "      <td>4.631185</td>\n",
       "      <td>-0.518664</td>\n",
       "      <td>0.036693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>-6.713977</td>\n",
       "      <td>4.797306</td>\n",
       "      <td>-6.859674</td>\n",
       "      <td>-0.427648</td>\n",
       "      <td>-1.465041</td>\n",
       "      <td>0.584409</td>\n",
       "      <td>-1.570887</td>\n",
       "      <td>0.707021</td>\n",
       "      <td>0.202451</td>\n",
       "      <td>-1.051615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948983</td>\n",
       "      <td>-1.454844</td>\n",
       "      <td>3.104134</td>\n",
       "      <td>-1.628868</td>\n",
       "      <td>1.587918</td>\n",
       "      <td>-1.379632</td>\n",
       "      <td>-0.742597</td>\n",
       "      <td>3.711644</td>\n",
       "      <td>0.533880</td>\n",
       "      <td>0.028781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>-3.505607</td>\n",
       "      <td>6.129325</td>\n",
       "      <td>-2.930341</td>\n",
       "      <td>-0.359151</td>\n",
       "      <td>1.557368</td>\n",
       "      <td>0.367298</td>\n",
       "      <td>1.640623</td>\n",
       "      <td>2.402381</td>\n",
       "      <td>-2.167556</td>\n",
       "      <td>0.352788</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.493095</td>\n",
       "      <td>0.081309</td>\n",
       "      <td>-3.520641</td>\n",
       "      <td>-0.392295</td>\n",
       "      <td>2.330890</td>\n",
       "      <td>1.521016</td>\n",
       "      <td>0.899050</td>\n",
       "      <td>4.925332</td>\n",
       "      <td>0.413980</td>\n",
       "      <td>0.015013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>-1.853786</td>\n",
       "      <td>3.641998</td>\n",
       "      <td>0.470991</td>\n",
       "      <td>-1.175941</td>\n",
       "      <td>3.441618</td>\n",
       "      <td>1.693989</td>\n",
       "      <td>2.112146</td>\n",
       "      <td>1.143281</td>\n",
       "      <td>-0.975709</td>\n",
       "      <td>-2.530986</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.952293</td>\n",
       "      <td>1.092013</td>\n",
       "      <td>-1.333903</td>\n",
       "      <td>1.238227</td>\n",
       "      <td>1.457066</td>\n",
       "      <td>0.588651</td>\n",
       "      <td>-1.395687</td>\n",
       "      <td>1.455708</td>\n",
       "      <td>-0.818322</td>\n",
       "      <td>0.050879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-3.249345</td>\n",
       "      <td>8.500051</td>\n",
       "      <td>-4.339647</td>\n",
       "      <td>-2.227715</td>\n",
       "      <td>-1.511902</td>\n",
       "      <td>0.807777</td>\n",
       "      <td>-0.969590</td>\n",
       "      <td>-1.554576</td>\n",
       "      <td>0.884828</td>\n",
       "      <td>-0.540825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068143</td>\n",
       "      <td>-3.087835</td>\n",
       "      <td>0.714141</td>\n",
       "      <td>0.378201</td>\n",
       "      <td>2.740462</td>\n",
       "      <td>-0.029870</td>\n",
       "      <td>-0.452864</td>\n",
       "      <td>-0.030688</td>\n",
       "      <td>2.088013</td>\n",
       "      <td>0.007352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>-7.493045</td>\n",
       "      <td>6.019004</td>\n",
       "      <td>-9.174811</td>\n",
       "      <td>0.258502</td>\n",
       "      <td>-2.122859</td>\n",
       "      <td>-1.390015</td>\n",
       "      <td>-0.537476</td>\n",
       "      <td>-2.462971</td>\n",
       "      <td>1.481490</td>\n",
       "      <td>-1.179641</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000996</td>\n",
       "      <td>-2.302604</td>\n",
       "      <td>1.013478</td>\n",
       "      <td>-2.525301</td>\n",
       "      <td>0.816626</td>\n",
       "      <td>1.031304</td>\n",
       "      <td>1.218161</td>\n",
       "      <td>2.438878</td>\n",
       "      <td>-1.005346</td>\n",
       "      <td>0.041755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     encodings_0  encodings_1  encodings_2  encodings_3  encodings_4  \\\n",
       "0      -3.235218     4.172423    -3.853053    -1.533935     2.644730   \n",
       "1      -3.164804     6.937546    -0.615424     0.798070    -2.365728   \n",
       "2      -3.450719     6.478036    -4.994792    -1.083578    -1.050726   \n",
       "3      -5.078038    10.407413    -5.961476    -0.954541    -2.045539   \n",
       "4      -4.685338     6.908415    -5.594373     1.017355    -2.475780   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "432    -6.713977     4.797306    -6.859674    -0.427648    -1.465041   \n",
       "433    -3.505607     6.129325    -2.930341    -0.359151     1.557368   \n",
       "434    -1.853786     3.641998     0.470991    -1.175941     3.441618   \n",
       "435    -3.249345     8.500051    -4.339647    -2.227715    -1.511902   \n",
       "436    -7.493045     6.019004    -9.174811     0.258502    -2.122859   \n",
       "\n",
       "     encodings_5  encodings_6  encodings_7  encodings_8  encodings_9  ...  \\\n",
       "0       3.716698    -0.299315    -2.650086     0.783824    -0.406989  ...   \n",
       "1      -1.246152     0.571691     0.340047    -0.374678     2.935323  ...   \n",
       "2      -0.028033    -1.456105    -1.262530    -1.064003     2.599940  ...   \n",
       "3       0.913142     3.408923    -2.241139     1.254574     1.749235  ...   \n",
       "4       1.170744    -1.731986     2.448224    -0.242145    -0.236407  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "432     0.584409    -1.570887     0.707021     0.202451    -1.051615  ...   \n",
       "433     0.367298     1.640623     2.402381    -2.167556     0.352788  ...   \n",
       "434     1.693989     2.112146     1.143281    -0.975709    -2.530986  ...   \n",
       "435     0.807777    -0.969590    -1.554576     0.884828    -0.540825  ...   \n",
       "436    -1.390015    -0.537476    -2.462971     1.481490    -1.179641  ...   \n",
       "\n",
       "     encodings_18  encodings_19  encodings_20  encodings_21  encodings_22  \\\n",
       "0        1.082240     -1.530903     -1.215420     -3.295104      0.245303   \n",
       "1       -0.065099     -0.072708     -2.343938      0.866952     -0.382145   \n",
       "2       -3.403145     -1.100375     -1.358432     -1.019482      3.274151   \n",
       "3       -0.824590      1.962076     -0.140499     -1.557903      3.796697   \n",
       "4       -2.392161     -1.289728     -2.297753      2.706107      0.366826   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "432      0.948983     -1.454844      3.104134     -1.628868      1.587918   \n",
       "433     -3.493095      0.081309     -3.520641     -0.392295      2.330890   \n",
       "434     -1.952293      1.092013     -1.333903      1.238227      1.457066   \n",
       "435     -0.068143     -3.087835      0.714141      0.378201      2.740462   \n",
       "436      2.000996     -2.302604      1.013478     -2.525301      0.816626   \n",
       "\n",
       "     encodings_23  encodings_24  encodings_25  encodings_26    errors  \n",
       "0       -0.055747     -1.089265     -1.649269      0.001300  0.008067  \n",
       "1       -2.748686      0.459386      0.983944      3.129371  0.009998  \n",
       "2        3.080497      2.445034      1.530065      0.137097  0.040302  \n",
       "3        3.281870      3.378306      1.271765     -2.542374  0.008206  \n",
       "4        1.816569      1.143190      4.631185     -0.518664  0.036693  \n",
       "..            ...           ...           ...           ...       ...  \n",
       "432     -1.379632     -0.742597      3.711644      0.533880  0.028781  \n",
       "433      1.521016      0.899050      4.925332      0.413980  0.015013  \n",
       "434      0.588651     -1.395687      1.455708     -0.818322  0.050879  \n",
       "435     -0.029870     -0.452864     -0.030688      2.088013  0.007352  \n",
       "436      1.031304      1.218161      2.438878     -1.005346  0.041755  \n",
       "\n",
       "[437 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae = pd.read_csv(\"./data/ae_values.csv\")\n",
    "ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd83b179-3e56-4125-b4aa-0a21edfe8f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262, 76), (350, 75))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = pd.concat([train, ae[:len(train)]], axis=1)\n",
    "test2 = pd.concat([test, ae[len(train):]], axis=1)\n",
    "\n",
    "train2.shape, test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd714cf0-a26e-4e62-a5f7-7b39beeb3342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 0, 0, 2, 1, 1, 0, 1,\n",
       "        2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0,\n",
       "        2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2,\n",
       "        0, 1, 1, 1, 2, 1, 2, 0, 1, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1,\n",
       "        2, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2,\n",
       "        1, 1, 2, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 1,\n",
       "        1, 1, 2, 2, 0, 1, 0, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0,\n",
       "        0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 1, 2, 1, 2, 2, 1,\n",
       "        1, 1, 0, 1, 1, 2, 1, 2, 0, 1, 0, 1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2,\n",
       "        0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 2, 0,\n",
       "        0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.LongTensor(train2['class'].values)\n",
    "X = train2.drop(['id', 'class'], axis=1).to_numpy()\n",
    "X_test = test2.drop(['id'], axis=1).to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb7f4a73-c57b-4fb2-9b10-061fffccf5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "xgb_params = {\n",
    "    'booster': 'gbtree',\n",
    "    'grow_policy': 'depthwise',\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.4,\n",
    "    'n_estimators': 30,\n",
    "    'reg_lambda': 100,\n",
    "    'subsample': 0.9,\n",
    "    'num_parallel_tree': 1,\n",
    "    # 'rate_drop': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27cbaa5d-f584-4ca9-9a0c-f49cfd306d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "    return 'f1', f1_score(y_true, y_hat, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1fa932df-058a-4c22-a630-90588b8cdd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.00455\tvalidation_0-f1:0.93540\n",
      "[1]\tvalidation_0-mlogloss:0.92590\tvalidation_0-f1:0.94282\n",
      "[2]\tvalidation_0-mlogloss:0.85614\tvalidation_0-f1:0.94282\n",
      "[3]\tvalidation_0-mlogloss:0.79948\tvalidation_0-f1:0.93683\n",
      "[4]\tvalidation_0-mlogloss:0.74157\tvalidation_0-f1:0.92959\n",
      "[5]\tvalidation_0-mlogloss:0.69207\tvalidation_0-f1:0.95017\n",
      "[6]\tvalidation_0-mlogloss:0.64906\tvalidation_0-f1:0.94282\n",
      "[7]\tvalidation_0-mlogloss:0.60993\tvalidation_0-f1:0.94282\n",
      "[8]\tvalidation_0-mlogloss:0.57561\tvalidation_0-f1:0.95712\n",
      "[9]\tvalidation_0-mlogloss:0.54718\tvalidation_0-f1:0.95017\n",
      "[10]\tvalidation_0-mlogloss:0.51964\tvalidation_0-f1:0.95017\n",
      "[11]\tvalidation_0-mlogloss:0.49552\tvalidation_0-f1:0.95017\n",
      "[12]\tvalidation_0-mlogloss:0.47675\tvalidation_0-f1:0.95712\n",
      "[13]\tvalidation_0-mlogloss:0.45720\tvalidation_0-f1:0.96411\n",
      "[14]\tvalidation_0-mlogloss:0.44009\tvalidation_0-f1:0.96411\n",
      "[15]\tvalidation_0-mlogloss:0.42392\tvalidation_0-f1:0.97141\n",
      "[16]\tvalidation_0-mlogloss:0.40854\tvalidation_0-f1:0.97141\n",
      "[17]\tvalidation_0-mlogloss:0.39622\tvalidation_0-f1:0.97141\n",
      "[18]\tvalidation_0-mlogloss:0.38498\tvalidation_0-f1:0.97141\n",
      "[19]\tvalidation_0-mlogloss:0.37347\tvalidation_0-f1:0.97141\n",
      "[20]\tvalidation_0-mlogloss:0.36325\tvalidation_0-f1:0.97141\n",
      "[21]\tvalidation_0-mlogloss:0.35420\tvalidation_0-f1:0.97141\n",
      "[22]\tvalidation_0-mlogloss:0.34594\tvalidation_0-f1:0.97141\n",
      "[23]\tvalidation_0-mlogloss:0.33923\tvalidation_0-f1:0.97141\n",
      "[24]\tvalidation_0-mlogloss:0.33062\tvalidation_0-f1:0.97141\n",
      "[25]\tvalidation_0-mlogloss:0.32319\tvalidation_0-f1:0.97141\n",
      "[26]\tvalidation_0-mlogloss:0.31478\tvalidation_0-f1:0.97141\n",
      "[27]\tvalidation_0-mlogloss:0.30868\tvalidation_0-f1:0.97141\n",
      "[28]\tvalidation_0-mlogloss:0.30213\tvalidation_0-f1:0.97865\n",
      "[29]\tvalidation_0-mlogloss:0.29624\tvalidation_0-f1:0.97865\n",
      "[0]\tvalidation_0-mlogloss:1.00625\tvalidation_0-f1:0.88826\n",
      "[1]\tvalidation_0-mlogloss:0.92834\tvalidation_0-f1:0.88148\n",
      "[2]\tvalidation_0-mlogloss:0.86187\tvalidation_0-f1:0.86338\n",
      "[3]\tvalidation_0-mlogloss:0.80132\tvalidation_0-f1:0.87180\n",
      "[4]\tvalidation_0-mlogloss:0.74714\tvalidation_0-f1:0.87180\n",
      "[5]\tvalidation_0-mlogloss:0.69766\tvalidation_0-f1:0.88826\n",
      "[6]\tvalidation_0-mlogloss:0.65513\tvalidation_0-f1:0.88148\n",
      "[7]\tvalidation_0-mlogloss:0.61748\tvalidation_0-f1:0.90422\n",
      "[8]\tvalidation_0-mlogloss:0.58424\tvalidation_0-f1:0.91896\n",
      "[9]\tvalidation_0-mlogloss:0.55529\tvalidation_0-f1:0.91205\n",
      "[10]\tvalidation_0-mlogloss:0.53026\tvalidation_0-f1:0.91205\n",
      "[11]\tvalidation_0-mlogloss:0.50702\tvalidation_0-f1:0.92741\n",
      "[12]\tvalidation_0-mlogloss:0.48622\tvalidation_0-f1:0.92741\n",
      "[13]\tvalidation_0-mlogloss:0.46778\tvalidation_0-f1:0.94941\n",
      "[14]\tvalidation_0-mlogloss:0.45025\tvalidation_0-f1:0.95681\n",
      "[15]\tvalidation_0-mlogloss:0.43483\tvalidation_0-f1:0.95681\n",
      "[16]\tvalidation_0-mlogloss:0.42102\tvalidation_0-f1:0.94981\n",
      "[17]\tvalidation_0-mlogloss:0.40705\tvalidation_0-f1:0.95681\n",
      "[18]\tvalidation_0-mlogloss:0.39495\tvalidation_0-f1:0.95681\n",
      "[19]\tvalidation_0-mlogloss:0.38440\tvalidation_0-f1:0.95681\n",
      "[20]\tvalidation_0-mlogloss:0.37422\tvalidation_0-f1:0.95681\n",
      "[21]\tvalidation_0-mlogloss:0.36505\tvalidation_0-f1:0.94981\n",
      "[22]\tvalidation_0-mlogloss:0.35581\tvalidation_0-f1:0.94981\n",
      "[23]\tvalidation_0-mlogloss:0.34871\tvalidation_0-f1:0.94981\n",
      "[24]\tvalidation_0-mlogloss:0.34155\tvalidation_0-f1:0.94981\n",
      "[25]\tvalidation_0-mlogloss:0.33369\tvalidation_0-f1:0.94981\n",
      "[26]\tvalidation_0-mlogloss:0.32635\tvalidation_0-f1:0.96386\n",
      "[27]\tvalidation_0-mlogloss:0.31969\tvalidation_0-f1:0.96386\n",
      "[28]\tvalidation_0-mlogloss:0.31463\tvalidation_0-f1:0.96386\n",
      "[29]\tvalidation_0-mlogloss:0.30874\tvalidation_0-f1:0.96386\n",
      "0.9713117800074321\n"
     ]
    }
   ],
   "source": [
    "random_seed = 5833\n",
    "\n",
    "y = train['class'].values\n",
    "X = train.drop(['id', 'class'], axis=1).to_numpy()\n",
    "X_test = test.drop(['id'], axis=1).to_numpy()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=random_seed)\n",
    "\n",
    "oof_val_preds = np.zeros((X.shape[0], 3))\n",
    "oof_test_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "# OOF\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "    # print('#'*30, f'Fold [{fold+1}/{skf.n_splits}]', '#'*30)\n",
    "\n",
    "    # train, valid data 설정\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "    \n",
    "    smote = SMOTE(random_state=random_seed)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # 불균형 데이터 가중치 조정 값 => 음성(0) 타깃값 개수 / 양성(1) 타깃값 개수\n",
    "    _, counts = np.unique(np.array(y_train), return_counts=True)\n",
    "    scale_weight = counts[0] / counts[1]\n",
    "\n",
    "    # XGBoost 모델 훈련\n",
    "    xgb_model = XGBClassifier(\n",
    "        **xgb_params,\n",
    "        tree_method='gpu_hist',\n",
    "        predictor='gpu_predictor',\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=calc_f1_score, verbose=True)\n",
    "\n",
    "    oof_test_preds += xgb_model.predict_proba(X_test) / skf.n_splits\n",
    "    oof_val_preds[valid_idx] += xgb_model.predict_proba(X_valid)\n",
    "    \n",
    "    # if fold == 1 :\n",
    "    #     pred = xgb_model.predict(X_test)\n",
    "    #     break\n",
    "    \n",
    "    #model save\n",
    "    # xgb_model.save_model(f'./models/new_xgb_{skf.n_splits}_{fold}.json')\n",
    "    del [[X_train, y_train, X_valid, y_valid, xgb_model]]\n",
    "    gc.collect()\n",
    "\n",
    "#     model score check\n",
    "preds = np.argmax(oof_val_preds, axis=1)\n",
    "print(f1_score(y, preds, average=\"macro\"))\n",
    "\n",
    "# # save OOF test preds\n",
    "# np.save(f'./results/new_{skf.n_splits}_oof_test_preds.npy', oof_test_preds[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b0f3d32-815f-42e4-836a-eb4c4762d1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TEST_170</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TEST_171</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>TEST_172</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>TEST_173</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>TEST_174</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class\n",
       "0    TEST_000     A\n",
       "1    TEST_001     B\n",
       "2    TEST_002     C\n",
       "3    TEST_003     B\n",
       "4    TEST_004     A\n",
       "..        ...   ...\n",
       "170  TEST_170     B\n",
       "171  TEST_171     C\n",
       "172  TEST_172     C\n",
       "173  TEST_173     B\n",
       "174  TEST_174     B\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_pred = np.argmax(oof_test_preds, axis=1)\n",
    "submit_file = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "submit_file['class'] = submit_pred\n",
    "submit_file['class'] = submit_file['class'].map(lambda x : \"A\" if x==0 else ( \"B\" if x==1 else \"C\"))\n",
    "submit_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ae48a6e4-e579-4741-8ffd-f06b88bff574",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7105d3a6-674e-4099-88ad-f36f23a7d2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 2, 0.912768361581921\n",
      "Fold : 3, 0.9238551500634071\n",
      "Fold : 4, 0.9423794596208389\n",
      "Fold : 5, 0.9418455743879472\n",
      "Fold : 6, 0.9460969138388493\n",
      "Fold : 7, 0.9567845947156292\n",
      "Fold : 8, 0.9386425051661104\n",
      "Fold : 9, 0.9421202579097315\n",
      "Fold : 10, 0.9314239763621233\n",
      "Fold : 11, 0.9530795627740843\n",
      "Fold : 12, 0.9314239763621233\n",
      "Fold : 13, 0.9495820271682341\n",
      "Fold : 14, 0.9495820271682341\n",
      "Fold : 15, 0.9532839919936694\n",
      "Fold : 16, 0.9567845947156292\n",
      "Fold : 17, 0.9460969138388493\n",
      "Fold : 18, 0.9497956150130062\n",
      "Fold : 19, 0.9460969138388493\n",
      "Fold : 20, 0.9567845947156292\n",
      "Fold : 21, 0.9532839919936694\n",
      "Fold : 22, 0.9532839919936694\n",
      "Fold : 23, 0.9497956150130062\n",
      "Fold : 24, 0.9639871622630243\n",
      "Fold : 25, 0.9567845947156292\n",
      "Fold : 26, 0.9497956150130062\n",
      "Fold : 27, 0.946318805106667\n",
      "Fold : 28, 0.9604710701484894\n",
      "Fold : 29, 0.9497956150130062\n",
      "Fold : 30, 0.9534762977591115\n",
      "Fold : 31, 0.9569676700111481\n",
      "Fold : 32, 0.9497956150130062\n",
      "Fold : 33, 0.9497956150130062\n",
      "Fold : 34, 0.9534762977591115\n",
      "Fold : 35, 0.9532839919936694\n",
      "Fold : 36, 0.9569676700111481\n",
      "Fold : 37, 0.9534762977591115\n",
      "Fold : 38, 0.9460969138388493\n",
      "Fold : 39, 0.9569676700111481\n",
      "Fold : 40, 0.9569676700111481\n",
      "Fold : 41, 0.9532839919936694\n",
      "Fold : 42, 0.9532839919936694\n",
      "Fold : 43, 0.9532839919936694\n",
      "Fold : 44, 0.9497956150130062\n",
      "Fold : 45, 0.9534762977591115\n",
      "Fold : 46, 0.9497956150130062\n",
      "Fold : 47, 0.9497956150130062\n",
      "Fold : 48, 0.9460969138388493\n",
      "Fold : 49, 0.946318805106667\n",
      "Fold : 50, 0.9532839919936694\n",
      "Fold : 51, 0.9497956150130062\n",
      "Fold : 52, 0.9497956150130062\n",
      "Fold : 53, 0.9532839919936694\n",
      "Fold : 54, 0.9460969138388493\n",
      "Fold : 55, 0.9460969138388493\n",
      "Fold : 56, 0.9460969138388493\n",
      "Fold : 57, 0.9460969138388493\n",
      "Fold : 58, 0.9426235600148644\n",
      "Fold : 59, 0.9499962987637871\n",
      "Fold : 60, 0.9497956150130062\n",
      "Fold : 61, 0.9534762977591115\n",
      "Fold : 62, 0.9569676700111481\n",
      "Fold : 63, 0.9534762977591115\n",
      "Fold : 64, 0.9534762977591115\n",
      "Fold : 65, 0.9532839919936694\n",
      "Fold : 66, 0.9530795627740843\n",
      "Fold : 67, 0.9493552256710153\n",
      "Fold : 68, 0.9530795627740843\n",
      "Fold : 69, 0.9493552256710153\n",
      "Fold : 70, 0.9530795627740843\n",
      "Fold : 71, 0.9530795627740843\n",
      "Fold : 72, 0.9530795627740843\n",
      "Fold : 73, 0.9530795627740843\n",
      "Fold : 74, 0.9530795627740843\n",
      "Fold : 75, 0.9530795627740843\n",
      "Fold : 76, 0.9530795627740843\n",
      "Fold : 77, 0.9530795627740843\n",
      "Fold : 78, 0.9530795627740843\n",
      "Fold : 79, 0.9530795627740843\n",
      "Fold : 80, 0.9530795627740843\n",
      "Fold : 81, 0.9495820271682341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 100) :\n",
    "    k = i+1\n",
    "    random_seed = 2005\n",
    "\n",
    "    y = train['class'].values\n",
    "    X = train.drop(['id', 'class'], axis=1).to_numpy()\n",
    "    X_test = test.drop(['id'], axis=1).to_numpy()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    oof_val_preds = np.zeros((X.shape[0], 3))\n",
    "    oof_test_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    # OOF\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # print('#'*30, f'Fold [{fold+1}/{skf.n_splits}]', '#'*30)\n",
    "\n",
    "        # train, valid data 설정\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "        smote = SMOTE(random_state=random_seed)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # 불균형 데이터 가중치 조정 값 => 음성(0) 타깃값 개수 / 양성(1) 타깃값 개수\n",
    "        _, counts = np.unique(np.array(y_train), return_counts=True)\n",
    "        scale_weight = counts[0] / counts[1]\n",
    "\n",
    "        # XGBoost 모델 훈련\n",
    "        xgb_model = XGBClassifier(\n",
    "            **xgb_params,\n",
    "            tree_method='gpu_hist',\n",
    "            predictor='gpu_predictor',\n",
    "            random_state=random_seed,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], eval_metric=calc_f1_score, verbose=False)\n",
    "\n",
    "        oof_test_preds += xgb_model.predict_proba(X_test) / skf.n_splits\n",
    "        oof_val_preds[valid_idx] += xgb_model.predict_proba(X_valid)\n",
    "\n",
    "        # if fold == 1 :\n",
    "        #     pred = xgb_model.predict(X_test)\n",
    "        #     break\n",
    "\n",
    "        #model save\n",
    "        # xgb_model.save_model(f'./models/new_xgb_{skf.n_splits}_{fold}.json')\n",
    "        del [[X_train, y_train, X_valid, y_valid, xgb_model]]\n",
    "        gc.collect()\n",
    "\n",
    "    #     model score check\n",
    "    preds = np.argmax(oof_val_preds, axis=1)\n",
    "    print(f'Fold : {k}, {f1_score(y, preds, average=\"macro\")}')\n",
    "\n",
    "    # # save OOF test preds\n",
    "    # np.save(f'./results/new_{skf.n_splits}_oof_test_preds.npy', oof_test_preds[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37534934-4b44-432e-81ee-9f8d9c44b3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8070b16-e4c8-45c8-91ba-c70b478fd6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed : 6147, 0.9499962987637871\n",
      "seed : 6141, 0.9426235600148644\n",
      "seed : 3315, 0.9532839919936694\n",
      "seed : 9973, 0.9534762977591115\n",
      "seed : 121, 0.9534762977591115\n",
      "seed : 9421, 0.9389098356840293\n",
      "seed : 6730, 0.9497956150130062\n",
      "seed : 542, 0.9497956150130062\n",
      "seed : 6204, 0.9495820271682341\n",
      "seed : 5579, 0.9458610339700974\n",
      "seed : 4531, 0.9426235600148644\n",
      "seed : 2456, 0.9423794596208389\n",
      "seed : 8807, 0.9497956150130062\n",
      "seed : 3419, 0.9495820271682341\n",
      "seed : 6361, 0.946318805106667\n",
      "seed : 4341, 0.9534762977591115\n",
      "seed : 7336, 0.9426235600148644\n",
      "seed : 4439, 0.9426235600148644\n",
      "seed : 7261, 0.9495820271682341\n",
      "seed : 8254, 0.9567845947156292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [67], line 45\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# XGBoost 모델 훈련\u001b[39;00m\n\u001b[1;32m     38\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxgb_params,\n\u001b[1;32m     40\u001b[0m     tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m oof_test_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test) \u001b[38;5;241m/\u001b[39m skf\u001b[38;5;241m.\u001b[39mn_splits\n\u001b[1;32m     48\u001b[0m oof_val_preds[valid_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1516\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m (\n\u001b[1;32m   1489\u001b[0m     model,\n\u001b[1;32m   1490\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1496\u001b[0m )\n\u001b[1;32m   1497\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1498\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1499\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1514\u001b[0m )\n\u001b[0;32m-> 1516\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seeds = []\n",
    "\n",
    "for _ in range(100) :\n",
    "    while True :\n",
    "        random_seed = np.random.randint(10000)\n",
    "        if random_seed not in seeds :\n",
    "            seeds.append(random_seed)\n",
    "            break\n",
    "        else :\n",
    "            continue\n",
    "\n",
    "    y = train['class'].values\n",
    "    X = train.drop(['id', 'class'], axis=1).to_numpy()\n",
    "    X_test = test.drop(['id'], axis=1).to_numpy()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=24, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    oof_val_preds = np.zeros((X.shape[0], 3))\n",
    "    oof_test_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "    # OOF\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        # print('#'*30, f'Fold [{fold+1}/{skf.n_splits}]', '#'*30)\n",
    "\n",
    "        # train, valid data 설정\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "        smote = SMOTE(random_state=random_seed)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        # 불균형 데이터 가중치 조정 값 => 음성(0) 타깃값 개수 / 양성(1) 타깃값 개수\n",
    "        _, counts = np.unique(np.array(y_train), return_counts=True)\n",
    "        scale_weight = counts[0] / counts[1]\n",
    "\n",
    "        # XGBoost 모델 훈련\n",
    "        xgb_model = XGBClassifier(\n",
    "            **xgb_params,\n",
    "            tree_method='gpu_hist',\n",
    "            predictor='gpu_predictor',\n",
    "            random_state=random_seed,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        oof_test_preds += xgb_model.predict_proba(X_test) / skf.n_splits\n",
    "        oof_val_preds[valid_idx] += xgb_model.predict_proba(X_valid)\n",
    "\n",
    "        # if fold == 1 :\n",
    "        #     pred = xgb_model.predict(X_test)\n",
    "        #     break\n",
    "\n",
    "        #model save\n",
    "        # xgb_model.save_model(f'./models/new_xgb_{skf.n_splits}_{fold}.json')\n",
    "        del [[X_train, y_train, X_valid, y_valid, xgb_model]]\n",
    "        gc.collect()\n",
    "\n",
    "    #     model score check\n",
    "    preds = np.argmax(oof_val_preds, axis=1)\n",
    "    print(f\"seed : {random_seed},\", f1_score(y, preds, average=\"macro\"))\n",
    "\n",
    "    # # save OOF test preds\n",
    "    # np.save(f'./results/new_{skf.n_splits}_oof_test_preds.npy', oof_test_preds[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91d2164a-c5dc-496c-b3d7-0b46bcb8cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2, seed : 724, 0.9139353400222966\n",
      "k: 2, seed : 7566, 0.9204153546258809\n",
      "k: 2, seed : 9630, 0.9238551500634071\n",
      "k: 2, seed : 9896, 0.9354515050167224\n",
      "k: 2, seed : 3823, 0.9386425051661104\n",
      "k: 2, seed : 3670, 0.9423794596208389\n",
      "k: 2, seed : 4040, 0.9460969138388493\n",
      "k: 2, seed : 2039, 0.9495820271682341\n",
      "k: 2, seed : 3197, 0.952862711944014\n",
      "k: 2, seed : 9072, 0.9534762977591115\n",
      "k: 3, seed : 1177, 0.9567845947156292\n",
      "k: 8, seed : 419, 0.9641397250092902\n",
      "k: 14, seed : 5833, 0.9713117800074321\n",
      "k: 14, seed : 5833, 0.9713117800074321\n"
     ]
    }
   ],
   "source": [
    "high = 0\n",
    "for k in range(2, 21) :\n",
    "    seeds = []\n",
    "    for _ in range(100) :\n",
    "        while True :\n",
    "            random_seed = np.random.randint(10000)\n",
    "            if random_seed not in seeds :\n",
    "                seeds.append(random_seed)\n",
    "                break\n",
    "            else :\n",
    "                continue\n",
    "\n",
    "        y = train['class'].values\n",
    "        X = train.drop(['id', 'class'], axis=1).to_numpy()\n",
    "        X_test = test.drop(['id'], axis=1).to_numpy()\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=random_seed)\n",
    "\n",
    "        oof_val_preds = np.zeros((X.shape[0], 3))\n",
    "        oof_test_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "        # OOF\n",
    "        for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "            # print('#'*30, f'Fold [{fold+1}/{skf.n_splits}]', '#'*30)\n",
    "\n",
    "            # train, valid data 설정\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "            smote = SMOTE(random_state=random_seed)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            # 불균형 데이터 가중치 조정 값 => 음성(0) 타깃값 개수 / 양성(1) 타깃값 개수\n",
    "            _, counts = np.unique(np.array(y_train), return_counts=True)\n",
    "            scale_weight = counts[0] / counts[1]\n",
    "\n",
    "            # XGBoost 모델 훈련\n",
    "            xgb_model = XGBClassifier(\n",
    "                **xgb_params,\n",
    "                tree_method='gpu_hist',\n",
    "                predictor='gpu_predictor',\n",
    "                random_state=random_seed,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "            oof_test_preds += xgb_model.predict_proba(X_test) / skf.n_splits\n",
    "            oof_val_preds[valid_idx] += xgb_model.predict_proba(X_valid)\n",
    "\n",
    "            # if fold == 1 :\n",
    "            #     pred = xgb_model.predict(X_test)\n",
    "            #     break\n",
    "\n",
    "            #model save\n",
    "            # xgb_model.save_model(f'./models/new_xgb_{skf.n_splits}_{fold}.json')\n",
    "            del [[X_train, y_train, X_valid, y_valid, xgb_model]]\n",
    "            gc.collect()\n",
    "\n",
    "        #     model score check\n",
    "        preds = np.argmax(oof_val_preds, axis=1)\n",
    "        score =  f1_score(y, preds, average=\"macro\")\n",
    "        if score > high :\n",
    "            high = score\n",
    "            text = f'k: {k}, seed : {random_seed}, {score}'\n",
    "            print(text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec8b9a12-b19d-46a0-94e9-f72dbf0d54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 2, seed : 7999, 0.9453459066066321\n",
      "k: 2, seed : 6982, 0.9456108214738622\n",
      "k: 2, seed : 2524, 0.946318805106667\n",
      "k: 2, seed : 4636, 0.9497956150130062\n",
      "k: 2, seed : 6274, 0.9532839919936694\n",
      "k: 2, seed : 3866, 0.9569676700111481\n",
      "k: 2, seed : 121, 0.9604710701484894\n",
      "k: 2, seed : 3049, 0.9607864867610525\n",
      "k: 3, seed : 8701, 0.9676581483033097\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 46\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# XGBoost 모델 훈련\u001b[39;00m\n\u001b[1;32m     39\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxgb_params,\n\u001b[1;32m     41\u001b[0m     tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     45\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m oof_test_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test) \u001b[38;5;241m/\u001b[39m skf\u001b[38;5;241m.\u001b[39mn_splits\n\u001b[1;32m     49\u001b[0m oof_val_preds[valid_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1516\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m (\n\u001b[1;32m   1489\u001b[0m     model,\n\u001b[1;32m   1490\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1496\u001b[0m )\n\u001b[1;32m   1497\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1498\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1499\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1514\u001b[0m )\n\u001b[0;32m-> 1516\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "high = 0\n",
    "for k in tqdm(range(2, 21)) :\n",
    "    seeds = []\n",
    "    for _ in range(1000) :\n",
    "        while True :\n",
    "            random_seed = np.random.randint(10000)\n",
    "            if random_seed not in seeds :\n",
    "                seeds.append(random_seed)\n",
    "                break\n",
    "            else :\n",
    "                continue\n",
    "\n",
    "        y = train['class'].values\n",
    "        X = train.drop(['id', 'class'], axis=1).to_numpy()\n",
    "        X_test = test.drop(['id'], axis=1).to_numpy()\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=random_seed)\n",
    "\n",
    "        oof_val_preds = np.zeros((X.shape[0], 3))\n",
    "        oof_test_preds = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "        # OOF\n",
    "        for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "            # print('#'*30, f'Fold [{fold+1}/{skf.n_splits}]', '#'*30)\n",
    "\n",
    "            # train, valid data 설정\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "            smote = SMOTE(random_state=random_seed)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            # 불균형 데이터 가중치 조정 값 => 음성(0) 타깃값 개수 / 양성(1) 타깃값 개수\n",
    "            _, counts = np.unique(np.array(y_train), return_counts=True)\n",
    "            scale_weight = counts[0] / counts[1]\n",
    "\n",
    "            # XGBoost 모델 훈련\n",
    "            xgb_model = XGBClassifier(\n",
    "                **xgb_params,\n",
    "                tree_method='gpu_hist',\n",
    "                predictor='gpu_predictor',\n",
    "                random_state=random_seed,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "            oof_test_preds += xgb_model.predict_proba(X_test) / skf.n_splits\n",
    "            oof_val_preds[valid_idx] += xgb_model.predict_proba(X_valid)\n",
    "\n",
    "            # if fold == 1 :\n",
    "            #     pred = xgb_model.predict(X_test)\n",
    "            #     break\n",
    "\n",
    "            #model save\n",
    "            # xgb_model.save_model(f'./models/new_xgb_{skf.n_splits}_{fold}.json')\n",
    "            del [[X_train, y_train, X_valid, y_valid, xgb_model]]\n",
    "            gc.collect()\n",
    "\n",
    "        #     model score check\n",
    "        preds = np.argmax(oof_val_preds, axis=1)\n",
    "        score =  f1_score(y, preds, average=\"macro\")\n",
    "        if score > high :\n",
    "            high = score\n",
    "            text = f'k: {k}, seed : {random_seed}, {score}'\n",
    "            print(text)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(text)\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e59e2-cddc-41c1-b18b-8d74289477ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
