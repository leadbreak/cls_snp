{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da5a778-128c-4d84-ae25-586932bf9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de763fbb-6ace-45cd-935f-30dd6b0a54fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474b1ef8-50a2-4228-8b09-58a9468f4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 41\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "seed_everything(seed=random_seed) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6cb23f-c9fe-4a1e-8410-3fdc2b59646e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((262, 48), (175, 47))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/df_train.csv\")\n",
    "test = pd.read_csv(\"./data/df_test.csv\")\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5d0a7f-9cee-4772-943b-142965934278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 0, 0, 2, 1, 1, 0, 1,\n",
       "        2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0,\n",
       "        2, 0, 0, 2, 0, 2, 1, 1, 0, 0, 2, 2, 1, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2,\n",
       "        0, 1, 1, 1, 2, 1, 2, 0, 1, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1,\n",
       "        2, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2,\n",
       "        1, 1, 2, 0, 0, 1, 1, 0, 2, 2, 2, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 1,\n",
       "        1, 1, 2, 2, 0, 1, 0, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0,\n",
       "        0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 1, 2, 1, 2, 2, 1,\n",
       "        1, 1, 0, 1, 1, 2, 1, 2, 0, 1, 0, 1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 0, 1, 2,\n",
       "        0, 0, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 2, 1, 2, 1, 0, 2, 0,\n",
       "        0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 0, 2, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.LongTensor(train['class'].values)\n",
    "X = train.drop(['id', 'class'], axis=1).to_numpy()\n",
    "X_test = test.drop(['id'], axis=1).to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ec9a90-06c6-4e35-9e42-93ea2613630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = nn.functional.one_hot(y, num_classes=3).to(device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ba246f-2991-4c64-a5d8-474a63ab40d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = np.concatenate([X, X_test], axis=0)\n",
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0db974-ebf3-4762-9b46-9fac884fc76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437, 46)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "total = scaler.fit_transform(total)\n",
    "# total = np.expand_dims(total, axis=1)\n",
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c594bd68-9483-45cb-a1a1-0abdd53bc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_features, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm0 = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=latent_dim**2,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=latent_dim**2,\n",
    "            hidden_size=latent_dim**3,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=latent_dim**3,\n",
    "            hidden_size=latent_dim*3,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(\n",
    "            input_size=latent_dim*3,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, (_, _) = self.lstm0(x)\n",
    "        x2, (_, _) = self.lstm1(x1)\n",
    "        x3, (_, _) = self.lstm2(x2)\n",
    "        x4, (h_n, _) = self.lstm3(x3)\n",
    "        \n",
    "        return h_n.permute(1, 0, 2)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_features, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.lstm0 = nn.LSTM(\n",
    "            input_size=latent_dim,\n",
    "            hidden_size=latent_dim*3,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=latent_dim*3,\n",
    "            hidden_size=latent_dim**3,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=latent_dim**3,\n",
    "            hidden_size=latent_dim**2,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(\n",
    "            input_size=latent_dim**2,\n",
    "            hidden_size=latent_dim*2,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )        \n",
    "        \n",
    "        \n",
    "        self.linear = nn.Linear(in_features=latent_dim*2, out_features=n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1, 31, 1)\n",
    "        \n",
    "        x, (_, _) = self.lstm0(x)\n",
    "        x, (_, _) = self.lstm1(x)\n",
    "        x, (_, _) = self.lstm2(x)\n",
    "        x, (_, _) = self.lstm3(x)            \n",
    "        \n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, n_features=46, latent_dim=6, device=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(n_features, latent_dim).to(device)\n",
    "        self.decoder = Decoder(n_features, latent_dim).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x2 = self.decoder(x1)\n",
    "        \n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b35cb587-3a24-45a7-a457-2f2e1b478678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_features, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm0 = nn.Linear(n_features, latent_dim**2)\n",
    "        self.lstm1 = nn.Linear(latent_dim**2, latent_dim*3)        \n",
    "        self.lstm2_1 = nn.Linear(latent_dim*3, 3)\n",
    "        self.lstm2_2 = nn.Linear(latent_dim*3, latent_dim-3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.lstm0(x)\n",
    "        x2 = self.lstm1(x1)\n",
    "        x3_1 = self.lstm2_1(x2)\n",
    "        x3_2 = self.lstm2_2(x2)\n",
    "        \n",
    "        return x3_1, x3_2\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_features, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.lstm0 = nn.Linear(latent_dim, latent_dim*3)\n",
    "        self.lstm1 = nn.Linear(latent_dim*3, latent_dim**2)        \n",
    "        self.lstm2 = nn.Linear(latent_dim**2, latent_dim*2)        \n",
    "        \n",
    "        \n",
    "        self.linear = nn.Linear(in_features=latent_dim*2, out_features=n_features)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.lstm0(x)\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x)\n",
    "        \n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, n_features=46, latent_dim=3+24, device=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(n_features, latent_dim).to(device)\n",
    "        self.decoder = Decoder(n_features, latent_dim).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1_1, x1_2 = self.encoder(x)\n",
    "        x1 = torch.concat([x1_1, x1_2], axis=1)\n",
    "        x2 = self.decoder(x1)\n",
    "        \n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9279d5-2548-4a1a-bb96-8ad6375fb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':5000,\n",
    "    'LEARNING_RATE':0.0017,\n",
    "    'BATCH_SIZE':437,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29399ab4-cf33-46ab-8632-80908f9bf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    model_preds = []\n",
    "    true_labels = []\n",
    "    \n",
    "    val_loss = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, label in iter(test_loader):\n",
    "            x, label = x.to(device), label.to(device)\n",
    "\n",
    "            model_pred = model(x)\n",
    "\n",
    "            loss = criterion(model_pred, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e51394c-d83c-46ba-b032-b84a454a15b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1], Loss1 : 1.216126, Loss2 : 1.008193, Train Loss : [1.00819] - Model Saved!\n",
      "\n",
      "Epoch [2], Loss1 : 1.218909, Loss2 : 1.008193, Train Loss : [1.00819] - Model Saved!\n",
      "\n",
      "Epoch [3], Loss1 : 1.218851, Loss2 : 1.008165, Train Loss : [1.00816] - Model Saved!\n",
      "\n",
      "Epoch [4], Loss1 : 1.219759, Loss2 : 1.008108, Train Loss : [1.00811] - Model Saved!\n",
      "\n",
      "Epoch [5], Loss1 : 1.221657, Loss2 : 1.008022, Train Loss : [1.00802] - Model Saved!\n",
      "\n",
      "Epoch [6], Loss1 : 1.223825, Loss2 : 1.007908, Train Loss : [1.00791] - Model Saved!\n",
      "\n",
      "Epoch [7], Loss1 : 1.224005, Loss2 : 1.007765, Train Loss : [1.00777] - Model Saved!\n",
      "\n",
      "Epoch [8], Loss1 : 1.226371, Loss2 : 1.007595, Train Loss : [1.00759] - Model Saved!\n",
      "\n",
      "Epoch [9], Loss1 : 1.219775, Loss2 : 1.007396, Train Loss : [1.00740] - Model Saved!\n",
      "\n",
      "Epoch [10], Loss1 : 1.221150, Loss2 : 1.007169, Train Loss : [1.00717] - Model Saved!\n",
      "\n",
      "Epoch [11], Loss1 : 1.219180, Loss2 : 1.006914, Train Loss : [1.00691] - Model Saved!\n",
      "\n",
      "Epoch [12], Loss1 : 1.223632, Loss2 : 1.006632, Train Loss : [1.00663] - Model Saved!\n",
      "\n",
      "Epoch [13], Loss1 : 1.218324, Loss2 : 1.006321, Train Loss : [1.00632] - Model Saved!\n",
      "\n",
      "Epoch [14], Loss1 : 1.221053, Loss2 : 1.005983, Train Loss : [1.00598] - Model Saved!\n",
      "\n",
      "Epoch [15], Loss1 : 1.219883, Loss2 : 1.005617, Train Loss : [1.00562] - Model Saved!\n",
      "\n",
      "Epoch [16], Loss1 : 1.219340, Loss2 : 1.005224, Train Loss : [1.00522] - Model Saved!\n",
      "\n",
      "Epoch [17], Loss1 : 1.217114, Loss2 : 1.004802, Train Loss : [1.00480] - Model Saved!\n",
      "\n",
      "Epoch [18], Loss1 : 1.218657, Loss2 : 1.004351, Train Loss : [1.00435] - Model Saved!\n",
      "\n",
      "Epoch [19], Loss1 : 1.219403, Loss2 : 1.003871, Train Loss : [1.00387] - Model Saved!\n",
      "\n",
      "Epoch [20], Loss1 : 1.220121, Loss2 : 1.003362, Train Loss : [1.00336] - Model Saved!\n",
      "\n",
      "Epoch [21], Loss1 : 1.223773, Loss2 : 1.002822, Train Loss : [1.00282] - Model Saved!\n",
      "\n",
      "Epoch [22], Loss1 : 1.219228, Loss2 : 1.002250, Train Loss : [1.00225] - Model Saved!\n",
      "\n",
      "Epoch [23], Loss1 : 1.225382, Loss2 : 1.001644, Train Loss : [1.00164] - Model Saved!\n",
      "\n",
      "Epoch [24], Loss1 : 1.220929, Loss2 : 1.001004, Train Loss : [1.00100] - Model Saved!\n",
      "\n",
      "Epoch [25], Loss1 : 1.226173, Loss2 : 1.000328, Train Loss : [1.00033] - Model Saved!\n",
      "\n",
      "Epoch [26], Loss1 : 1.223677, Loss2 : 0.999612, Train Loss : [0.99961] - Model Saved!\n",
      "\n",
      "Epoch [27], Loss1 : 1.219672, Loss2 : 0.998854, Train Loss : [0.99885] - Model Saved!\n",
      "\n",
      "Epoch [28], Loss1 : 1.223222, Loss2 : 0.998052, Train Loss : [0.99805] - Model Saved!\n",
      "\n",
      "Epoch [29], Loss1 : 1.226034, Loss2 : 0.997201, Train Loss : [0.99720] - Model Saved!\n",
      "\n",
      "Epoch [30], Loss1 : 1.218481, Loss2 : 0.996299, Train Loss : [0.99630] - Model Saved!\n",
      "\n",
      "Epoch [31], Loss1 : 1.222061, Loss2 : 0.995340, Train Loss : [0.99534] - Model Saved!\n",
      "\n",
      "Epoch [32], Loss1 : 1.222339, Loss2 : 0.994320, Train Loss : [0.99432] - Model Saved!\n",
      "\n",
      "Epoch [33], Loss1 : 1.221686, Loss2 : 0.993234, Train Loss : [0.99323] - Model Saved!\n",
      "\n",
      "Epoch [34], Loss1 : 1.222634, Loss2 : 0.992076, Train Loss : [0.99208] - Model Saved!\n",
      "\n",
      "Epoch [35], Loss1 : 1.221274, Loss2 : 0.990840, Train Loss : [0.99084] - Model Saved!\n",
      "\n",
      "Epoch [36], Loss1 : 1.220022, Loss2 : 0.989518, Train Loss : [0.98952] - Model Saved!\n",
      "\n",
      "Epoch [37], Loss1 : 1.227634, Loss2 : 0.988104, Train Loss : [0.98810] - Model Saved!\n",
      "\n",
      "Epoch [38], Loss1 : 1.223273, Loss2 : 0.986590, Train Loss : [0.98659] - Model Saved!\n",
      "\n",
      "Epoch [39], Loss1 : 1.218608, Loss2 : 0.984966, Train Loss : [0.98497] - Model Saved!\n",
      "\n",
      "Epoch [40], Loss1 : 1.221023, Loss2 : 0.983223, Train Loss : [0.98322] - Model Saved!\n",
      "\n",
      "Epoch [41], Loss1 : 1.219961, Loss2 : 0.981353, Train Loss : [0.98135] - Model Saved!\n",
      "\n",
      "Epoch [42], Loss1 : 1.220324, Loss2 : 0.979343, Train Loss : [0.97934] - Model Saved!\n",
      "\n",
      "Epoch [43], Loss1 : 1.218591, Loss2 : 0.977184, Train Loss : [0.97718] - Model Saved!\n",
      "\n",
      "Epoch [44], Loss1 : 1.219081, Loss2 : 0.974863, Train Loss : [0.97486] - Model Saved!\n",
      "\n",
      "Epoch [45], Loss1 : 1.221613, Loss2 : 0.972369, Train Loss : [0.97237] - Model Saved!\n",
      "\n",
      "Epoch [46], Loss1 : 1.222682, Loss2 : 0.969689, Train Loss : [0.96969] - Model Saved!\n",
      "\n",
      "Epoch [47], Loss1 : 1.221418, Loss2 : 0.966810, Train Loss : [0.96681] - Model Saved!\n",
      "\n",
      "Epoch [48], Loss1 : 1.217658, Loss2 : 0.963720, Train Loss : [0.96372] - Model Saved!\n",
      "\n",
      "Epoch [49], Loss1 : 1.223066, Loss2 : 0.960405, Train Loss : [0.96041] - Model Saved!\n",
      "\n",
      "Epoch [50], Loss1 : 1.218108, Loss2 : 0.956854, Train Loss : [0.95685] - Model Saved!\n",
      "\n",
      "Epoch [51], Loss1 : 1.218723, Loss2 : 0.953052, Train Loss : [0.95305] - Model Saved!\n",
      "\n",
      "Epoch [52], Loss1 : 1.221097, Loss2 : 0.948988, Train Loss : [0.94899] - Model Saved!\n",
      "\n",
      "Epoch [53], Loss1 : 1.223011, Loss2 : 0.944652, Train Loss : [0.94465] - Model Saved!\n",
      "\n",
      "Epoch [54], Loss1 : 1.222308, Loss2 : 0.940033, Train Loss : [0.94003] - Model Saved!\n",
      "\n",
      "Epoch [55], Loss1 : 1.219477, Loss2 : 0.935123, Train Loss : [0.93512] - Model Saved!\n",
      "\n",
      "Epoch [56], Loss1 : 1.219106, Loss2 : 0.929915, Train Loss : [0.92992] - Model Saved!\n",
      "\n",
      "Epoch [57], Loss1 : 1.219967, Loss2 : 0.924407, Train Loss : [0.92441] - Model Saved!\n",
      "\n",
      "Epoch [58], Loss1 : 1.220411, Loss2 : 0.918598, Train Loss : [0.91860] - Model Saved!\n",
      "\n",
      "Epoch [59], Loss1 : 1.218897, Loss2 : 0.912491, Train Loss : [0.91249] - Model Saved!\n",
      "\n",
      "Epoch [60], Loss1 : 1.220992, Loss2 : 0.906094, Train Loss : [0.90609] - Model Saved!\n",
      "\n",
      "Epoch [61], Loss1 : 1.221976, Loss2 : 0.899420, Train Loss : [0.89942] - Model Saved!\n",
      "\n",
      "Epoch [62], Loss1 : 1.221857, Loss2 : 0.892488, Train Loss : [0.89249] - Model Saved!\n",
      "\n",
      "Epoch [63], Loss1 : 1.216283, Loss2 : 0.885322, Train Loss : [0.88532] - Model Saved!\n",
      "\n",
      "Epoch [64], Loss1 : 1.218474, Loss2 : 0.877955, Train Loss : [0.87796] - Model Saved!\n",
      "\n",
      "Epoch [65], Loss1 : 1.221624, Loss2 : 0.870427, Train Loss : [0.87043] - Model Saved!\n",
      "\n",
      "Epoch [66], Loss1 : 1.223031, Loss2 : 0.862786, Train Loss : [0.86279] - Model Saved!\n",
      "\n",
      "Epoch [67], Loss1 : 1.219561, Loss2 : 0.855084, Train Loss : [0.85508] - Model Saved!\n",
      "\n",
      "Epoch [68], Loss1 : 1.225297, Loss2 : 0.847383, Train Loss : [0.84738] - Model Saved!\n",
      "\n",
      "Epoch [69], Loss1 : 1.225529, Loss2 : 0.839748, Train Loss : [0.83975] - Model Saved!\n",
      "\n",
      "Epoch [70], Loss1 : 1.222164, Loss2 : 0.832246, Train Loss : [0.83225] - Model Saved!\n",
      "\n",
      "Epoch [71], Loss1 : 1.222020, Loss2 : 0.824946, Train Loss : [0.82495] - Model Saved!\n",
      "\n",
      "Epoch [72], Loss1 : 1.220358, Loss2 : 0.817907, Train Loss : [0.81791] - Model Saved!\n",
      "\n",
      "Epoch [73], Loss1 : 1.217752, Loss2 : 0.811181, Train Loss : [0.81118] - Model Saved!\n",
      "\n",
      "Epoch [74], Loss1 : 1.214176, Loss2 : 0.804803, Train Loss : [0.80480] - Model Saved!\n",
      "\n",
      "Epoch [75], Loss1 : 1.219211, Loss2 : 0.798789, Train Loss : [0.79879] - Model Saved!\n",
      "\n",
      "Epoch [76], Loss1 : 1.224648, Loss2 : 0.793135, Train Loss : [0.79314] - Model Saved!\n",
      "\n",
      "Epoch [77], Loss1 : 1.212853, Loss2 : 0.787816, Train Loss : [0.78782] - Model Saved!\n",
      "\n",
      "Epoch [78], Loss1 : 1.220274, Loss2 : 0.782786, Train Loss : [0.78279] - Model Saved!\n",
      "\n",
      "Epoch [79], Loss1 : 1.216797, Loss2 : 0.777991, Train Loss : [0.77799] - Model Saved!\n",
      "\n",
      "Epoch [80], Loss1 : 1.219404, Loss2 : 0.773367, Train Loss : [0.77337] - Model Saved!\n",
      "\n",
      "Epoch [81], Loss1 : 1.212899, Loss2 : 0.768855, Train Loss : [0.76886] - Model Saved!\n",
      "\n",
      "Epoch [82], Loss1 : 1.210302, Loss2 : 0.764406, Train Loss : [0.76441] - Model Saved!\n",
      "\n",
      "Epoch [83], Loss1 : 1.220892, Loss2 : 0.759982, Train Loss : [0.75998] - Model Saved!\n",
      "\n",
      "Epoch [84], Loss1 : 1.218399, Loss2 : 0.755563, Train Loss : [0.75556] - Model Saved!\n",
      "\n",
      "Epoch [85], Loss1 : 1.222050, Loss2 : 0.751144, Train Loss : [0.75114] - Model Saved!\n",
      "\n",
      "Epoch [86], Loss1 : 1.219069, Loss2 : 0.746730, Train Loss : [0.74673] - Model Saved!\n",
      "\n",
      "Epoch [87], Loss1 : 1.218841, Loss2 : 0.742335, Train Loss : [0.74233] - Model Saved!\n",
      "\n",
      "Epoch [88], Loss1 : 1.221177, Loss2 : 0.737977, Train Loss : [0.73798] - Model Saved!\n",
      "\n",
      "Epoch [89], Loss1 : 1.227775, Loss2 : 0.733675, Train Loss : [0.73367] - Model Saved!\n",
      "\n",
      "Epoch [90], Loss1 : 1.217949, Loss2 : 0.729442, Train Loss : [0.72944] - Model Saved!\n",
      "\n",
      "Epoch [91], Loss1 : 1.220671, Loss2 : 0.725291, Train Loss : [0.72529] - Model Saved!\n",
      "\n",
      "Epoch [92], Loss1 : 1.224244, Loss2 : 0.721224, Train Loss : [0.72122] - Model Saved!\n",
      "\n",
      "Epoch [93], Loss1 : 1.231602, Loss2 : 0.717243, Train Loss : [0.71724] - Model Saved!\n",
      "\n",
      "Epoch [94], Loss1 : 1.220448, Loss2 : 0.713345, Train Loss : [0.71335] - Model Saved!\n",
      "\n",
      "Epoch [95], Loss1 : 1.232755, Loss2 : 0.709524, Train Loss : [0.70952] - Model Saved!\n",
      "\n",
      "Epoch [96], Loss1 : 1.227285, Loss2 : 0.705773, Train Loss : [0.70577] - Model Saved!\n",
      "\n",
      "Epoch [97], Loss1 : 1.219723, Loss2 : 0.702088, Train Loss : [0.70209] - Model Saved!\n",
      "\n",
      "Epoch [98], Loss1 : 1.218609, Loss2 : 0.698464, Train Loss : [0.69846] - Model Saved!\n",
      "\n",
      "Epoch [99], Loss1 : 1.217758, Loss2 : 0.694898, Train Loss : [0.69490] - Model Saved!\n",
      "\n",
      "Epoch [100], Loss1 : 1.221995, Loss2 : 0.691385, Train Loss : [0.69138] - Model Saved!\n",
      "\n",
      "Epoch [101], Loss1 : 1.222347, Loss2 : 0.687921, Train Loss : [0.68792] - Model Saved!\n",
      "\n",
      "Epoch [102], Loss1 : 1.222894, Loss2 : 0.684499, Train Loss : [0.68450] - Model Saved!\n",
      "\n",
      "Epoch [103], Loss1 : 1.221678, Loss2 : 0.681113, Train Loss : [0.68111] - Model Saved!\n",
      "\n",
      "Epoch [104], Loss1 : 1.227680, Loss2 : 0.677752, Train Loss : [0.67775] - Model Saved!\n",
      "\n",
      "Epoch [105], Loss1 : 1.217113, Loss2 : 0.674407, Train Loss : [0.67441] - Model Saved!\n",
      "\n",
      "Epoch [106], Loss1 : 1.213642, Loss2 : 0.671069, Train Loss : [0.67107] - Model Saved!\n",
      "\n",
      "Epoch [107], Loss1 : 1.217717, Loss2 : 0.667732, Train Loss : [0.66773] - Model Saved!\n",
      "\n",
      "Epoch [108], Loss1 : 1.221423, Loss2 : 0.664392, Train Loss : [0.66439] - Model Saved!\n",
      "\n",
      "Epoch [109], Loss1 : 1.230041, Loss2 : 0.661047, Train Loss : [0.66105] - Model Saved!\n",
      "\n",
      "Epoch [110], Loss1 : 1.216961, Loss2 : 0.657699, Train Loss : [0.65770] - Model Saved!\n",
      "\n",
      "Epoch [111], Loss1 : 1.208378, Loss2 : 0.654350, Train Loss : [0.65435] - Model Saved!\n",
      "\n",
      "Epoch [112], Loss1 : 1.223675, Loss2 : 0.651000, Train Loss : [0.65100] - Model Saved!\n",
      "\n",
      "Epoch [113], Loss1 : 1.212039, Loss2 : 0.647652, Train Loss : [0.64765] - Model Saved!\n",
      "\n",
      "Epoch [114], Loss1 : 1.226487, Loss2 : 0.644302, Train Loss : [0.64430] - Model Saved!\n",
      "\n",
      "Epoch [115], Loss1 : 1.222103, Loss2 : 0.640950, Train Loss : [0.64095] - Model Saved!\n",
      "\n",
      "Epoch [116], Loss1 : 1.218064, Loss2 : 0.637591, Train Loss : [0.63759] - Model Saved!\n",
      "\n",
      "Epoch [117], Loss1 : 1.237603, Loss2 : 0.634224, Train Loss : [0.63422] - Model Saved!\n",
      "\n",
      "Epoch [118], Loss1 : 1.215856, Loss2 : 0.630844, Train Loss : [0.63084] - Model Saved!\n",
      "\n",
      "Epoch [119], Loss1 : 1.212541, Loss2 : 0.627453, Train Loss : [0.62745] - Model Saved!\n",
      "\n",
      "Epoch [120], Loss1 : 1.207323, Loss2 : 0.624048, Train Loss : [0.62405] - Model Saved!\n",
      "\n",
      "Epoch [121], Loss1 : 1.211447, Loss2 : 0.620630, Train Loss : [0.62063] - Model Saved!\n",
      "\n",
      "Epoch [122], Loss1 : 1.209096, Loss2 : 0.617200, Train Loss : [0.61720] - Model Saved!\n",
      "\n",
      "Epoch [123], Loss1 : 1.227075, Loss2 : 0.613759, Train Loss : [0.61376] - Model Saved!\n",
      "\n",
      "Epoch [124], Loss1 : 1.230712, Loss2 : 0.610303, Train Loss : [0.61030] - Model Saved!\n",
      "\n",
      "Epoch [125], Loss1 : 1.217121, Loss2 : 0.606833, Train Loss : [0.60683] - Model Saved!\n",
      "\n",
      "Epoch [126], Loss1 : 1.214902, Loss2 : 0.603343, Train Loss : [0.60334] - Model Saved!\n",
      "\n",
      "Epoch [127], Loss1 : 1.209479, Loss2 : 0.599831, Train Loss : [0.59983] - Model Saved!\n",
      "\n",
      "Epoch [128], Loss1 : 1.226507, Loss2 : 0.596291, Train Loss : [0.59629] - Model Saved!\n",
      "\n",
      "Epoch [129], Loss1 : 1.227939, Loss2 : 0.592717, Train Loss : [0.59272] - Model Saved!\n",
      "\n",
      "Epoch [130], Loss1 : 1.199429, Loss2 : 0.589107, Train Loss : [0.58911] - Model Saved!\n",
      "\n",
      "Epoch [131], Loss1 : 1.221771, Loss2 : 0.585457, Train Loss : [0.58546] - Model Saved!\n",
      "\n",
      "Epoch [132], Loss1 : 1.225369, Loss2 : 0.581764, Train Loss : [0.58176] - Model Saved!\n",
      "\n",
      "Epoch [133], Loss1 : 1.219929, Loss2 : 0.578029, Train Loss : [0.57803] - Model Saved!\n",
      "\n",
      "Epoch [134], Loss1 : 1.220626, Loss2 : 0.574252, Train Loss : [0.57425] - Model Saved!\n",
      "\n",
      "Epoch [135], Loss1 : 1.200203, Loss2 : 0.570435, Train Loss : [0.57043] - Model Saved!\n",
      "\n",
      "Epoch [136], Loss1 : 1.237570, Loss2 : 0.566581, Train Loss : [0.56658] - Model Saved!\n",
      "\n",
      "Epoch [137], Loss1 : 1.208310, Loss2 : 0.562693, Train Loss : [0.56269] - Model Saved!\n",
      "\n",
      "Epoch [138], Loss1 : 1.209835, Loss2 : 0.558774, Train Loss : [0.55877] - Model Saved!\n",
      "\n",
      "Epoch [139], Loss1 : 1.204842, Loss2 : 0.554824, Train Loss : [0.55482] - Model Saved!\n",
      "\n",
      "Epoch [140], Loss1 : 1.209206, Loss2 : 0.550847, Train Loss : [0.55085] - Model Saved!\n",
      "\n",
      "Epoch [141], Loss1 : 1.223008, Loss2 : 0.546844, Train Loss : [0.54684] - Model Saved!\n",
      "\n",
      "Epoch [142], Loss1 : 1.210847, Loss2 : 0.542817, Train Loss : [0.54282] - Model Saved!\n",
      "\n",
      "Epoch [143], Loss1 : 1.230074, Loss2 : 0.538770, Train Loss : [0.53877] - Model Saved!\n",
      "\n",
      "Epoch [144], Loss1 : 1.220590, Loss2 : 0.534708, Train Loss : [0.53471] - Model Saved!\n",
      "\n",
      "Epoch [145], Loss1 : 1.208779, Loss2 : 0.530634, Train Loss : [0.53063] - Model Saved!\n",
      "\n",
      "Epoch [146], Loss1 : 1.201393, Loss2 : 0.526552, Train Loss : [0.52655] - Model Saved!\n",
      "\n",
      "Epoch [147], Loss1 : 1.214208, Loss2 : 0.522467, Train Loss : [0.52247] - Model Saved!\n",
      "\n",
      "Epoch [148], Loss1 : 1.216116, Loss2 : 0.518380, Train Loss : [0.51838] - Model Saved!\n",
      "\n",
      "Epoch [149], Loss1 : 1.219516, Loss2 : 0.514296, Train Loss : [0.51430] - Model Saved!\n",
      "\n",
      "Epoch [150], Loss1 : 1.205999, Loss2 : 0.510215, Train Loss : [0.51021] - Model Saved!\n",
      "\n",
      "Epoch [151], Loss1 : 1.221549, Loss2 : 0.506139, Train Loss : [0.50614] - Model Saved!\n",
      "\n",
      "Epoch [152], Loss1 : 1.211584, Loss2 : 0.502070, Train Loss : [0.50207] - Model Saved!\n",
      "\n",
      "Epoch [153], Loss1 : 1.231187, Loss2 : 0.498009, Train Loss : [0.49801] - Model Saved!\n",
      "\n",
      "Epoch [154], Loss1 : 1.192672, Loss2 : 0.493956, Train Loss : [0.49396] - Model Saved!\n",
      "\n",
      "Epoch [155], Loss1 : 1.201296, Loss2 : 0.489913, Train Loss : [0.48991] - Model Saved!\n",
      "\n",
      "Epoch [156], Loss1 : 1.219437, Loss2 : 0.485881, Train Loss : [0.48588] - Model Saved!\n",
      "\n",
      "Epoch [157], Loss1 : 1.204973, Loss2 : 0.481861, Train Loss : [0.48186] - Model Saved!\n",
      "\n",
      "Epoch [158], Loss1 : 1.216135, Loss2 : 0.477854, Train Loss : [0.47785] - Model Saved!\n",
      "\n",
      "Epoch [159], Loss1 : 1.231345, Loss2 : 0.473864, Train Loss : [0.47386] - Model Saved!\n",
      "\n",
      "Epoch [160], Loss1 : 1.219981, Loss2 : 0.469893, Train Loss : [0.46989] - Model Saved!\n",
      "\n",
      "Epoch [161], Loss1 : 1.216568, Loss2 : 0.465944, Train Loss : [0.46594] - Model Saved!\n",
      "\n",
      "Epoch [162], Loss1 : 1.233845, Loss2 : 0.462021, Train Loss : [0.46202] - Model Saved!\n",
      "\n",
      "Epoch [163], Loss1 : 1.248500, Loss2 : 0.458129, Train Loss : [0.45813] - Model Saved!\n",
      "\n",
      "Epoch [164], Loss1 : 1.200079, Loss2 : 0.454270, Train Loss : [0.45427] - Model Saved!\n",
      "\n",
      "Epoch [165], Loss1 : 1.216484, Loss2 : 0.450449, Train Loss : [0.45045] - Model Saved!\n",
      "\n",
      "Epoch [166], Loss1 : 1.210384, Loss2 : 0.446668, Train Loss : [0.44667] - Model Saved!\n",
      "\n",
      "Epoch [167], Loss1 : 1.203557, Loss2 : 0.442931, Train Loss : [0.44293] - Model Saved!\n",
      "\n",
      "Epoch [168], Loss1 : 1.204863, Loss2 : 0.439239, Train Loss : [0.43924] - Model Saved!\n",
      "\n",
      "Epoch [169], Loss1 : 1.197657, Loss2 : 0.435593, Train Loss : [0.43559] - Model Saved!\n",
      "\n",
      "Epoch [170], Loss1 : 1.224194, Loss2 : 0.431994, Train Loss : [0.43199] - Model Saved!\n",
      "\n",
      "Epoch [171], Loss1 : 1.229879, Loss2 : 0.428439, Train Loss : [0.42844] - Model Saved!\n",
      "\n",
      "Epoch [172], Loss1 : 1.182028, Loss2 : 0.424929, Train Loss : [0.42493] - Model Saved!\n",
      "\n",
      "Epoch [173], Loss1 : 1.210476, Loss2 : 0.421462, Train Loss : [0.42146] - Model Saved!\n",
      "\n",
      "Epoch [174], Loss1 : 1.225699, Loss2 : 0.418036, Train Loss : [0.41804] - Model Saved!\n",
      "\n",
      "Epoch [175], Loss1 : 1.235291, Loss2 : 0.414648, Train Loss : [0.41465] - Model Saved!\n",
      "\n",
      "Epoch [176], Loss1 : 1.238775, Loss2 : 0.411299, Train Loss : [0.41130] - Model Saved!\n",
      "\n",
      "Epoch [177], Loss1 : 1.222352, Loss2 : 0.407987, Train Loss : [0.40799] - Model Saved!\n",
      "\n",
      "Epoch [178], Loss1 : 1.217311, Loss2 : 0.404710, Train Loss : [0.40471] - Model Saved!\n",
      "\n",
      "Epoch [179], Loss1 : 1.214373, Loss2 : 0.401470, Train Loss : [0.40147] - Model Saved!\n",
      "\n",
      "Epoch [180], Loss1 : 1.236283, Loss2 : 0.398267, Train Loss : [0.39827] - Model Saved!\n",
      "\n",
      "Epoch [181], Loss1 : 1.190270, Loss2 : 0.395100, Train Loss : [0.39510] - Model Saved!\n",
      "\n",
      "Epoch [182], Loss1 : 1.221571, Loss2 : 0.391971, Train Loss : [0.39197] - Model Saved!\n",
      "\n",
      "Epoch [183], Loss1 : 1.207554, Loss2 : 0.388880, Train Loss : [0.38888] - Model Saved!\n",
      "\n",
      "Epoch [184], Loss1 : 1.214890, Loss2 : 0.385827, Train Loss : [0.38583] - Model Saved!\n",
      "\n",
      "Epoch [185], Loss1 : 1.201154, Loss2 : 0.382811, Train Loss : [0.38281] - Model Saved!\n",
      "\n",
      "Epoch [186], Loss1 : 1.206761, Loss2 : 0.379831, Train Loss : [0.37983] - Model Saved!\n",
      "\n",
      "Epoch [187], Loss1 : 1.214810, Loss2 : 0.376886, Train Loss : [0.37689] - Model Saved!\n",
      "\n",
      "Epoch [188], Loss1 : 1.204732, Loss2 : 0.373973, Train Loss : [0.37397] - Model Saved!\n",
      "\n",
      "Epoch [189], Loss1 : 1.203045, Loss2 : 0.371091, Train Loss : [0.37109] - Model Saved!\n",
      "\n",
      "Epoch [190], Loss1 : 1.189643, Loss2 : 0.368237, Train Loss : [0.36824] - Model Saved!\n",
      "\n",
      "Epoch [191], Loss1 : 1.232934, Loss2 : 0.365409, Train Loss : [0.36541] - Model Saved!\n",
      "\n",
      "Epoch [192], Loss1 : 1.207948, Loss2 : 0.362607, Train Loss : [0.36261] - Model Saved!\n",
      "\n",
      "Epoch [193], Loss1 : 1.212187, Loss2 : 0.359829, Train Loss : [0.35983] - Model Saved!\n",
      "\n",
      "Epoch [194], Loss1 : 1.221169, Loss2 : 0.357076, Train Loss : [0.35708] - Model Saved!\n",
      "\n",
      "Epoch [195], Loss1 : 1.213761, Loss2 : 0.354349, Train Loss : [0.35435] - Model Saved!\n",
      "\n",
      "Epoch [196], Loss1 : 1.183412, Loss2 : 0.351649, Train Loss : [0.35165] - Model Saved!\n",
      "\n",
      "Epoch [197], Loss1 : 1.189278, Loss2 : 0.348979, Train Loss : [0.34898] - Model Saved!\n",
      "\n",
      "Epoch [198], Loss1 : 1.196021, Loss2 : 0.346341, Train Loss : [0.34634] - Model Saved!\n",
      "\n",
      "Epoch [199], Loss1 : 1.234476, Loss2 : 0.343738, Train Loss : [0.34374] - Model Saved!\n",
      "\n",
      "Epoch [200], Loss1 : 1.203211, Loss2 : 0.341172, Train Loss : [0.34117] - Model Saved!\n",
      "\n",
      "Epoch [201], Loss1 : 1.214979, Loss2 : 0.338646, Train Loss : [0.33865] - Model Saved!\n",
      "\n",
      "Epoch [202], Loss1 : 1.212862, Loss2 : 0.336161, Train Loss : [0.33616] - Model Saved!\n",
      "\n",
      "Epoch [203], Loss1 : 1.182655, Loss2 : 0.333718, Train Loss : [0.33372] - Model Saved!\n",
      "\n",
      "Epoch [204], Loss1 : 1.217048, Loss2 : 0.331319, Train Loss : [0.33132] - Model Saved!\n",
      "\n",
      "Epoch [205], Loss1 : 1.219377, Loss2 : 0.328961, Train Loss : [0.32896] - Model Saved!\n",
      "\n",
      "Epoch [206], Loss1 : 1.195213, Loss2 : 0.326646, Train Loss : [0.32665] - Model Saved!\n",
      "\n",
      "Epoch [207], Loss1 : 1.228325, Loss2 : 0.324370, Train Loss : [0.32437] - Model Saved!\n",
      "\n",
      "Epoch [208], Loss1 : 1.191558, Loss2 : 0.322132, Train Loss : [0.32213] - Model Saved!\n",
      "\n",
      "Epoch [209], Loss1 : 1.215212, Loss2 : 0.319929, Train Loss : [0.31993] - Model Saved!\n",
      "\n",
      "Epoch [210], Loss1 : 1.214558, Loss2 : 0.317758, Train Loss : [0.31776] - Model Saved!\n",
      "\n",
      "Epoch [211], Loss1 : 1.203269, Loss2 : 0.315616, Train Loss : [0.31562] - Model Saved!\n",
      "\n",
      "Epoch [212], Loss1 : 1.231241, Loss2 : 0.313499, Train Loss : [0.31350] - Model Saved!\n",
      "\n",
      "Epoch [213], Loss1 : 1.213132, Loss2 : 0.311406, Train Loss : [0.31141] - Model Saved!\n",
      "\n",
      "Epoch [214], Loss1 : 1.205402, Loss2 : 0.309333, Train Loss : [0.30933] - Model Saved!\n",
      "\n",
      "Epoch [215], Loss1 : 1.208289, Loss2 : 0.307277, Train Loss : [0.30728] - Model Saved!\n",
      "\n",
      "Epoch [216], Loss1 : 1.196390, Loss2 : 0.305238, Train Loss : [0.30524] - Model Saved!\n",
      "\n",
      "Epoch [217], Loss1 : 1.198998, Loss2 : 0.303214, Train Loss : [0.30321] - Model Saved!\n",
      "\n",
      "Epoch [218], Loss1 : 1.226596, Loss2 : 0.301204, Train Loss : [0.30120] - Model Saved!\n",
      "\n",
      "Epoch [219], Loss1 : 1.209350, Loss2 : 0.299207, Train Loss : [0.29921] - Model Saved!\n",
      "\n",
      "Epoch [220], Loss1 : 1.227293, Loss2 : 0.297223, Train Loss : [0.29722] - Model Saved!\n",
      "\n",
      "Epoch [221], Loss1 : 1.227862, Loss2 : 0.295252, Train Loss : [0.29525] - Model Saved!\n",
      "\n",
      "Epoch [222], Loss1 : 1.222165, Loss2 : 0.293296, Train Loss : [0.29330] - Model Saved!\n",
      "\n",
      "Epoch [223], Loss1 : 1.215141, Loss2 : 0.291353, Train Loss : [0.29135] - Model Saved!\n",
      "\n",
      "Epoch [224], Loss1 : 1.216081, Loss2 : 0.289426, Train Loss : [0.28943] - Model Saved!\n",
      "\n",
      "Epoch [225], Loss1 : 1.224052, Loss2 : 0.287513, Train Loss : [0.28751] - Model Saved!\n",
      "\n",
      "Epoch [226], Loss1 : 1.223392, Loss2 : 0.285617, Train Loss : [0.28562] - Model Saved!\n",
      "\n",
      "Epoch [227], Loss1 : 1.214402, Loss2 : 0.283736, Train Loss : [0.28374] - Model Saved!\n",
      "\n",
      "Epoch [228], Loss1 : 1.217383, Loss2 : 0.281871, Train Loss : [0.28187] - Model Saved!\n",
      "\n",
      "Epoch [229], Loss1 : 1.189233, Loss2 : 0.280022, Train Loss : [0.28002] - Model Saved!\n",
      "\n",
      "Epoch [230], Loss1 : 1.217717, Loss2 : 0.278188, Train Loss : [0.27819] - Model Saved!\n",
      "\n",
      "Epoch [231], Loss1 : 1.208951, Loss2 : 0.276370, Train Loss : [0.27637] - Model Saved!\n",
      "\n",
      "Epoch [232], Loss1 : 1.202791, Loss2 : 0.274564, Train Loss : [0.27456] - Model Saved!\n",
      "\n",
      "Epoch [233], Loss1 : 1.228924, Loss2 : 0.272771, Train Loss : [0.27277] - Model Saved!\n",
      "\n",
      "Epoch [234], Loss1 : 1.196949, Loss2 : 0.270988, Train Loss : [0.27099] - Model Saved!\n",
      "\n",
      "Epoch [235], Loss1 : 1.244067, Loss2 : 0.269214, Train Loss : [0.26921] - Model Saved!\n",
      "\n",
      "Epoch [236], Loss1 : 1.234770, Loss2 : 0.267445, Train Loss : [0.26745] - Model Saved!\n",
      "\n",
      "Epoch [237], Loss1 : 1.235415, Loss2 : 0.265681, Train Loss : [0.26568] - Model Saved!\n",
      "\n",
      "Epoch [238], Loss1 : 1.232866, Loss2 : 0.263919, Train Loss : [0.26392] - Model Saved!\n",
      "\n",
      "Epoch [239], Loss1 : 1.233982, Loss2 : 0.262158, Train Loss : [0.26216] - Model Saved!\n",
      "\n",
      "Epoch [240], Loss1 : 1.201850, Loss2 : 0.260395, Train Loss : [0.26039] - Model Saved!\n",
      "\n",
      "Epoch [241], Loss1 : 1.211522, Loss2 : 0.258629, Train Loss : [0.25863] - Model Saved!\n",
      "\n",
      "Epoch [242], Loss1 : 1.216093, Loss2 : 0.256860, Train Loss : [0.25686] - Model Saved!\n",
      "\n",
      "Epoch [243], Loss1 : 1.227184, Loss2 : 0.255088, Train Loss : [0.25509] - Model Saved!\n",
      "\n",
      "Epoch [244], Loss1 : 1.215416, Loss2 : 0.253311, Train Loss : [0.25331] - Model Saved!\n",
      "\n",
      "Epoch [245], Loss1 : 1.224637, Loss2 : 0.251530, Train Loss : [0.25153] - Model Saved!\n",
      "\n",
      "Epoch [246], Loss1 : 1.195181, Loss2 : 0.249745, Train Loss : [0.24974] - Model Saved!\n",
      "\n",
      "Epoch [247], Loss1 : 1.210338, Loss2 : 0.247955, Train Loss : [0.24795] - Model Saved!\n",
      "\n",
      "Epoch [248], Loss1 : 1.216100, Loss2 : 0.246160, Train Loss : [0.24616] - Model Saved!\n",
      "\n",
      "Epoch [249], Loss1 : 1.210706, Loss2 : 0.244361, Train Loss : [0.24436] - Model Saved!\n",
      "\n",
      "Epoch [250], Loss1 : 1.226827, Loss2 : 0.242557, Train Loss : [0.24256] - Model Saved!\n",
      "\n",
      "Epoch [251], Loss1 : 1.225037, Loss2 : 0.240747, Train Loss : [0.24075] - Model Saved!\n",
      "\n",
      "Epoch [252], Loss1 : 1.249764, Loss2 : 0.238931, Train Loss : [0.23893] - Model Saved!\n",
      "\n",
      "Epoch [253], Loss1 : 1.230945, Loss2 : 0.237110, Train Loss : [0.23711] - Model Saved!\n",
      "\n",
      "Epoch [254], Loss1 : 1.192901, Loss2 : 0.235281, Train Loss : [0.23528] - Model Saved!\n",
      "\n",
      "Epoch [255], Loss1 : 1.242191, Loss2 : 0.233447, Train Loss : [0.23345] - Model Saved!\n",
      "\n",
      "Epoch [256], Loss1 : 1.214093, Loss2 : 0.231607, Train Loss : [0.23161] - Model Saved!\n",
      "\n",
      "Epoch [257], Loss1 : 1.205451, Loss2 : 0.229762, Train Loss : [0.22976] - Model Saved!\n",
      "\n",
      "Epoch [258], Loss1 : 1.207963, Loss2 : 0.227913, Train Loss : [0.22791] - Model Saved!\n",
      "\n",
      "Epoch [259], Loss1 : 1.169145, Loss2 : 0.226063, Train Loss : [0.22606] - Model Saved!\n",
      "\n",
      "Epoch [260], Loss1 : 1.247450, Loss2 : 0.224213, Train Loss : [0.22421] - Model Saved!\n",
      "\n",
      "Epoch [261], Loss1 : 1.218476, Loss2 : 0.222367, Train Loss : [0.22237] - Model Saved!\n",
      "\n",
      "Epoch [262], Loss1 : 1.221895, Loss2 : 0.220528, Train Loss : [0.22053] - Model Saved!\n",
      "\n",
      "Epoch [263], Loss1 : 1.183725, Loss2 : 0.218700, Train Loss : [0.21870] - Model Saved!\n",
      "\n",
      "Epoch [264], Loss1 : 1.215316, Loss2 : 0.216887, Train Loss : [0.21689] - Model Saved!\n",
      "\n",
      "Epoch [265], Loss1 : 1.223428, Loss2 : 0.215092, Train Loss : [0.21509] - Model Saved!\n",
      "\n",
      "Epoch [266], Loss1 : 1.230371, Loss2 : 0.213318, Train Loss : [0.21332] - Model Saved!\n",
      "\n",
      "Epoch [267], Loss1 : 1.221198, Loss2 : 0.211570, Train Loss : [0.21157] - Model Saved!\n",
      "\n",
      "Epoch [268], Loss1 : 1.198413, Loss2 : 0.209849, Train Loss : [0.20985] - Model Saved!\n",
      "\n",
      "Epoch [269], Loss1 : 1.229002, Loss2 : 0.208157, Train Loss : [0.20816] - Model Saved!\n",
      "\n",
      "Epoch [270], Loss1 : 1.204017, Loss2 : 0.206494, Train Loss : [0.20649] - Model Saved!\n",
      "\n",
      "Epoch [271], Loss1 : 1.237064, Loss2 : 0.204860, Train Loss : [0.20486] - Model Saved!\n",
      "\n",
      "Epoch [272], Loss1 : 1.231773, Loss2 : 0.203254, Train Loss : [0.20325] - Model Saved!\n",
      "\n",
      "Epoch [273], Loss1 : 1.210062, Loss2 : 0.201672, Train Loss : [0.20167] - Model Saved!\n",
      "\n",
      "Epoch [274], Loss1 : 1.190562, Loss2 : 0.200113, Train Loss : [0.20011] - Model Saved!\n",
      "\n",
      "Epoch [275], Loss1 : 1.203055, Loss2 : 0.198573, Train Loss : [0.19857] - Model Saved!\n",
      "\n",
      "Epoch [276], Loss1 : 1.217576, Loss2 : 0.197047, Train Loss : [0.19705] - Model Saved!\n",
      "\n",
      "Epoch [277], Loss1 : 1.243152, Loss2 : 0.195534, Train Loss : [0.19553] - Model Saved!\n",
      "\n",
      "Epoch [278], Loss1 : 1.224518, Loss2 : 0.194028, Train Loss : [0.19403] - Model Saved!\n",
      "\n",
      "Epoch [279], Loss1 : 1.180281, Loss2 : 0.192529, Train Loss : [0.19253] - Model Saved!\n",
      "\n",
      "Epoch [280], Loss1 : 1.204680, Loss2 : 0.191032, Train Loss : [0.19103] - Model Saved!\n",
      "\n",
      "Epoch [281], Loss1 : 1.235368, Loss2 : 0.189536, Train Loss : [0.18954] - Model Saved!\n",
      "\n",
      "Epoch [282], Loss1 : 1.217349, Loss2 : 0.188040, Train Loss : [0.18804] - Model Saved!\n",
      "\n",
      "Epoch [283], Loss1 : 1.221842, Loss2 : 0.186542, Train Loss : [0.18654] - Model Saved!\n",
      "\n",
      "Epoch [284], Loss1 : 1.251605, Loss2 : 0.185040, Train Loss : [0.18504] - Model Saved!\n",
      "\n",
      "Epoch [285], Loss1 : 1.223874, Loss2 : 0.183534, Train Loss : [0.18353] - Model Saved!\n",
      "\n",
      "Epoch [286], Loss1 : 1.238211, Loss2 : 0.182024, Train Loss : [0.18202] - Model Saved!\n",
      "\n",
      "Epoch [287], Loss1 : 1.229271, Loss2 : 0.180509, Train Loss : [0.18051] - Model Saved!\n",
      "\n",
      "Epoch [288], Loss1 : 1.202336, Loss2 : 0.178989, Train Loss : [0.17899] - Model Saved!\n",
      "\n",
      "Epoch [289], Loss1 : 1.206999, Loss2 : 0.177464, Train Loss : [0.17746] - Model Saved!\n",
      "\n",
      "Epoch [290], Loss1 : 1.205536, Loss2 : 0.175934, Train Loss : [0.17593] - Model Saved!\n",
      "\n",
      "Epoch [291], Loss1 : 1.218573, Loss2 : 0.174401, Train Loss : [0.17440] - Model Saved!\n",
      "\n",
      "Epoch [292], Loss1 : 1.217057, Loss2 : 0.172865, Train Loss : [0.17286] - Model Saved!\n",
      "\n",
      "Epoch [293], Loss1 : 1.213867, Loss2 : 0.171327, Train Loss : [0.17133] - Model Saved!\n",
      "\n",
      "Epoch [294], Loss1 : 1.211812, Loss2 : 0.169789, Train Loss : [0.16979] - Model Saved!\n",
      "\n",
      "Epoch [295], Loss1 : 1.202525, Loss2 : 0.168252, Train Loss : [0.16825] - Model Saved!\n",
      "\n",
      "Epoch [296], Loss1 : 1.228408, Loss2 : 0.166717, Train Loss : [0.16672] - Model Saved!\n",
      "\n",
      "Epoch [297], Loss1 : 1.236503, Loss2 : 0.165187, Train Loss : [0.16519] - Model Saved!\n",
      "\n",
      "Epoch [298], Loss1 : 1.257558, Loss2 : 0.163661, Train Loss : [0.16366] - Model Saved!\n",
      "\n",
      "Epoch [299], Loss1 : 1.199441, Loss2 : 0.162142, Train Loss : [0.16214] - Model Saved!\n",
      "\n",
      "Epoch [300], Loss1 : 1.203535, Loss2 : 0.160630, Train Loss : [0.16063] - Model Saved!\n",
      "\n",
      "Epoch [301], Loss1 : 1.217931, Loss2 : 0.159126, Train Loss : [0.15913] - Model Saved!\n",
      "\n",
      "Epoch [302], Loss1 : 1.215951, Loss2 : 0.157631, Train Loss : [0.15763] - Model Saved!\n",
      "\n",
      "Epoch [303], Loss1 : 1.231623, Loss2 : 0.156145, Train Loss : [0.15615] - Model Saved!\n",
      "\n",
      "Epoch [304], Loss1 : 1.217116, Loss2 : 0.154669, Train Loss : [0.15467] - Model Saved!\n",
      "\n",
      "Epoch [305], Loss1 : 1.205902, Loss2 : 0.153203, Train Loss : [0.15320] - Model Saved!\n",
      "\n",
      "Epoch [306], Loss1 : 1.221764, Loss2 : 0.151747, Train Loss : [0.15175] - Model Saved!\n",
      "\n",
      "Epoch [307], Loss1 : 1.208070, Loss2 : 0.150301, Train Loss : [0.15030] - Model Saved!\n",
      "\n",
      "Epoch [308], Loss1 : 1.224748, Loss2 : 0.148866, Train Loss : [0.14887] - Model Saved!\n",
      "\n",
      "Epoch [309], Loss1 : 1.222803, Loss2 : 0.147442, Train Loss : [0.14744] - Model Saved!\n",
      "\n",
      "Epoch [310], Loss1 : 1.212732, Loss2 : 0.146030, Train Loss : [0.14603] - Model Saved!\n",
      "\n",
      "Epoch [311], Loss1 : 1.203578, Loss2 : 0.144632, Train Loss : [0.14463] - Model Saved!\n",
      "\n",
      "Epoch [312], Loss1 : 1.240118, Loss2 : 0.143247, Train Loss : [0.14325] - Model Saved!\n",
      "\n",
      "Epoch [313], Loss1 : 1.207057, Loss2 : 0.141877, Train Loss : [0.14188] - Model Saved!\n",
      "\n",
      "Epoch [314], Loss1 : 1.262386, Loss2 : 0.140525, Train Loss : [0.14053] - Model Saved!\n",
      "\n",
      "Epoch [315], Loss1 : 1.219945, Loss2 : 0.139192, Train Loss : [0.13919] - Model Saved!\n",
      "\n",
      "Epoch [316], Loss1 : 1.246036, Loss2 : 0.137879, Train Loss : [0.13788] - Model Saved!\n",
      "\n",
      "Epoch [317], Loss1 : 1.220653, Loss2 : 0.136588, Train Loss : [0.13659] - Model Saved!\n",
      "\n",
      "Epoch [318], Loss1 : 1.219069, Loss2 : 0.135322, Train Loss : [0.13532] - Model Saved!\n",
      "\n",
      "Epoch [319], Loss1 : 1.235079, Loss2 : 0.134081, Train Loss : [0.13408] - Model Saved!\n",
      "\n",
      "Epoch [320], Loss1 : 1.216930, Loss2 : 0.132866, Train Loss : [0.13287] - Model Saved!\n",
      "\n",
      "Epoch [321], Loss1 : 1.205086, Loss2 : 0.131678, Train Loss : [0.13168] - Model Saved!\n",
      "\n",
      "Epoch [322], Loss1 : 1.200985, Loss2 : 0.130517, Train Loss : [0.13052] - Model Saved!\n",
      "\n",
      "Epoch [323], Loss1 : 1.230240, Loss2 : 0.129383, Train Loss : [0.12938] - Model Saved!\n",
      "\n",
      "Epoch [324], Loss1 : 1.174834, Loss2 : 0.128275, Train Loss : [0.12827] - Model Saved!\n",
      "\n",
      "Epoch [325], Loss1 : 1.195157, Loss2 : 0.127191, Train Loss : [0.12719] - Model Saved!\n",
      "\n",
      "Epoch [326], Loss1 : 1.207283, Loss2 : 0.126131, Train Loss : [0.12613] - Model Saved!\n",
      "\n",
      "Epoch [327], Loss1 : 1.215011, Loss2 : 0.125093, Train Loss : [0.12509] - Model Saved!\n",
      "\n",
      "Epoch [328], Loss1 : 1.235974, Loss2 : 0.124076, Train Loss : [0.12408] - Model Saved!\n",
      "\n",
      "Epoch [329], Loss1 : 1.204401, Loss2 : 0.123080, Train Loss : [0.12308] - Model Saved!\n",
      "\n",
      "Epoch [330], Loss1 : 1.204575, Loss2 : 0.122104, Train Loss : [0.12210] - Model Saved!\n",
      "\n",
      "Epoch [331], Loss1 : 1.206335, Loss2 : 0.121148, Train Loss : [0.12115] - Model Saved!\n",
      "\n",
      "Epoch [332], Loss1 : 1.241100, Loss2 : 0.120211, Train Loss : [0.12021] - Model Saved!\n",
      "\n",
      "Epoch [333], Loss1 : 1.249849, Loss2 : 0.119295, Train Loss : [0.11929] - Model Saved!\n",
      "\n",
      "Epoch [334], Loss1 : 1.184725, Loss2 : 0.118398, Train Loss : [0.11840] - Model Saved!\n",
      "\n",
      "Epoch [335], Loss1 : 1.229756, Loss2 : 0.117521, Train Loss : [0.11752] - Model Saved!\n",
      "\n",
      "Epoch [336], Loss1 : 1.204042, Loss2 : 0.116664, Train Loss : [0.11666] - Model Saved!\n",
      "\n",
      "Epoch [337], Loss1 : 1.236111, Loss2 : 0.115825, Train Loss : [0.11582] - Model Saved!\n",
      "\n",
      "Epoch [338], Loss1 : 1.243471, Loss2 : 0.115003, Train Loss : [0.11500] - Model Saved!\n",
      "\n",
      "Epoch [339], Loss1 : 1.218194, Loss2 : 0.114197, Train Loss : [0.11420] - Model Saved!\n",
      "\n",
      "Epoch [340], Loss1 : 1.217125, Loss2 : 0.113405, Train Loss : [0.11341] - Model Saved!\n",
      "\n",
      "Epoch [341], Loss1 : 1.202218, Loss2 : 0.112625, Train Loss : [0.11263] - Model Saved!\n",
      "\n",
      "Epoch [342], Loss1 : 1.205231, Loss2 : 0.111855, Train Loss : [0.11186] - Model Saved!\n",
      "\n",
      "Epoch [343], Loss1 : 1.227832, Loss2 : 0.111093, Train Loss : [0.11109] - Model Saved!\n",
      "\n",
      "Epoch [344], Loss1 : 1.250075, Loss2 : 0.110337, Train Loss : [0.11034] - Model Saved!\n",
      "\n",
      "Epoch [345], Loss1 : 1.201761, Loss2 : 0.109585, Train Loss : [0.10959] - Model Saved!\n",
      "\n",
      "Epoch [346], Loss1 : 1.217926, Loss2 : 0.108837, Train Loss : [0.10884] - Model Saved!\n",
      "\n",
      "Epoch [347], Loss1 : 1.218541, Loss2 : 0.108091, Train Loss : [0.10809] - Model Saved!\n",
      "\n",
      "Epoch [348], Loss1 : 1.217191, Loss2 : 0.107348, Train Loss : [0.10735] - Model Saved!\n",
      "\n",
      "Epoch [349], Loss1 : 1.220090, Loss2 : 0.106608, Train Loss : [0.10661] - Model Saved!\n",
      "\n",
      "Epoch [350], Loss1 : 1.225629, Loss2 : 0.105870, Train Loss : [0.10587] - Model Saved!\n",
      "\n",
      "Epoch [351], Loss1 : 1.215035, Loss2 : 0.105137, Train Loss : [0.10514] - Model Saved!\n",
      "\n",
      "Epoch [352], Loss1 : 1.225429, Loss2 : 0.104408, Train Loss : [0.10441] - Model Saved!\n",
      "\n",
      "Epoch [353], Loss1 : 1.235473, Loss2 : 0.103685, Train Loss : [0.10368] - Model Saved!\n",
      "\n",
      "Epoch [354], Loss1 : 1.228096, Loss2 : 0.102970, Train Loss : [0.10297] - Model Saved!\n",
      "\n",
      "Epoch [355], Loss1 : 1.185012, Loss2 : 0.102263, Train Loss : [0.10226] - Model Saved!\n",
      "\n",
      "Epoch [356], Loss1 : 1.231484, Loss2 : 0.101567, Train Loss : [0.10157] - Model Saved!\n",
      "\n",
      "Epoch [357], Loss1 : 1.230673, Loss2 : 0.100883, Train Loss : [0.10088] - Model Saved!\n",
      "\n",
      "Epoch [358], Loss1 : 1.226414, Loss2 : 0.100213, Train Loss : [0.10021] - Model Saved!\n",
      "\n",
      "Epoch [359], Loss1 : 1.235949, Loss2 : 0.099557, Train Loss : [0.09956] - Model Saved!\n",
      "\n",
      "Epoch [360], Loss1 : 1.222649, Loss2 : 0.098917, Train Loss : [0.09892] - Model Saved!\n",
      "\n",
      "Epoch [361], Loss1 : 1.239258, Loss2 : 0.098294, Train Loss : [0.09829] - Model Saved!\n",
      "\n",
      "Epoch [362], Loss1 : 1.231354, Loss2 : 0.097688, Train Loss : [0.09769] - Model Saved!\n",
      "\n",
      "Epoch [363], Loss1 : 1.227063, Loss2 : 0.097098, Train Loss : [0.09710] - Model Saved!\n",
      "\n",
      "Epoch [364], Loss1 : 1.237383, Loss2 : 0.096525, Train Loss : [0.09653] - Model Saved!\n",
      "\n",
      "Epoch [365], Loss1 : 1.214533, Loss2 : 0.095967, Train Loss : [0.09597] - Model Saved!\n",
      "\n",
      "Epoch [366], Loss1 : 1.226871, Loss2 : 0.095424, Train Loss : [0.09542] - Model Saved!\n",
      "\n",
      "Epoch [367], Loss1 : 1.227438, Loss2 : 0.094893, Train Loss : [0.09489] - Model Saved!\n",
      "\n",
      "Epoch [368], Loss1 : 1.239237, Loss2 : 0.094374, Train Loss : [0.09437] - Model Saved!\n",
      "\n",
      "Epoch [369], Loss1 : 1.190498, Loss2 : 0.093864, Train Loss : [0.09386] - Model Saved!\n",
      "\n",
      "Epoch [370], Loss1 : 1.221468, Loss2 : 0.093362, Train Loss : [0.09336] - Model Saved!\n",
      "\n",
      "Epoch [371], Loss1 : 1.258748, Loss2 : 0.092867, Train Loss : [0.09287] - Model Saved!\n",
      "\n",
      "Epoch [372], Loss1 : 1.215429, Loss2 : 0.092377, Train Loss : [0.09238] - Model Saved!\n",
      "\n",
      "Epoch [373], Loss1 : 1.203150, Loss2 : 0.091891, Train Loss : [0.09189] - Model Saved!\n",
      "\n",
      "Epoch [374], Loss1 : 1.197118, Loss2 : 0.091410, Train Loss : [0.09141] - Model Saved!\n",
      "\n",
      "Epoch [375], Loss1 : 1.216878, Loss2 : 0.090931, Train Loss : [0.09093] - Model Saved!\n",
      "\n",
      "Epoch [376], Loss1 : 1.207367, Loss2 : 0.090455, Train Loss : [0.09046] - Model Saved!\n",
      "\n",
      "Epoch [377], Loss1 : 1.230296, Loss2 : 0.089982, Train Loss : [0.08998] - Model Saved!\n",
      "\n",
      "Epoch [378], Loss1 : 1.224155, Loss2 : 0.089510, Train Loss : [0.08951] - Model Saved!\n",
      "\n",
      "Epoch [379], Loss1 : 1.200146, Loss2 : 0.089038, Train Loss : [0.08904] - Model Saved!\n",
      "\n",
      "Epoch [380], Loss1 : 1.197027, Loss2 : 0.088568, Train Loss : [0.08857] - Model Saved!\n",
      "\n",
      "Epoch [381], Loss1 : 1.230914, Loss2 : 0.088097, Train Loss : [0.08810] - Model Saved!\n",
      "\n",
      "Epoch [382], Loss1 : 1.246358, Loss2 : 0.087626, Train Loss : [0.08763] - Model Saved!\n",
      "\n",
      "Epoch [383], Loss1 : 1.229123, Loss2 : 0.087152, Train Loss : [0.08715] - Model Saved!\n",
      "\n",
      "Epoch [384], Loss1 : 1.223607, Loss2 : 0.086677, Train Loss : [0.08668] - Model Saved!\n",
      "\n",
      "Epoch [385], Loss1 : 1.217289, Loss2 : 0.086199, Train Loss : [0.08620] - Model Saved!\n",
      "\n",
      "Epoch [386], Loss1 : 1.228565, Loss2 : 0.085718, Train Loss : [0.08572] - Model Saved!\n",
      "\n",
      "Epoch [387], Loss1 : 1.208361, Loss2 : 0.085232, Train Loss : [0.08523] - Model Saved!\n",
      "\n",
      "Epoch [388], Loss1 : 1.186136, Loss2 : 0.084742, Train Loss : [0.08474] - Model Saved!\n",
      "\n",
      "Epoch [389], Loss1 : 1.201075, Loss2 : 0.084248, Train Loss : [0.08425] - Model Saved!\n",
      "\n",
      "Epoch [390], Loss1 : 1.225233, Loss2 : 0.083749, Train Loss : [0.08375] - Model Saved!\n",
      "\n",
      "Epoch [391], Loss1 : 1.244310, Loss2 : 0.083246, Train Loss : [0.08325] - Model Saved!\n",
      "\n",
      "Epoch [392], Loss1 : 1.202411, Loss2 : 0.082738, Train Loss : [0.08274] - Model Saved!\n",
      "\n",
      "Epoch [393], Loss1 : 1.227058, Loss2 : 0.082227, Train Loss : [0.08223] - Model Saved!\n",
      "\n",
      "Epoch [394], Loss1 : 1.204038, Loss2 : 0.081712, Train Loss : [0.08171] - Model Saved!\n",
      "\n",
      "Epoch [395], Loss1 : 1.199704, Loss2 : 0.081196, Train Loss : [0.08120] - Model Saved!\n",
      "\n",
      "Epoch [396], Loss1 : 1.240973, Loss2 : 0.080678, Train Loss : [0.08068] - Model Saved!\n",
      "\n",
      "Epoch [397], Loss1 : 1.217313, Loss2 : 0.080161, Train Loss : [0.08016] - Model Saved!\n",
      "\n",
      "Epoch [398], Loss1 : 1.205910, Loss2 : 0.079645, Train Loss : [0.07964] - Model Saved!\n",
      "\n",
      "Epoch [399], Loss1 : 1.251404, Loss2 : 0.079132, Train Loss : [0.07913] - Model Saved!\n",
      "\n",
      "Epoch [400], Loss1 : 1.233595, Loss2 : 0.078625, Train Loss : [0.07862] - Model Saved!\n",
      "\n",
      "Epoch [401], Loss1 : 1.220358, Loss2 : 0.078123, Train Loss : [0.07812] - Model Saved!\n",
      "\n",
      "Epoch [402], Loss1 : 1.230336, Loss2 : 0.077630, Train Loss : [0.07763] - Model Saved!\n",
      "\n",
      "Epoch [403], Loss1 : 1.219776, Loss2 : 0.077145, Train Loss : [0.07715] - Model Saved!\n",
      "\n",
      "Epoch [404], Loss1 : 1.220502, Loss2 : 0.076671, Train Loss : [0.07667] - Model Saved!\n",
      "\n",
      "Epoch [405], Loss1 : 1.165289, Loss2 : 0.076207, Train Loss : [0.07621] - Model Saved!\n",
      "\n",
      "Epoch [406], Loss1 : 1.230584, Loss2 : 0.075755, Train Loss : [0.07576] - Model Saved!\n",
      "\n",
      "Epoch [407], Loss1 : 1.243296, Loss2 : 0.075314, Train Loss : [0.07531] - Model Saved!\n",
      "\n",
      "Epoch [408], Loss1 : 1.214767, Loss2 : 0.074883, Train Loss : [0.07488] - Model Saved!\n",
      "\n",
      "Epoch [409], Loss1 : 1.204157, Loss2 : 0.074461, Train Loss : [0.07446] - Model Saved!\n",
      "\n",
      "Epoch [410], Loss1 : 1.231744, Loss2 : 0.074046, Train Loss : [0.07405] - Model Saved!\n",
      "\n",
      "Epoch [411], Loss1 : 1.213819, Loss2 : 0.073637, Train Loss : [0.07364] - Model Saved!\n",
      "\n",
      "Epoch [412], Loss1 : 1.238068, Loss2 : 0.073232, Train Loss : [0.07323] - Model Saved!\n",
      "\n",
      "Epoch [413], Loss1 : 1.203166, Loss2 : 0.072828, Train Loss : [0.07283] - Model Saved!\n",
      "\n",
      "Epoch [414], Loss1 : 1.237344, Loss2 : 0.072424, Train Loss : [0.07242] - Model Saved!\n",
      "\n",
      "Epoch [415], Loss1 : 1.214843, Loss2 : 0.072018, Train Loss : [0.07202] - Model Saved!\n",
      "\n",
      "Epoch [416], Loss1 : 1.226639, Loss2 : 0.071609, Train Loss : [0.07161] - Model Saved!\n",
      "\n",
      "Epoch [417], Loss1 : 1.209231, Loss2 : 0.071195, Train Loss : [0.07120] - Model Saved!\n",
      "\n",
      "Epoch [418], Loss1 : 1.212068, Loss2 : 0.070777, Train Loss : [0.07078] - Model Saved!\n",
      "\n",
      "Epoch [419], Loss1 : 1.236428, Loss2 : 0.070354, Train Loss : [0.07035] - Model Saved!\n",
      "\n",
      "Epoch [420], Loss1 : 1.224457, Loss2 : 0.069926, Train Loss : [0.06993] - Model Saved!\n",
      "\n",
      "Epoch [421], Loss1 : 1.218381, Loss2 : 0.069493, Train Loss : [0.06949] - Model Saved!\n",
      "\n",
      "Epoch [422], Loss1 : 1.214679, Loss2 : 0.069057, Train Loss : [0.06906] - Model Saved!\n",
      "\n",
      "Epoch [423], Loss1 : 1.223856, Loss2 : 0.068618, Train Loss : [0.06862] - Model Saved!\n",
      "\n",
      "Epoch [424], Loss1 : 1.221813, Loss2 : 0.068177, Train Loss : [0.06818] - Model Saved!\n",
      "\n",
      "Epoch [425], Loss1 : 1.216150, Loss2 : 0.067734, Train Loss : [0.06773] - Model Saved!\n",
      "\n",
      "Epoch [426], Loss1 : 1.231527, Loss2 : 0.067290, Train Loss : [0.06729] - Model Saved!\n",
      "\n",
      "Epoch [427], Loss1 : 1.215974, Loss2 : 0.066847, Train Loss : [0.06685] - Model Saved!\n",
      "\n",
      "Epoch [428], Loss1 : 1.244111, Loss2 : 0.066405, Train Loss : [0.06641] - Model Saved!\n",
      "\n",
      "Epoch [429], Loss1 : 1.240120, Loss2 : 0.065966, Train Loss : [0.06597] - Model Saved!\n",
      "\n",
      "Epoch [430], Loss1 : 1.235773, Loss2 : 0.065530, Train Loss : [0.06553] - Model Saved!\n",
      "\n",
      "Epoch [431], Loss1 : 1.199738, Loss2 : 0.065098, Train Loss : [0.06510] - Model Saved!\n",
      "\n",
      "Epoch [432], Loss1 : 1.254081, Loss2 : 0.064672, Train Loss : [0.06467] - Model Saved!\n",
      "\n",
      "Epoch [433], Loss1 : 1.218692, Loss2 : 0.064252, Train Loss : [0.06425] - Model Saved!\n",
      "\n",
      "Epoch [434], Loss1 : 1.223916, Loss2 : 0.063839, Train Loss : [0.06384] - Model Saved!\n",
      "\n",
      "Epoch [435], Loss1 : 1.212420, Loss2 : 0.063435, Train Loss : [0.06344] - Model Saved!\n",
      "\n",
      "Epoch [436], Loss1 : 1.169037, Loss2 : 0.063040, Train Loss : [0.06304] - Model Saved!\n",
      "\n",
      "Epoch [437], Loss1 : 1.242294, Loss2 : 0.062654, Train Loss : [0.06265] - Model Saved!\n",
      "\n",
      "Epoch [438], Loss1 : 1.216253, Loss2 : 0.062277, Train Loss : [0.06228] - Model Saved!\n",
      "\n",
      "Epoch [439], Loss1 : 1.212168, Loss2 : 0.061909, Train Loss : [0.06191] - Model Saved!\n",
      "\n",
      "Epoch [440], Loss1 : 1.200600, Loss2 : 0.061550, Train Loss : [0.06155] - Model Saved!\n",
      "\n",
      "Epoch [441], Loss1 : 1.227267, Loss2 : 0.061198, Train Loss : [0.06120] - Model Saved!\n",
      "\n",
      "Epoch [442], Loss1 : 1.184481, Loss2 : 0.060854, Train Loss : [0.06085] - Model Saved!\n",
      "\n",
      "Epoch [443], Loss1 : 1.213532, Loss2 : 0.060516, Train Loss : [0.06052] - Model Saved!\n",
      "\n",
      "Epoch [444], Loss1 : 1.251893, Loss2 : 0.060183, Train Loss : [0.06018] - Model Saved!\n",
      "\n",
      "Epoch [445], Loss1 : 1.218535, Loss2 : 0.059853, Train Loss : [0.05985] - Model Saved!\n",
      "\n",
      "Epoch [446], Loss1 : 1.200961, Loss2 : 0.059526, Train Loss : [0.05953] - Model Saved!\n",
      "\n",
      "Epoch [447], Loss1 : 1.208631, Loss2 : 0.059201, Train Loss : [0.05920] - Model Saved!\n",
      "\n",
      "Epoch [448], Loss1 : 1.238309, Loss2 : 0.058876, Train Loss : [0.05888] - Model Saved!\n",
      "\n",
      "Epoch [449], Loss1 : 1.205519, Loss2 : 0.058552, Train Loss : [0.05855] - Model Saved!\n",
      "\n",
      "Epoch [450], Loss1 : 1.188457, Loss2 : 0.058227, Train Loss : [0.05823] - Model Saved!\n",
      "\n",
      "Epoch [451], Loss1 : 1.244137, Loss2 : 0.057902, Train Loss : [0.05790] - Model Saved!\n",
      "\n",
      "Epoch [452], Loss1 : 1.230021, Loss2 : 0.057575, Train Loss : [0.05757] - Model Saved!\n",
      "\n",
      "Epoch [453], Loss1 : 1.181516, Loss2 : 0.057246, Train Loss : [0.05725] - Model Saved!\n",
      "\n",
      "Epoch [454], Loss1 : 1.194057, Loss2 : 0.056916, Train Loss : [0.05692] - Model Saved!\n",
      "\n",
      "Epoch [455], Loss1 : 1.206796, Loss2 : 0.056584, Train Loss : [0.05658] - Model Saved!\n",
      "\n",
      "Epoch [456], Loss1 : 1.198871, Loss2 : 0.056251, Train Loss : [0.05625] - Model Saved!\n",
      "\n",
      "Epoch [457], Loss1 : 1.189744, Loss2 : 0.055916, Train Loss : [0.05592] - Model Saved!\n",
      "\n",
      "Epoch [458], Loss1 : 1.254611, Loss2 : 0.055580, Train Loss : [0.05558] - Model Saved!\n",
      "\n",
      "Epoch [459], Loss1 : 1.224119, Loss2 : 0.055243, Train Loss : [0.05524] - Model Saved!\n",
      "\n",
      "Epoch [460], Loss1 : 1.210538, Loss2 : 0.054906, Train Loss : [0.05491] - Model Saved!\n",
      "\n",
      "Epoch [461], Loss1 : 1.233518, Loss2 : 0.054569, Train Loss : [0.05457] - Model Saved!\n",
      "\n",
      "Epoch [462], Loss1 : 1.234489, Loss2 : 0.054234, Train Loss : [0.05423] - Model Saved!\n",
      "\n",
      "Epoch [463], Loss1 : 1.216981, Loss2 : 0.053900, Train Loss : [0.05390] - Model Saved!\n",
      "\n",
      "Epoch [464], Loss1 : 1.233795, Loss2 : 0.053569, Train Loss : [0.05357] - Model Saved!\n",
      "\n",
      "Epoch [465], Loss1 : 1.212088, Loss2 : 0.053242, Train Loss : [0.05324] - Model Saved!\n",
      "\n",
      "Epoch [466], Loss1 : 1.223699, Loss2 : 0.052918, Train Loss : [0.05292] - Model Saved!\n",
      "\n",
      "Epoch [467], Loss1 : 1.204441, Loss2 : 0.052599, Train Loss : [0.05260] - Model Saved!\n",
      "\n",
      "Epoch [468], Loss1 : 1.224424, Loss2 : 0.052285, Train Loss : [0.05228] - Model Saved!\n",
      "\n",
      "Epoch [469], Loss1 : 1.222985, Loss2 : 0.051976, Train Loss : [0.05198] - Model Saved!\n",
      "\n",
      "Epoch [470], Loss1 : 1.216265, Loss2 : 0.051673, Train Loss : [0.05167] - Model Saved!\n",
      "\n",
      "Epoch [471], Loss1 : 1.202003, Loss2 : 0.051375, Train Loss : [0.05137] - Model Saved!\n",
      "\n",
      "Epoch [472], Loss1 : 1.230661, Loss2 : 0.051082, Train Loss : [0.05108] - Model Saved!\n",
      "\n",
      "Epoch [473], Loss1 : 1.214844, Loss2 : 0.050793, Train Loss : [0.05079] - Model Saved!\n",
      "\n",
      "Epoch [474], Loss1 : 1.236201, Loss2 : 0.050508, Train Loss : [0.05051] - Model Saved!\n",
      "\n",
      "Epoch [475], Loss1 : 1.199894, Loss2 : 0.050226, Train Loss : [0.05023] - Model Saved!\n",
      "\n",
      "Epoch [476], Loss1 : 1.193608, Loss2 : 0.049946, Train Loss : [0.04995] - Model Saved!\n",
      "\n",
      "Epoch [477], Loss1 : 1.186618, Loss2 : 0.049667, Train Loss : [0.04967] - Model Saved!\n",
      "\n",
      "Epoch [478], Loss1 : 1.212904, Loss2 : 0.049388, Train Loss : [0.04939] - Model Saved!\n",
      "\n",
      "Epoch [479], Loss1 : 1.222407, Loss2 : 0.049107, Train Loss : [0.04911] - Model Saved!\n",
      "\n",
      "Epoch [480], Loss1 : 1.202830, Loss2 : 0.048826, Train Loss : [0.04883] - Model Saved!\n",
      "\n",
      "Epoch [481], Loss1 : 1.195321, Loss2 : 0.048542, Train Loss : [0.04854] - Model Saved!\n",
      "\n",
      "Epoch [482], Loss1 : 1.179793, Loss2 : 0.048256, Train Loss : [0.04826] - Model Saved!\n",
      "\n",
      "Epoch [483], Loss1 : 1.202948, Loss2 : 0.047967, Train Loss : [0.04797] - Model Saved!\n",
      "\n",
      "Epoch [484], Loss1 : 1.213415, Loss2 : 0.047675, Train Loss : [0.04768] - Model Saved!\n",
      "\n",
      "Epoch [485], Loss1 : 1.203437, Loss2 : 0.047381, Train Loss : [0.04738] - Model Saved!\n",
      "\n",
      "Epoch [486], Loss1 : 1.215940, Loss2 : 0.047085, Train Loss : [0.04709] - Model Saved!\n",
      "\n",
      "Epoch [487], Loss1 : 1.279220, Loss2 : 0.046787, Train Loss : [0.04679] - Model Saved!\n",
      "\n",
      "Epoch [488], Loss1 : 1.212546, Loss2 : 0.046488, Train Loss : [0.04649] - Model Saved!\n",
      "\n",
      "Epoch [489], Loss1 : 1.215225, Loss2 : 0.046188, Train Loss : [0.04619] - Model Saved!\n",
      "\n",
      "Epoch [490], Loss1 : 1.256690, Loss2 : 0.045887, Train Loss : [0.04589] - Model Saved!\n",
      "\n",
      "Epoch [491], Loss1 : 1.251331, Loss2 : 0.045587, Train Loss : [0.04559] - Model Saved!\n",
      "\n",
      "Epoch [492], Loss1 : 1.229627, Loss2 : 0.045288, Train Loss : [0.04529] - Model Saved!\n",
      "\n",
      "Epoch [493], Loss1 : 1.251518, Loss2 : 0.044990, Train Loss : [0.04499] - Model Saved!\n",
      "\n",
      "Epoch [494], Loss1 : 1.200477, Loss2 : 0.044695, Train Loss : [0.04469] - Model Saved!\n",
      "\n",
      "Epoch [495], Loss1 : 1.220448, Loss2 : 0.044402, Train Loss : [0.04440] - Model Saved!\n",
      "\n",
      "Epoch [496], Loss1 : 1.214836, Loss2 : 0.044114, Train Loss : [0.04411] - Model Saved!\n",
      "\n",
      "Epoch [497], Loss1 : 1.217510, Loss2 : 0.043831, Train Loss : [0.04383] - Model Saved!\n",
      "\n",
      "Epoch [498], Loss1 : 1.185006, Loss2 : 0.043553, Train Loss : [0.04355] - Model Saved!\n",
      "\n",
      "Epoch [499], Loss1 : 1.214976, Loss2 : 0.043282, Train Loss : [0.04328] - Model Saved!\n",
      "\n",
      "Epoch [500], Loss1 : 1.200731, Loss2 : 0.043019, Train Loss : [0.04302] - Model Saved!\n",
      "\n",
      "Epoch [501], Loss1 : 1.243305, Loss2 : 0.042763, Train Loss : [0.04276] - Model Saved!\n",
      "\n",
      "Epoch [502], Loss1 : 1.215196, Loss2 : 0.042517, Train Loss : [0.04252] - Model Saved!\n",
      "\n",
      "Epoch [503], Loss1 : 1.197464, Loss2 : 0.042280, Train Loss : [0.04228] - Model Saved!\n",
      "\n",
      "Epoch [504], Loss1 : 1.220985, Loss2 : 0.042052, Train Loss : [0.04205] - Model Saved!\n",
      "\n",
      "Epoch [505], Loss1 : 1.196107, Loss2 : 0.041834, Train Loss : [0.04183] - Model Saved!\n",
      "\n",
      "Epoch [506], Loss1 : 1.194630, Loss2 : 0.041626, Train Loss : [0.04163] - Model Saved!\n",
      "\n",
      "Epoch [507], Loss1 : 1.225210, Loss2 : 0.041426, Train Loss : [0.04143] - Model Saved!\n",
      "\n",
      "Epoch [508], Loss1 : 1.246281, Loss2 : 0.041235, Train Loss : [0.04123] - Model Saved!\n",
      "\n",
      "Epoch [509], Loss1 : 1.230068, Loss2 : 0.041051, Train Loss : [0.04105] - Model Saved!\n",
      "\n",
      "Epoch [510], Loss1 : 1.233509, Loss2 : 0.040875, Train Loss : [0.04087] - Model Saved!\n",
      "\n",
      "Epoch [511], Loss1 : 1.230218, Loss2 : 0.040704, Train Loss : [0.04070] - Model Saved!\n",
      "\n",
      "Epoch [512], Loss1 : 1.204713, Loss2 : 0.040538, Train Loss : [0.04054] - Model Saved!\n",
      "\n",
      "Epoch [513], Loss1 : 1.230765, Loss2 : 0.040377, Train Loss : [0.04038] - Model Saved!\n",
      "\n",
      "Epoch [514], Loss1 : 1.206419, Loss2 : 0.040219, Train Loss : [0.04022] - Model Saved!\n",
      "\n",
      "Epoch [515], Loss1 : 1.248421, Loss2 : 0.040065, Train Loss : [0.04007] - Model Saved!\n",
      "\n",
      "Epoch [516], Loss1 : 1.207089, Loss2 : 0.039914, Train Loss : [0.03991] - Model Saved!\n",
      "\n",
      "Epoch [517], Loss1 : 1.192587, Loss2 : 0.039765, Train Loss : [0.03976] - Model Saved!\n",
      "\n",
      "Epoch [518], Loss1 : 1.202003, Loss2 : 0.039619, Train Loss : [0.03962] - Model Saved!\n",
      "\n",
      "Epoch [519], Loss1 : 1.178386, Loss2 : 0.039474, Train Loss : [0.03947] - Model Saved!\n",
      "\n",
      "Epoch [520], Loss1 : 1.188705, Loss2 : 0.039333, Train Loss : [0.03933] - Model Saved!\n",
      "\n",
      "Epoch [521], Loss1 : 1.209503, Loss2 : 0.039193, Train Loss : [0.03919] - Model Saved!\n",
      "\n",
      "Epoch [522], Loss1 : 1.207069, Loss2 : 0.039056, Train Loss : [0.03906] - Model Saved!\n",
      "\n",
      "Epoch [523], Loss1 : 1.211993, Loss2 : 0.038921, Train Loss : [0.03892] - Model Saved!\n",
      "\n",
      "Epoch [524], Loss1 : 1.202441, Loss2 : 0.038788, Train Loss : [0.03879] - Model Saved!\n",
      "\n",
      "Epoch [525], Loss1 : 1.218388, Loss2 : 0.038657, Train Loss : [0.03866] - Model Saved!\n",
      "\n",
      "Epoch [526], Loss1 : 1.226189, Loss2 : 0.038529, Train Loss : [0.03853] - Model Saved!\n",
      "\n",
      "Epoch [527], Loss1 : 1.213498, Loss2 : 0.038402, Train Loss : [0.03840] - Model Saved!\n",
      "\n",
      "Epoch [528], Loss1 : 1.237270, Loss2 : 0.038276, Train Loss : [0.03828] - Model Saved!\n",
      "\n",
      "Epoch [529], Loss1 : 1.218090, Loss2 : 0.038153, Train Loss : [0.03815] - Model Saved!\n",
      "\n",
      "Epoch [530], Loss1 : 1.214067, Loss2 : 0.038030, Train Loss : [0.03803] - Model Saved!\n",
      "\n",
      "Epoch [531], Loss1 : 1.191423, Loss2 : 0.037909, Train Loss : [0.03791] - Model Saved!\n",
      "\n",
      "Epoch [532], Loss1 : 1.239597, Loss2 : 0.037789, Train Loss : [0.03779] - Model Saved!\n",
      "\n",
      "Epoch [533], Loss1 : 1.200310, Loss2 : 0.037670, Train Loss : [0.03767] - Model Saved!\n",
      "\n",
      "Epoch [534], Loss1 : 1.218830, Loss2 : 0.037552, Train Loss : [0.03755] - Model Saved!\n",
      "\n",
      "Epoch [535], Loss1 : 1.217056, Loss2 : 0.037435, Train Loss : [0.03744] - Model Saved!\n",
      "\n",
      "Epoch [536], Loss1 : 1.238477, Loss2 : 0.037319, Train Loss : [0.03732] - Model Saved!\n",
      "\n",
      "Epoch [537], Loss1 : 1.232603, Loss2 : 0.037204, Train Loss : [0.03720] - Model Saved!\n",
      "\n",
      "Epoch [538], Loss1 : 1.219629, Loss2 : 0.037089, Train Loss : [0.03709] - Model Saved!\n",
      "\n",
      "Epoch [539], Loss1 : 1.225563, Loss2 : 0.036975, Train Loss : [0.03697] - Model Saved!\n",
      "\n",
      "Epoch [540], Loss1 : 1.238189, Loss2 : 0.036861, Train Loss : [0.03686] - Model Saved!\n",
      "\n",
      "Epoch [541], Loss1 : 1.200136, Loss2 : 0.036748, Train Loss : [0.03675] - Model Saved!\n",
      "\n",
      "Epoch [542], Loss1 : 1.244772, Loss2 : 0.036636, Train Loss : [0.03664] - Model Saved!\n",
      "\n",
      "Epoch [543], Loss1 : 1.219718, Loss2 : 0.036523, Train Loss : [0.03652] - Model Saved!\n",
      "\n",
      "Epoch [544], Loss1 : 1.205145, Loss2 : 0.036411, Train Loss : [0.03641] - Model Saved!\n",
      "\n",
      "Epoch [545], Loss1 : 1.258428, Loss2 : 0.036298, Train Loss : [0.03630] - Model Saved!\n",
      "\n",
      "Epoch [546], Loss1 : 1.210954, Loss2 : 0.036186, Train Loss : [0.03619] - Model Saved!\n",
      "\n",
      "Epoch [547], Loss1 : 1.203391, Loss2 : 0.036073, Train Loss : [0.03607] - Model Saved!\n",
      "\n",
      "Epoch [548], Loss1 : 1.213362, Loss2 : 0.035959, Train Loss : [0.03596] - Model Saved!\n",
      "\n",
      "Epoch [549], Loss1 : 1.218815, Loss2 : 0.035844, Train Loss : [0.03584] - Model Saved!\n",
      "\n",
      "Epoch [550], Loss1 : 1.229660, Loss2 : 0.035729, Train Loss : [0.03573] - Model Saved!\n",
      "\n",
      "Epoch [551], Loss1 : 1.188884, Loss2 : 0.035612, Train Loss : [0.03561] - Model Saved!\n",
      "\n",
      "Epoch [552], Loss1 : 1.227694, Loss2 : 0.035494, Train Loss : [0.03549] - Model Saved!\n",
      "\n",
      "Epoch [553], Loss1 : 1.198705, Loss2 : 0.035374, Train Loss : [0.03537] - Model Saved!\n",
      "\n",
      "Epoch [554], Loss1 : 1.230178, Loss2 : 0.035252, Train Loss : [0.03525] - Model Saved!\n",
      "\n",
      "Epoch [555], Loss1 : 1.240691, Loss2 : 0.035128, Train Loss : [0.03513] - Model Saved!\n",
      "\n",
      "Epoch [556], Loss1 : 1.205048, Loss2 : 0.035002, Train Loss : [0.03500] - Model Saved!\n",
      "\n",
      "Epoch [557], Loss1 : 1.224083, Loss2 : 0.034873, Train Loss : [0.03487] - Model Saved!\n",
      "\n",
      "Epoch [558], Loss1 : 1.209523, Loss2 : 0.034741, Train Loss : [0.03474] - Model Saved!\n",
      "\n",
      "Epoch [559], Loss1 : 1.213667, Loss2 : 0.034605, Train Loss : [0.03460] - Model Saved!\n",
      "\n",
      "Epoch [560], Loss1 : 1.180918, Loss2 : 0.034465, Train Loss : [0.03447] - Model Saved!\n",
      "\n",
      "Epoch [561], Loss1 : 1.220465, Loss2 : 0.034322, Train Loss : [0.03432] - Model Saved!\n",
      "\n",
      "Epoch [562], Loss1 : 1.204846, Loss2 : 0.034174, Train Loss : [0.03417] - Model Saved!\n",
      "\n",
      "Epoch [563], Loss1 : 1.215204, Loss2 : 0.034020, Train Loss : [0.03402] - Model Saved!\n",
      "\n",
      "Epoch [564], Loss1 : 1.215208, Loss2 : 0.033862, Train Loss : [0.03386] - Model Saved!\n",
      "\n",
      "Epoch [565], Loss1 : 1.225806, Loss2 : 0.033697, Train Loss : [0.03370] - Model Saved!\n",
      "\n",
      "Epoch [566], Loss1 : 1.252266, Loss2 : 0.033527, Train Loss : [0.03353] - Model Saved!\n",
      "\n",
      "Epoch [567], Loss1 : 1.211657, Loss2 : 0.033349, Train Loss : [0.03335] - Model Saved!\n",
      "\n",
      "Epoch [568], Loss1 : 1.249892, Loss2 : 0.033164, Train Loss : [0.03316] - Model Saved!\n",
      "\n",
      "Epoch [569], Loss1 : 1.205961, Loss2 : 0.032971, Train Loss : [0.03297] - Model Saved!\n",
      "\n",
      "Epoch [570], Loss1 : 1.204064, Loss2 : 0.032771, Train Loss : [0.03277] - Model Saved!\n",
      "\n",
      "Epoch [571], Loss1 : 1.218281, Loss2 : 0.032561, Train Loss : [0.03256] - Model Saved!\n",
      "\n",
      "Epoch [572], Loss1 : 1.218453, Loss2 : 0.032342, Train Loss : [0.03234] - Model Saved!\n",
      "\n",
      "Epoch [573], Loss1 : 1.223561, Loss2 : 0.032113, Train Loss : [0.03211] - Model Saved!\n",
      "\n",
      "Epoch [574], Loss1 : 1.200001, Loss2 : 0.031875, Train Loss : [0.03187] - Model Saved!\n",
      "\n",
      "Epoch [575], Loss1 : 1.224623, Loss2 : 0.031626, Train Loss : [0.03163] - Model Saved!\n",
      "\n",
      "Epoch [576], Loss1 : 1.196284, Loss2 : 0.031367, Train Loss : [0.03137] - Model Saved!\n",
      "\n",
      "Epoch [577], Loss1 : 1.167922, Loss2 : 0.031098, Train Loss : [0.03110] - Model Saved!\n",
      "\n",
      "Epoch [578], Loss1 : 1.239793, Loss2 : 0.030819, Train Loss : [0.03082] - Model Saved!\n",
      "\n",
      "Epoch [579], Loss1 : 1.231060, Loss2 : 0.030530, Train Loss : [0.03053] - Model Saved!\n",
      "\n",
      "Epoch [580], Loss1 : 1.229860, Loss2 : 0.030232, Train Loss : [0.03023] - Model Saved!\n",
      "\n",
      "Epoch [581], Loss1 : 1.208750, Loss2 : 0.029926, Train Loss : [0.02993] - Model Saved!\n",
      "\n",
      "Epoch [582], Loss1 : 1.218415, Loss2 : 0.029614, Train Loss : [0.02961] - Model Saved!\n",
      "\n",
      "Epoch [583], Loss1 : 1.216164, Loss2 : 0.029297, Train Loss : [0.02930] - Model Saved!\n",
      "\n",
      "Epoch [584], Loss1 : 1.183519, Loss2 : 0.028978, Train Loss : [0.02898] - Model Saved!\n",
      "\n",
      "Epoch [585], Loss1 : 1.221406, Loss2 : 0.028659, Train Loss : [0.02866] - Model Saved!\n",
      "\n",
      "Epoch [586], Loss1 : 1.219190, Loss2 : 0.028343, Train Loss : [0.02834] - Model Saved!\n",
      "\n",
      "Epoch [587], Loss1 : 1.245431, Loss2 : 0.028034, Train Loss : [0.02803] - Model Saved!\n",
      "\n",
      "Epoch [588], Loss1 : 1.201183, Loss2 : 0.027734, Train Loss : [0.02773] - Model Saved!\n",
      "\n",
      "Epoch [589], Loss1 : 1.216854, Loss2 : 0.027448, Train Loss : [0.02745] - Model Saved!\n",
      "\n",
      "Epoch [590], Loss1 : 1.215659, Loss2 : 0.027179, Train Loss : [0.02718] - Model Saved!\n",
      "\n",
      "Epoch [591], Loss1 : 1.225017, Loss2 : 0.026928, Train Loss : [0.02693] - Model Saved!\n",
      "\n",
      "Epoch [592], Loss1 : 1.212465, Loss2 : 0.026698, Train Loss : [0.02670] - Model Saved!\n",
      "\n",
      "Epoch [593], Loss1 : 1.241453, Loss2 : 0.026490, Train Loss : [0.02649] - Model Saved!\n",
      "\n",
      "Epoch [594], Loss1 : 1.221262, Loss2 : 0.026305, Train Loss : [0.02630] - Model Saved!\n",
      "\n",
      "Epoch [595], Loss1 : 1.187175, Loss2 : 0.026141, Train Loss : [0.02614] - Model Saved!\n",
      "\n",
      "Epoch [596], Loss1 : 1.209314, Loss2 : 0.025996, Train Loss : [0.02600] - Model Saved!\n",
      "\n",
      "Epoch [597], Loss1 : 1.245086, Loss2 : 0.025869, Train Loss : [0.02587] - Model Saved!\n",
      "\n",
      "Epoch [598], Loss1 : 1.230887, Loss2 : 0.025757, Train Loss : [0.02576] - Model Saved!\n",
      "\n",
      "Epoch [599], Loss1 : 1.216236, Loss2 : 0.025658, Train Loss : [0.02566] - Model Saved!\n",
      "\n",
      "Epoch [600], Loss1 : 1.246583, Loss2 : 0.025569, Train Loss : [0.02557] - Model Saved!\n",
      "\n",
      "Epoch [601], Loss1 : 1.234906, Loss2 : 0.025489, Train Loss : [0.02549] - Model Saved!\n",
      "\n",
      "Epoch [602], Loss1 : 1.207356, Loss2 : 0.025415, Train Loss : [0.02542] - Model Saved!\n",
      "\n",
      "Epoch [603], Loss1 : 1.235033, Loss2 : 0.025347, Train Loss : [0.02535] - Model Saved!\n",
      "\n",
      "Epoch [604], Loss1 : 1.229834, Loss2 : 0.025283, Train Loss : [0.02528] - Model Saved!\n",
      "\n",
      "Epoch [605], Loss1 : 1.224945, Loss2 : 0.025222, Train Loss : [0.02522] - Model Saved!\n",
      "\n",
      "Epoch [606], Loss1 : 1.234438, Loss2 : 0.025163, Train Loss : [0.02516] - Model Saved!\n",
      "\n",
      "Epoch [607], Loss1 : 1.218770, Loss2 : 0.025107, Train Loss : [0.02511] - Model Saved!\n",
      "\n",
      "Epoch [608], Loss1 : 1.230876, Loss2 : 0.025052, Train Loss : [0.02505] - Model Saved!\n",
      "\n",
      "Epoch [609], Loss1 : 1.214609, Loss2 : 0.024998, Train Loss : [0.02500] - Model Saved!\n",
      "\n",
      "Epoch [610], Loss1 : 1.209117, Loss2 : 0.024946, Train Loss : [0.02495] - Model Saved!\n",
      "\n",
      "Epoch [611], Loss1 : 1.243652, Loss2 : 0.024895, Train Loss : [0.02490] - Model Saved!\n",
      "\n",
      "Epoch [612], Loss1 : 1.209054, Loss2 : 0.024846, Train Loss : [0.02485] - Model Saved!\n",
      "\n",
      "Epoch [613], Loss1 : 1.221097, Loss2 : 0.024798, Train Loss : [0.02480] - Model Saved!\n",
      "\n",
      "Epoch [614], Loss1 : 1.226813, Loss2 : 0.024753, Train Loss : [0.02475] - Model Saved!\n",
      "\n",
      "Epoch [615], Loss1 : 1.200716, Loss2 : 0.024709, Train Loss : [0.02471] - Model Saved!\n",
      "\n",
      "Epoch [616], Loss1 : 1.196903, Loss2 : 0.024668, Train Loss : [0.02467] - Model Saved!\n",
      "\n",
      "Epoch [617], Loss1 : 1.233433, Loss2 : 0.024630, Train Loss : [0.02463] - Model Saved!\n",
      "\n",
      "Epoch [618], Loss1 : 1.202155, Loss2 : 0.024594, Train Loss : [0.02459] - Model Saved!\n",
      "\n",
      "Epoch [619], Loss1 : 1.254554, Loss2 : 0.024561, Train Loss : [0.02456] - Model Saved!\n",
      "\n",
      "Epoch [620], Loss1 : 1.226588, Loss2 : 0.024530, Train Loss : [0.02453] - Model Saved!\n",
      "\n",
      "Epoch [621], Loss1 : 1.234762, Loss2 : 0.024502, Train Loss : [0.02450] - Model Saved!\n",
      "\n",
      "Epoch [622], Loss1 : 1.211649, Loss2 : 0.024475, Train Loss : [0.02448] - Model Saved!\n",
      "\n",
      "Epoch [623], Loss1 : 1.222049, Loss2 : 0.024451, Train Loss : [0.02445] - Model Saved!\n",
      "\n",
      "Epoch [624], Loss1 : 1.227375, Loss2 : 0.024427, Train Loss : [0.02443] - Model Saved!\n",
      "\n",
      "Epoch [625], Loss1 : 1.245153, Loss2 : 0.024405, Train Loss : [0.02441] - Model Saved!\n",
      "\n",
      "Epoch [626], Loss1 : 1.228894, Loss2 : 0.024385, Train Loss : [0.02438] - Model Saved!\n",
      "\n",
      "Epoch [627], Loss1 : 1.213075, Loss2 : 0.024365, Train Loss : [0.02436] - Model Saved!\n",
      "\n",
      "Epoch [628], Loss1 : 1.238181, Loss2 : 0.024346, Train Loss : [0.02435] - Model Saved!\n",
      "\n",
      "Epoch [629], Loss1 : 1.233887, Loss2 : 0.024327, Train Loss : [0.02433] - Model Saved!\n",
      "\n",
      "Epoch [630], Loss1 : 1.218619, Loss2 : 0.024310, Train Loss : [0.02431] - Model Saved!\n",
      "\n",
      "Epoch [631], Loss1 : 1.239564, Loss2 : 0.024293, Train Loss : [0.02429] - Model Saved!\n",
      "\n",
      "Epoch [632], Loss1 : 1.212134, Loss2 : 0.024276, Train Loss : [0.02428] - Model Saved!\n",
      "\n",
      "Epoch [633], Loss1 : 1.216112, Loss2 : 0.024260, Train Loss : [0.02426] - Model Saved!\n",
      "\n",
      "Epoch [634], Loss1 : 1.203029, Loss2 : 0.024244, Train Loss : [0.02424] - Model Saved!\n",
      "\n",
      "Epoch [635], Loss1 : 1.213619, Loss2 : 0.024229, Train Loss : [0.02423] - Model Saved!\n",
      "\n",
      "Epoch [636], Loss1 : 1.254378, Loss2 : 0.024215, Train Loss : [0.02421] - Model Saved!\n",
      "\n",
      "Epoch [637], Loss1 : 1.243552, Loss2 : 0.024200, Train Loss : [0.02420] - Model Saved!\n",
      "\n",
      "Epoch [638], Loss1 : 1.231597, Loss2 : 0.024186, Train Loss : [0.02419] - Model Saved!\n",
      "\n",
      "Epoch [639], Loss1 : 1.227580, Loss2 : 0.024173, Train Loss : [0.02417] - Model Saved!\n",
      "\n",
      "Epoch [640], Loss1 : 1.251654, Loss2 : 0.024160, Train Loss : [0.02416] - Model Saved!\n",
      "\n",
      "Epoch [641], Loss1 : 1.210176, Loss2 : 0.024147, Train Loss : [0.02415] - Model Saved!\n",
      "\n",
      "Epoch [642], Loss1 : 1.199670, Loss2 : 0.024134, Train Loss : [0.02413] - Model Saved!\n",
      "\n",
      "Epoch [643], Loss1 : 1.237910, Loss2 : 0.024122, Train Loss : [0.02412] - Model Saved!\n",
      "\n",
      "Epoch [644], Loss1 : 1.202188, Loss2 : 0.024110, Train Loss : [0.02411] - Model Saved!\n",
      "\n",
      "Epoch [645], Loss1 : 1.229712, Loss2 : 0.024098, Train Loss : [0.02410] - Model Saved!\n",
      "\n",
      "Epoch [646], Loss1 : 1.206484, Loss2 : 0.024087, Train Loss : [0.02409] - Model Saved!\n",
      "\n",
      "Epoch [647], Loss1 : 1.239000, Loss2 : 0.024075, Train Loss : [0.02408] - Model Saved!\n",
      "\n",
      "Epoch [648], Loss1 : 1.231667, Loss2 : 0.024064, Train Loss : [0.02406] - Model Saved!\n",
      "\n",
      "Epoch [649], Loss1 : 1.213747, Loss2 : 0.024054, Train Loss : [0.02405] - Model Saved!\n",
      "\n",
      "Epoch [650], Loss1 : 1.239901, Loss2 : 0.024043, Train Loss : [0.02404] - Model Saved!\n",
      "\n",
      "Epoch [651], Loss1 : 1.224859, Loss2 : 0.024033, Train Loss : [0.02403] - Model Saved!\n",
      "\n",
      "Epoch [652], Loss1 : 1.205645, Loss2 : 0.024023, Train Loss : [0.02402] - Model Saved!\n",
      "\n",
      "Epoch [653], Loss1 : 1.252019, Loss2 : 0.024013, Train Loss : [0.02401] - Model Saved!\n",
      "\n",
      "Epoch [654], Loss1 : 1.228966, Loss2 : 0.024003, Train Loss : [0.02400] - Model Saved!\n",
      "\n",
      "Epoch [655], Loss1 : 1.231271, Loss2 : 0.023993, Train Loss : [0.02399] - Model Saved!\n",
      "\n",
      "Epoch [656], Loss1 : 1.226077, Loss2 : 0.023983, Train Loss : [0.02398] - Model Saved!\n",
      "\n",
      "Epoch [657], Loss1 : 1.228668, Loss2 : 0.023974, Train Loss : [0.02397] - Model Saved!\n",
      "\n",
      "Epoch [658], Loss1 : 1.201829, Loss2 : 0.023964, Train Loss : [0.02396] - Model Saved!\n",
      "\n",
      "Epoch [659], Loss1 : 1.223916, Loss2 : 0.023955, Train Loss : [0.02395] - Model Saved!\n",
      "\n",
      "Epoch [660], Loss1 : 1.200978, Loss2 : 0.023946, Train Loss : [0.02395] - Model Saved!\n",
      "\n",
      "Epoch [661], Loss1 : 1.185620, Loss2 : 0.023936, Train Loss : [0.02394] - Model Saved!\n",
      "\n",
      "Epoch [662], Loss1 : 1.209470, Loss2 : 0.023927, Train Loss : [0.02393] - Model Saved!\n",
      "\n",
      "Epoch [663], Loss1 : 1.233426, Loss2 : 0.023918, Train Loss : [0.02392] - Model Saved!\n",
      "\n",
      "Epoch [664], Loss1 : 1.211947, Loss2 : 0.023909, Train Loss : [0.02391] - Model Saved!\n",
      "\n",
      "Epoch [665], Loss1 : 1.219661, Loss2 : 0.023900, Train Loss : [0.02390] - Model Saved!\n",
      "\n",
      "Epoch [666], Loss1 : 1.226263, Loss2 : 0.023892, Train Loss : [0.02389] - Model Saved!\n",
      "\n",
      "Epoch [667], Loss1 : 1.224949, Loss2 : 0.023883, Train Loss : [0.02388] - Model Saved!\n",
      "\n",
      "Epoch [668], Loss1 : 1.202987, Loss2 : 0.023874, Train Loss : [0.02387] - Model Saved!\n",
      "\n",
      "Epoch [669], Loss1 : 1.193979, Loss2 : 0.023866, Train Loss : [0.02387] - Model Saved!\n",
      "\n",
      "Epoch [670], Loss1 : 1.209502, Loss2 : 0.023857, Train Loss : [0.02386] - Model Saved!\n",
      "\n",
      "Epoch [671], Loss1 : 1.244549, Loss2 : 0.023849, Train Loss : [0.02385] - Model Saved!\n",
      "\n",
      "Epoch [672], Loss1 : 1.214527, Loss2 : 0.023840, Train Loss : [0.02384] - Model Saved!\n",
      "\n",
      "Epoch [673], Loss1 : 1.241270, Loss2 : 0.023832, Train Loss : [0.02383] - Model Saved!\n",
      "\n",
      "Epoch [674], Loss1 : 1.213832, Loss2 : 0.023823, Train Loss : [0.02382] - Model Saved!\n",
      "\n",
      "Epoch [675], Loss1 : 1.180446, Loss2 : 0.023815, Train Loss : [0.02382] - Model Saved!\n",
      "\n",
      "Epoch [676], Loss1 : 1.215679, Loss2 : 0.023807, Train Loss : [0.02381] - Model Saved!\n",
      "\n",
      "Epoch [677], Loss1 : 1.249999, Loss2 : 0.023799, Train Loss : [0.02380] - Model Saved!\n",
      "\n",
      "Epoch [678], Loss1 : 1.201566, Loss2 : 0.023791, Train Loss : [0.02379] - Model Saved!\n",
      "\n",
      "Epoch [679], Loss1 : 1.208844, Loss2 : 0.023783, Train Loss : [0.02378] - Model Saved!\n",
      "\n",
      "Epoch [680], Loss1 : 1.230074, Loss2 : 0.023775, Train Loss : [0.02377] - Model Saved!\n",
      "\n",
      "Epoch [681], Loss1 : 1.215955, Loss2 : 0.023766, Train Loss : [0.02377] - Model Saved!\n",
      "\n",
      "Epoch [682], Loss1 : 1.210695, Loss2 : 0.023759, Train Loss : [0.02376] - Model Saved!\n",
      "\n",
      "Epoch [683], Loss1 : 1.189284, Loss2 : 0.023751, Train Loss : [0.02375] - Model Saved!\n",
      "\n",
      "Epoch [684], Loss1 : 1.232992, Loss2 : 0.023743, Train Loss : [0.02374] - Model Saved!\n",
      "\n",
      "Epoch [685], Loss1 : 1.223836, Loss2 : 0.023735, Train Loss : [0.02373] - Model Saved!\n",
      "\n",
      "Epoch [686], Loss1 : 1.214755, Loss2 : 0.023727, Train Loss : [0.02373] - Model Saved!\n",
      "\n",
      "Epoch [687], Loss1 : 1.197645, Loss2 : 0.023719, Train Loss : [0.02372] - Model Saved!\n",
      "\n",
      "Epoch [688], Loss1 : 1.218709, Loss2 : 0.023711, Train Loss : [0.02371] - Model Saved!\n",
      "\n",
      "Epoch [689], Loss1 : 1.231654, Loss2 : 0.023704, Train Loss : [0.02370] - Model Saved!\n",
      "\n",
      "Epoch [690], Loss1 : 1.242510, Loss2 : 0.023696, Train Loss : [0.02370] - Model Saved!\n",
      "\n",
      "Epoch [691], Loss1 : 1.236273, Loss2 : 0.023688, Train Loss : [0.02369] - Model Saved!\n",
      "\n",
      "Epoch [692], Loss1 : 1.187724, Loss2 : 0.023680, Train Loss : [0.02368] - Model Saved!\n",
      "\n",
      "Epoch [693], Loss1 : 1.209707, Loss2 : 0.023673, Train Loss : [0.02367] - Model Saved!\n",
      "\n",
      "Epoch [694], Loss1 : 1.241163, Loss2 : 0.023665, Train Loss : [0.02367] - Model Saved!\n",
      "\n",
      "Epoch [695], Loss1 : 1.255951, Loss2 : 0.023658, Train Loss : [0.02366] - Model Saved!\n",
      "\n",
      "Epoch [696], Loss1 : 1.244952, Loss2 : 0.023650, Train Loss : [0.02365] - Model Saved!\n",
      "\n",
      "Epoch [697], Loss1 : 1.221941, Loss2 : 0.023642, Train Loss : [0.02364] - Model Saved!\n",
      "\n",
      "Epoch [698], Loss1 : 1.233342, Loss2 : 0.023635, Train Loss : [0.02363] - Model Saved!\n",
      "\n",
      "Epoch [699], Loss1 : 1.210244, Loss2 : 0.023627, Train Loss : [0.02363] - Model Saved!\n",
      "\n",
      "Epoch [700], Loss1 : 1.195635, Loss2 : 0.023620, Train Loss : [0.02362] - Model Saved!\n",
      "\n",
      "Epoch [701], Loss1 : 1.234039, Loss2 : 0.023612, Train Loss : [0.02361] - Model Saved!\n",
      "\n",
      "Epoch [702], Loss1 : 1.200233, Loss2 : 0.023605, Train Loss : [0.02360] - Model Saved!\n",
      "\n",
      "Epoch [703], Loss1 : 1.178625, Loss2 : 0.023597, Train Loss : [0.02360] - Model Saved!\n",
      "\n",
      "Epoch [704], Loss1 : 1.208328, Loss2 : 0.023590, Train Loss : [0.02359] - Model Saved!\n",
      "\n",
      "Epoch [705], Loss1 : 1.211097, Loss2 : 0.023582, Train Loss : [0.02358] - Model Saved!\n",
      "\n",
      "Epoch [706], Loss1 : 1.210791, Loss2 : 0.023575, Train Loss : [0.02357] - Model Saved!\n",
      "\n",
      "Epoch [707], Loss1 : 1.204589, Loss2 : 0.023567, Train Loss : [0.02357] - Model Saved!\n",
      "\n",
      "Epoch [708], Loss1 : 1.224986, Loss2 : 0.023560, Train Loss : [0.02356] - Model Saved!\n",
      "\n",
      "Epoch [709], Loss1 : 1.219183, Loss2 : 0.023552, Train Loss : [0.02355] - Model Saved!\n",
      "\n",
      "Epoch [710], Loss1 : 1.209072, Loss2 : 0.023545, Train Loss : [0.02354] - Model Saved!\n",
      "\n",
      "Epoch [711], Loss1 : 1.245944, Loss2 : 0.023538, Train Loss : [0.02354] - Model Saved!\n",
      "\n",
      "Epoch [712], Loss1 : 1.247247, Loss2 : 0.023530, Train Loss : [0.02353] - Model Saved!\n",
      "\n",
      "Epoch [713], Loss1 : 1.236573, Loss2 : 0.023523, Train Loss : [0.02352] - Model Saved!\n",
      "\n",
      "Epoch [714], Loss1 : 1.214060, Loss2 : 0.023515, Train Loss : [0.02352] - Model Saved!\n",
      "\n",
      "Epoch [715], Loss1 : 1.215887, Loss2 : 0.023508, Train Loss : [0.02351] - Model Saved!\n",
      "\n",
      "Epoch [716], Loss1 : 1.199302, Loss2 : 0.023501, Train Loss : [0.02350] - Model Saved!\n",
      "\n",
      "Epoch [717], Loss1 : 1.230300, Loss2 : 0.023493, Train Loss : [0.02349] - Model Saved!\n",
      "\n",
      "Epoch [718], Loss1 : 1.228648, Loss2 : 0.023486, Train Loss : [0.02349] - Model Saved!\n",
      "\n",
      "Epoch [719], Loss1 : 1.195929, Loss2 : 0.023479, Train Loss : [0.02348] - Model Saved!\n",
      "\n",
      "Epoch [720], Loss1 : 1.207586, Loss2 : 0.023471, Train Loss : [0.02347] - Model Saved!\n",
      "\n",
      "Epoch [721], Loss1 : 1.237256, Loss2 : 0.023464, Train Loss : [0.02346] - Model Saved!\n",
      "\n",
      "Epoch [722], Loss1 : 1.198652, Loss2 : 0.023457, Train Loss : [0.02346] - Model Saved!\n",
      "\n",
      "Epoch [723], Loss1 : 1.233925, Loss2 : 0.023449, Train Loss : [0.02345] - Model Saved!\n",
      "\n",
      "Epoch [724], Loss1 : 1.203651, Loss2 : 0.023442, Train Loss : [0.02344] - Model Saved!\n",
      "\n",
      "Epoch [725], Loss1 : 1.215350, Loss2 : 0.023435, Train Loss : [0.02343] - Model Saved!\n",
      "\n",
      "Epoch [726], Loss1 : 1.205734, Loss2 : 0.023428, Train Loss : [0.02343] - Model Saved!\n",
      "\n",
      "Epoch [727], Loss1 : 1.197637, Loss2 : 0.023420, Train Loss : [0.02342] - Model Saved!\n",
      "\n",
      "Epoch [728], Loss1 : 1.212596, Loss2 : 0.023413, Train Loss : [0.02341] - Model Saved!\n",
      "\n",
      "Epoch [729], Loss1 : 1.214880, Loss2 : 0.023406, Train Loss : [0.02341] - Model Saved!\n",
      "\n",
      "Epoch [730], Loss1 : 1.229364, Loss2 : 0.023399, Train Loss : [0.02340] - Model Saved!\n",
      "\n",
      "Epoch [731], Loss1 : 1.213519, Loss2 : 0.023391, Train Loss : [0.02339] - Model Saved!\n",
      "\n",
      "Epoch [732], Loss1 : 1.223319, Loss2 : 0.023384, Train Loss : [0.02338] - Model Saved!\n",
      "\n",
      "Epoch [733], Loss1 : 1.206008, Loss2 : 0.023377, Train Loss : [0.02338] - Model Saved!\n",
      "\n",
      "Epoch [734], Loss1 : 1.219191, Loss2 : 0.023370, Train Loss : [0.02337] - Model Saved!\n",
      "\n",
      "Epoch [735], Loss1 : 1.241350, Loss2 : 0.023362, Train Loss : [0.02336] - Model Saved!\n",
      "\n",
      "Epoch [736], Loss1 : 1.204540, Loss2 : 0.023355, Train Loss : [0.02336] - Model Saved!\n",
      "\n",
      "Epoch [737], Loss1 : 1.223183, Loss2 : 0.023348, Train Loss : [0.02335] - Model Saved!\n",
      "\n",
      "Epoch [738], Loss1 : 1.206460, Loss2 : 0.023341, Train Loss : [0.02334] - Model Saved!\n",
      "\n",
      "Epoch [739], Loss1 : 1.225274, Loss2 : 0.023334, Train Loss : [0.02333] - Model Saved!\n",
      "\n",
      "Epoch [740], Loss1 : 1.216008, Loss2 : 0.023327, Train Loss : [0.02333] - Model Saved!\n",
      "\n",
      "Epoch [741], Loss1 : 1.225146, Loss2 : 0.023319, Train Loss : [0.02332] - Model Saved!\n",
      "\n",
      "Epoch [742], Loss1 : 1.200549, Loss2 : 0.023312, Train Loss : [0.02331] - Model Saved!\n",
      "\n",
      "Epoch [743], Loss1 : 1.210403, Loss2 : 0.023305, Train Loss : [0.02331] - Model Saved!\n",
      "\n",
      "Epoch [744], Loss1 : 1.216827, Loss2 : 0.023298, Train Loss : [0.02330] - Model Saved!\n",
      "\n",
      "Epoch [745], Loss1 : 1.232924, Loss2 : 0.023291, Train Loss : [0.02329] - Model Saved!\n",
      "\n",
      "Epoch [746], Loss1 : 1.227688, Loss2 : 0.023284, Train Loss : [0.02328] - Model Saved!\n",
      "\n",
      "Epoch [747], Loss1 : 1.218164, Loss2 : 0.023277, Train Loss : [0.02328] - Model Saved!\n",
      "\n",
      "Epoch [748], Loss1 : 1.177244, Loss2 : 0.023270, Train Loss : [0.02327] - Model Saved!\n",
      "\n",
      "Epoch [749], Loss1 : 1.211976, Loss2 : 0.023263, Train Loss : [0.02326] - Model Saved!\n",
      "\n",
      "Epoch [750], Loss1 : 1.269220, Loss2 : 0.023256, Train Loss : [0.02326] - Model Saved!\n",
      "\n",
      "Epoch [751], Loss1 : 1.250827, Loss2 : 0.023249, Train Loss : [0.02325] - Model Saved!\n",
      "\n",
      "Epoch [752], Loss1 : 1.205836, Loss2 : 0.023242, Train Loss : [0.02324] - Model Saved!\n",
      "\n",
      "Epoch [753], Loss1 : 1.184299, Loss2 : 0.023235, Train Loss : [0.02323] - Model Saved!\n",
      "\n",
      "Epoch [754], Loss1 : 1.206536, Loss2 : 0.023228, Train Loss : [0.02323] - Model Saved!\n",
      "\n",
      "Epoch [755], Loss1 : 1.219662, Loss2 : 0.023221, Train Loss : [0.02322] - Model Saved!\n",
      "\n",
      "Epoch [756], Loss1 : 1.212395, Loss2 : 0.023214, Train Loss : [0.02321] - Model Saved!\n",
      "\n",
      "Epoch [757], Loss1 : 1.220737, Loss2 : 0.023207, Train Loss : [0.02321] - Model Saved!\n",
      "\n",
      "Epoch [758], Loss1 : 1.236086, Loss2 : 0.023200, Train Loss : [0.02320] - Model Saved!\n",
      "\n",
      "Epoch [759], Loss1 : 1.195702, Loss2 : 0.023193, Train Loss : [0.02319] - Model Saved!\n",
      "\n",
      "Epoch [760], Loss1 : 1.223181, Loss2 : 0.023187, Train Loss : [0.02319] - Model Saved!\n",
      "\n",
      "Epoch [761], Loss1 : 1.235526, Loss2 : 0.023180, Train Loss : [0.02318] - Model Saved!\n",
      "\n",
      "Epoch [762], Loss1 : 1.237567, Loss2 : 0.023173, Train Loss : [0.02317] - Model Saved!\n",
      "\n",
      "Epoch [763], Loss1 : 1.197863, Loss2 : 0.023166, Train Loss : [0.02317] - Model Saved!\n",
      "\n",
      "Epoch [764], Loss1 : 1.210725, Loss2 : 0.023159, Train Loss : [0.02316] - Model Saved!\n",
      "\n",
      "Epoch [765], Loss1 : 1.253543, Loss2 : 0.023153, Train Loss : [0.02315] - Model Saved!\n",
      "\n",
      "Epoch [766], Loss1 : 1.198817, Loss2 : 0.023146, Train Loss : [0.02315] - Model Saved!\n",
      "\n",
      "Epoch [767], Loss1 : 1.216754, Loss2 : 0.023139, Train Loss : [0.02314] - Model Saved!\n",
      "\n",
      "Epoch [768], Loss1 : 1.234977, Loss2 : 0.023133, Train Loss : [0.02313] - Model Saved!\n",
      "\n",
      "Epoch [769], Loss1 : 1.227730, Loss2 : 0.023126, Train Loss : [0.02313] - Model Saved!\n",
      "\n",
      "Epoch [770], Loss1 : 1.234389, Loss2 : 0.023120, Train Loss : [0.02312] - Model Saved!\n",
      "\n",
      "Epoch [771], Loss1 : 1.199453, Loss2 : 0.023113, Train Loss : [0.02311] - Model Saved!\n",
      "\n",
      "Epoch [772], Loss1 : 1.221494, Loss2 : 0.023106, Train Loss : [0.02311] - Model Saved!\n",
      "\n",
      "Epoch [773], Loss1 : 1.230024, Loss2 : 0.023100, Train Loss : [0.02310] - Model Saved!\n",
      "\n",
      "Epoch [774], Loss1 : 1.208765, Loss2 : 0.023093, Train Loss : [0.02309] - Model Saved!\n",
      "\n",
      "Epoch [775], Loss1 : 1.233614, Loss2 : 0.023087, Train Loss : [0.02309] - Model Saved!\n",
      "\n",
      "Epoch [776], Loss1 : 1.259221, Loss2 : 0.023081, Train Loss : [0.02308] - Model Saved!\n",
      "\n",
      "Epoch [777], Loss1 : 1.217700, Loss2 : 0.023074, Train Loss : [0.02307] - Model Saved!\n",
      "\n",
      "Epoch [778], Loss1 : 1.212188, Loss2 : 0.023068, Train Loss : [0.02307] - Model Saved!\n",
      "\n",
      "Epoch [779], Loss1 : 1.239111, Loss2 : 0.023061, Train Loss : [0.02306] - Model Saved!\n",
      "\n",
      "Epoch [780], Loss1 : 1.200569, Loss2 : 0.023055, Train Loss : [0.02306] - Model Saved!\n",
      "\n",
      "Epoch [781], Loss1 : 1.237100, Loss2 : 0.023049, Train Loss : [0.02305] - Model Saved!\n",
      "\n",
      "Epoch [782], Loss1 : 1.195705, Loss2 : 0.023043, Train Loss : [0.02304] - Model Saved!\n",
      "\n",
      "Epoch [783], Loss1 : 1.207388, Loss2 : 0.023037, Train Loss : [0.02304] - Model Saved!\n",
      "\n",
      "Epoch [784], Loss1 : 1.199056, Loss2 : 0.023030, Train Loss : [0.02303] - Model Saved!\n",
      "\n",
      "Epoch [785], Loss1 : 1.221907, Loss2 : 0.023024, Train Loss : [0.02302] - Model Saved!\n",
      "\n",
      "Epoch [786], Loss1 : 1.222761, Loss2 : 0.023018, Train Loss : [0.02302] - Model Saved!\n",
      "\n",
      "Epoch [787], Loss1 : 1.213314, Loss2 : 0.023012, Train Loss : [0.02301] - Model Saved!\n",
      "\n",
      "Epoch [788], Loss1 : 1.210423, Loss2 : 0.023006, Train Loss : [0.02301] - Model Saved!\n",
      "\n",
      "Epoch [789], Loss1 : 1.240137, Loss2 : 0.023000, Train Loss : [0.02300] - Model Saved!\n",
      "\n",
      "Epoch [790], Loss1 : 1.225861, Loss2 : 0.022994, Train Loss : [0.02299] - Model Saved!\n",
      "\n",
      "Epoch [791], Loss1 : 1.196536, Loss2 : 0.022988, Train Loss : [0.02299] - Model Saved!\n",
      "\n",
      "Epoch [792], Loss1 : 1.231944, Loss2 : 0.022982, Train Loss : [0.02298] - Model Saved!\n",
      "\n",
      "Epoch [793], Loss1 : 1.205647, Loss2 : 0.022977, Train Loss : [0.02298] - Model Saved!\n",
      "\n",
      "Epoch [794], Loss1 : 1.207117, Loss2 : 0.022971, Train Loss : [0.02297] - Model Saved!\n",
      "\n",
      "Epoch [795], Loss1 : 1.222583, Loss2 : 0.022965, Train Loss : [0.02297] - Model Saved!\n",
      "\n",
      "Epoch [796], Loss1 : 1.174894, Loss2 : 0.022959, Train Loss : [0.02296] - Model Saved!\n",
      "\n",
      "Epoch [797], Loss1 : 1.207702, Loss2 : 0.022954, Train Loss : [0.02295] - Model Saved!\n",
      "\n",
      "Epoch [798], Loss1 : 1.224077, Loss2 : 0.022948, Train Loss : [0.02295] - Model Saved!\n",
      "\n",
      "Epoch [799], Loss1 : 1.214282, Loss2 : 0.022943, Train Loss : [0.02294] - Model Saved!\n",
      "\n",
      "Epoch [800], Loss1 : 1.247595, Loss2 : 0.022937, Train Loss : [0.02294] - Model Saved!\n",
      "\n",
      "Epoch [801], Loss1 : 1.194155, Loss2 : 0.022931, Train Loss : [0.02293] - Model Saved!\n",
      "\n",
      "Epoch [802], Loss1 : 1.245182, Loss2 : 0.022926, Train Loss : [0.02293] - Model Saved!\n",
      "\n",
      "Epoch [803], Loss1 : 1.241935, Loss2 : 0.022921, Train Loss : [0.02292] - Model Saved!\n",
      "\n",
      "Epoch [804], Loss1 : 1.208931, Loss2 : 0.022915, Train Loss : [0.02292] - Model Saved!\n",
      "\n",
      "Epoch [805], Loss1 : 1.222689, Loss2 : 0.022910, Train Loss : [0.02291] - Model Saved!\n",
      "\n",
      "Epoch [806], Loss1 : 1.215297, Loss2 : 0.022905, Train Loss : [0.02290] - Model Saved!\n",
      "\n",
      "Epoch [807], Loss1 : 1.232361, Loss2 : 0.022899, Train Loss : [0.02290] - Model Saved!\n",
      "\n",
      "Epoch [808], Loss1 : 1.208926, Loss2 : 0.022894, Train Loss : [0.02289] - Model Saved!\n",
      "\n",
      "Epoch [809], Loss1 : 1.209235, Loss2 : 0.022889, Train Loss : [0.02289] - Model Saved!\n",
      "\n",
      "Epoch [810], Loss1 : 1.218573, Loss2 : 0.022884, Train Loss : [0.02288] - Model Saved!\n",
      "\n",
      "Epoch [811], Loss1 : 1.225640, Loss2 : 0.022879, Train Loss : [0.02288] - Model Saved!\n",
      "\n",
      "Epoch [812], Loss1 : 1.210950, Loss2 : 0.022874, Train Loss : [0.02287] - Model Saved!\n",
      "\n",
      "Epoch [813], Loss1 : 1.224761, Loss2 : 0.022869, Train Loss : [0.02287] - Model Saved!\n",
      "\n",
      "Epoch [814], Loss1 : 1.189757, Loss2 : 0.022864, Train Loss : [0.02286] - Model Saved!\n",
      "\n",
      "Epoch [815], Loss1 : 1.241194, Loss2 : 0.022859, Train Loss : [0.02286] - Model Saved!\n",
      "\n",
      "Epoch [816], Loss1 : 1.218706, Loss2 : 0.022854, Train Loss : [0.02285] - Model Saved!\n",
      "\n",
      "Epoch [817], Loss1 : 1.195457, Loss2 : 0.022850, Train Loss : [0.02285] - Model Saved!\n",
      "\n",
      "Epoch [818], Loss1 : 1.238898, Loss2 : 0.022845, Train Loss : [0.02284] - Model Saved!\n",
      "\n",
      "Epoch [819], Loss1 : 1.217707, Loss2 : 0.022840, Train Loss : [0.02284] - Model Saved!\n",
      "\n",
      "Epoch [820], Loss1 : 1.237077, Loss2 : 0.022835, Train Loss : [0.02284] - Model Saved!\n",
      "\n",
      "Epoch [821], Loss1 : 1.226677, Loss2 : 0.022831, Train Loss : [0.02283] - Model Saved!\n",
      "\n",
      "Epoch [822], Loss1 : 1.244177, Loss2 : 0.022826, Train Loss : [0.02283] - Model Saved!\n",
      "\n",
      "Epoch [823], Loss1 : 1.231061, Loss2 : 0.022822, Train Loss : [0.02282] - Model Saved!\n",
      "\n",
      "Epoch [824], Loss1 : 1.232631, Loss2 : 0.022817, Train Loss : [0.02282] - Model Saved!\n",
      "\n",
      "Epoch [825], Loss1 : 1.199737, Loss2 : 0.022813, Train Loss : [0.02281] - Model Saved!\n",
      "\n",
      "Epoch [826], Loss1 : 1.236552, Loss2 : 0.022809, Train Loss : [0.02281] - Model Saved!\n",
      "\n",
      "Epoch [827], Loss1 : 1.204327, Loss2 : 0.022804, Train Loss : [0.02280] - Model Saved!\n",
      "\n",
      "Epoch [828], Loss1 : 1.220600, Loss2 : 0.022800, Train Loss : [0.02280] - Model Saved!\n",
      "\n",
      "Epoch [829], Loss1 : 1.233487, Loss2 : 0.022796, Train Loss : [0.02280] - Model Saved!\n",
      "\n",
      "Epoch [830], Loss1 : 1.246091, Loss2 : 0.022792, Train Loss : [0.02279] - Model Saved!\n",
      "\n",
      "Epoch [831], Loss1 : 1.187269, Loss2 : 0.022788, Train Loss : [0.02279] - Model Saved!\n",
      "\n",
      "Epoch [832], Loss1 : 1.226713, Loss2 : 0.022783, Train Loss : [0.02278] - Model Saved!\n",
      "\n",
      "Epoch [833], Loss1 : 1.195075, Loss2 : 0.022779, Train Loss : [0.02278] - Model Saved!\n",
      "\n",
      "Epoch [834], Loss1 : 1.208385, Loss2 : 0.022775, Train Loss : [0.02278] - Model Saved!\n",
      "\n",
      "Epoch [835], Loss1 : 1.237584, Loss2 : 0.022772, Train Loss : [0.02277] - Model Saved!\n",
      "\n",
      "Epoch [836], Loss1 : 1.248484, Loss2 : 0.022768, Train Loss : [0.02277] - Model Saved!\n",
      "\n",
      "Epoch [837], Loss1 : 1.245120, Loss2 : 0.022764, Train Loss : [0.02276] - Model Saved!\n",
      "\n",
      "Epoch [838], Loss1 : 1.219550, Loss2 : 0.022760, Train Loss : [0.02276] - Model Saved!\n",
      "\n",
      "Epoch [839], Loss1 : 1.203248, Loss2 : 0.022756, Train Loss : [0.02276] - Model Saved!\n",
      "\n",
      "Epoch [840], Loss1 : 1.267684, Loss2 : 0.022753, Train Loss : [0.02275] - Model Saved!\n",
      "\n",
      "Epoch [841], Loss1 : 1.249468, Loss2 : 0.022749, Train Loss : [0.02275] - Model Saved!\n",
      "\n",
      "Epoch [842], Loss1 : 1.218874, Loss2 : 0.022745, Train Loss : [0.02275] - Model Saved!\n",
      "\n",
      "Epoch [843], Loss1 : 1.240533, Loss2 : 0.022742, Train Loss : [0.02274] - Model Saved!\n",
      "\n",
      "Epoch [844], Loss1 : 1.234451, Loss2 : 0.022738, Train Loss : [0.02274] - Model Saved!\n",
      "\n",
      "Epoch [845], Loss1 : 1.224278, Loss2 : 0.022735, Train Loss : [0.02273] - Model Saved!\n",
      "\n",
      "Epoch [846], Loss1 : 1.205643, Loss2 : 0.022731, Train Loss : [0.02273] - Model Saved!\n",
      "\n",
      "Epoch [847], Loss1 : 1.224362, Loss2 : 0.022728, Train Loss : [0.02273] - Model Saved!\n",
      "\n",
      "Epoch [848], Loss1 : 1.216712, Loss2 : 0.022725, Train Loss : [0.02272] - Model Saved!\n",
      "\n",
      "Epoch [849], Loss1 : 1.232053, Loss2 : 0.022721, Train Loss : [0.02272] - Model Saved!\n",
      "\n",
      "Epoch [850], Loss1 : 1.203510, Loss2 : 0.022718, Train Loss : [0.02272] - Model Saved!\n",
      "\n",
      "Epoch [851], Loss1 : 1.234018, Loss2 : 0.022715, Train Loss : [0.02271] - Model Saved!\n",
      "\n",
      "Epoch [852], Loss1 : 1.231823, Loss2 : 0.022712, Train Loss : [0.02271] - Model Saved!\n",
      "\n",
      "Epoch [853], Loss1 : 1.205995, Loss2 : 0.022709, Train Loss : [0.02271] - Model Saved!\n",
      "\n",
      "Epoch [854], Loss1 : 1.231673, Loss2 : 0.022706, Train Loss : [0.02271] - Model Saved!\n",
      "\n",
      "Epoch [855], Loss1 : 1.214763, Loss2 : 0.022703, Train Loss : [0.02270] - Model Saved!\n",
      "\n",
      "Epoch [856], Loss1 : 1.239829, Loss2 : 0.022700, Train Loss : [0.02270] - Model Saved!\n",
      "\n",
      "Epoch [857], Loss1 : 1.210869, Loss2 : 0.022697, Train Loss : [0.02270] - Model Saved!\n",
      "\n",
      "Epoch [858], Loss1 : 1.246901, Loss2 : 0.022694, Train Loss : [0.02269] - Model Saved!\n",
      "\n",
      "Epoch [859], Loss1 : 1.227082, Loss2 : 0.022691, Train Loss : [0.02269] - Model Saved!\n",
      "\n",
      "Epoch [860], Loss1 : 1.226359, Loss2 : 0.022688, Train Loss : [0.02269] - Model Saved!\n",
      "\n",
      "Epoch [861], Loss1 : 1.225904, Loss2 : 0.022685, Train Loss : [0.02269] - Model Saved!\n",
      "\n",
      "Epoch [862], Loss1 : 1.247777, Loss2 : 0.022682, Train Loss : [0.02268] - Model Saved!\n",
      "\n",
      "Epoch [863], Loss1 : 1.255153, Loss2 : 0.022680, Train Loss : [0.02268] - Model Saved!\n",
      "\n",
      "Epoch [864], Loss1 : 1.198199, Loss2 : 0.022677, Train Loss : [0.02268] - Model Saved!\n",
      "\n",
      "Epoch [865], Loss1 : 1.213466, Loss2 : 0.022675, Train Loss : [0.02267] - Model Saved!\n",
      "\n",
      "Epoch [866], Loss1 : 1.241207, Loss2 : 0.022672, Train Loss : [0.02267] - Model Saved!\n",
      "\n",
      "Epoch [867], Loss1 : 1.230981, Loss2 : 0.022669, Train Loss : [0.02267] - Model Saved!\n",
      "\n",
      "Epoch [868], Loss1 : 1.244276, Loss2 : 0.022667, Train Loss : [0.02267] - Model Saved!\n",
      "\n",
      "Epoch [869], Loss1 : 1.206882, Loss2 : 0.022664, Train Loss : [0.02266] - Model Saved!\n",
      "\n",
      "Epoch [870], Loss1 : 1.226324, Loss2 : 0.022662, Train Loss : [0.02266] - Model Saved!\n",
      "\n",
      "Epoch [871], Loss1 : 1.225369, Loss2 : 0.022660, Train Loss : [0.02266] - Model Saved!\n",
      "\n",
      "Epoch [872], Loss1 : 1.224318, Loss2 : 0.022657, Train Loss : [0.02266] - Model Saved!\n",
      "\n",
      "Epoch [873], Loss1 : 1.224667, Loss2 : 0.022655, Train Loss : [0.02265] - Model Saved!\n",
      "\n",
      "Epoch [874], Loss1 : 1.212500, Loss2 : 0.022653, Train Loss : [0.02265] - Model Saved!\n",
      "\n",
      "Epoch [875], Loss1 : 1.229505, Loss2 : 0.022650, Train Loss : [0.02265] - Model Saved!\n",
      "\n",
      "Epoch [876], Loss1 : 1.198500, Loss2 : 0.022648, Train Loss : [0.02265] - Model Saved!\n",
      "\n",
      "Epoch [877], Loss1 : 1.231988, Loss2 : 0.022646, Train Loss : [0.02265] - Model Saved!\n",
      "\n",
      "Epoch [878], Loss1 : 1.197855, Loss2 : 0.022644, Train Loss : [0.02264] - Model Saved!\n",
      "\n",
      "Epoch [879], Loss1 : 1.232524, Loss2 : 0.022642, Train Loss : [0.02264] - Model Saved!\n",
      "\n",
      "Epoch [880], Loss1 : 1.199148, Loss2 : 0.022640, Train Loss : [0.02264] - Model Saved!\n",
      "\n",
      "Epoch [881], Loss1 : 1.243675, Loss2 : 0.022638, Train Loss : [0.02264] - Model Saved!\n",
      "\n",
      "Epoch [882], Loss1 : 1.226711, Loss2 : 0.022636, Train Loss : [0.02264] - Model Saved!\n",
      "\n",
      "Epoch [883], Loss1 : 1.201446, Loss2 : 0.022634, Train Loss : [0.02263] - Model Saved!\n",
      "\n",
      "Epoch [884], Loss1 : 1.228341, Loss2 : 0.022632, Train Loss : [0.02263] - Model Saved!\n",
      "\n",
      "Epoch [885], Loss1 : 1.265796, Loss2 : 0.022630, Train Loss : [0.02263] - Model Saved!\n",
      "\n",
      "Epoch [886], Loss1 : 1.219585, Loss2 : 0.022628, Train Loss : [0.02263] - Model Saved!\n",
      "\n",
      "Epoch [887], Loss1 : 1.225480, Loss2 : 0.022626, Train Loss : [0.02263] - Model Saved!\n",
      "\n",
      "Epoch [888], Loss1 : 1.224977, Loss2 : 0.022625, Train Loss : [0.02262] - Model Saved!\n",
      "\n",
      "Epoch [889], Loss1 : 1.225587, Loss2 : 0.022623, Train Loss : [0.02262] - Model Saved!\n",
      "\n",
      "Epoch [890], Loss1 : 1.238582, Loss2 : 0.022621, Train Loss : [0.02262] - Model Saved!\n",
      "\n",
      "Epoch [891], Loss1 : 1.244766, Loss2 : 0.022619, Train Loss : [0.02262] - Model Saved!\n",
      "\n",
      "Epoch [892], Loss1 : 1.215402, Loss2 : 0.022618, Train Loss : [0.02262] - Model Saved!\n",
      "\n",
      "Epoch [893], Loss1 : 1.212323, Loss2 : 0.022616, Train Loss : [0.02262] - Model Saved!\n",
      "\n",
      "Epoch [894], Loss1 : 1.236989, Loss2 : 0.022614, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [895], Loss1 : 1.237131, Loss2 : 0.022613, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [896], Loss1 : 1.236936, Loss2 : 0.022611, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [897], Loss1 : 1.216693, Loss2 : 0.022610, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [898], Loss1 : 1.185657, Loss2 : 0.022608, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [899], Loss1 : 1.260575, Loss2 : 0.022607, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [900], Loss1 : 1.238918, Loss2 : 0.022605, Train Loss : [0.02261] - Model Saved!\n",
      "\n",
      "Epoch [901], Loss1 : 1.192661, Loss2 : 0.022604, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [902], Loss1 : 1.243376, Loss2 : 0.022602, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [903], Loss1 : 1.211012, Loss2 : 0.022601, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [904], Loss1 : 1.219920, Loss2 : 0.022600, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [905], Loss1 : 1.191165, Loss2 : 0.022598, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [906], Loss1 : 1.229888, Loss2 : 0.022597, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [907], Loss1 : 1.203513, Loss2 : 0.022596, Train Loss : [0.02260] - Model Saved!\n",
      "\n",
      "Epoch [908], Loss1 : 1.223114, Loss2 : 0.022595, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [909], Loss1 : 1.235762, Loss2 : 0.022593, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [910], Loss1 : 1.225350, Loss2 : 0.022592, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [911], Loss1 : 1.243074, Loss2 : 0.022591, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [912], Loss1 : 1.217252, Loss2 : 0.022590, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [913], Loss1 : 1.220221, Loss2 : 0.022589, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [914], Loss1 : 1.207993, Loss2 : 0.022588, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [915], Loss1 : 1.214647, Loss2 : 0.022587, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [916], Loss1 : 1.192386, Loss2 : 0.022586, Train Loss : [0.02259] - Model Saved!\n",
      "\n",
      "Epoch [917], Loss1 : 1.261880, Loss2 : 0.022584, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [918], Loss1 : 1.219191, Loss2 : 0.022583, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [919], Loss1 : 1.222405, Loss2 : 0.022582, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [920], Loss1 : 1.229429, Loss2 : 0.022581, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [921], Loss1 : 1.202976, Loss2 : 0.022580, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [922], Loss1 : 1.207933, Loss2 : 0.022580, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [923], Loss1 : 1.185436, Loss2 : 0.022579, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [924], Loss1 : 1.252602, Loss2 : 0.022578, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [925], Loss1 : 1.228030, Loss2 : 0.022577, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [926], Loss1 : 1.227695, Loss2 : 0.022576, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [927], Loss1 : 1.213521, Loss2 : 0.022575, Train Loss : [0.02258] - Model Saved!\n",
      "\n",
      "Epoch [928], Loss1 : 1.209902, Loss2 : 0.022574, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [929], Loss1 : 1.233920, Loss2 : 0.022573, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [930], Loss1 : 1.238813, Loss2 : 0.022573, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [931], Loss1 : 1.236285, Loss2 : 0.022572, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [932], Loss1 : 1.227190, Loss2 : 0.022571, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [933], Loss1 : 1.206303, Loss2 : 0.022570, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [934], Loss1 : 1.224221, Loss2 : 0.022570, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [935], Loss1 : 1.216579, Loss2 : 0.022569, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [936], Loss1 : 1.220768, Loss2 : 0.022568, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [937], Loss1 : 1.195366, Loss2 : 0.022567, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [938], Loss1 : 1.219297, Loss2 : 0.022567, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [939], Loss1 : 1.208818, Loss2 : 0.022566, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [940], Loss1 : 1.226142, Loss2 : 0.022565, Train Loss : [0.02257] - Model Saved!\n",
      "\n",
      "Epoch [941], Loss1 : 1.206264, Loss2 : 0.022565, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [942], Loss1 : 1.241349, Loss2 : 0.022564, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [943], Loss1 : 1.248064, Loss2 : 0.022564, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [944], Loss1 : 1.234823, Loss2 : 0.022563, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [945], Loss1 : 1.214034, Loss2 : 0.022563, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [946], Loss1 : 1.226839, Loss2 : 0.022563, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [947], Loss1 : 1.206766, Loss2 : 0.022563, Train Loss : [0.02256] \n",
      "Epoch [948], Loss1 : 1.211403, Loss2 : 0.022566, Train Loss : [0.02257] \n",
      "Epoch [949], Loss1 : 1.225695, Loss2 : 0.022573, Train Loss : [0.02257] \n",
      "Epoch [950], Loss1 : 1.202523, Loss2 : 0.022592, Train Loss : [0.02259] \n",
      "Epoch [951], Loss1 : 1.217733, Loss2 : 0.022645, Train Loss : [0.02264] \n",
      "Epoch [952], Loss1 : 1.228850, Loss2 : 0.022781, Train Loss : [0.02278] \n",
      "Epoch [953], Loss1 : 1.228203, Loss2 : 0.023123, Train Loss : [0.02312] \n",
      "Epoch [954], Loss1 : 1.179076, Loss2 : 0.023864, Train Loss : [0.02386] \n",
      "Epoch [955], Loss1 : 1.242256, Loss2 : 0.025069, Train Loss : [0.02507] \n",
      "Epoch [956], Loss1 : 1.220962, Loss2 : 0.025674, Train Loss : [0.02567] \n",
      "Epoch [957], Loss1 : 1.211526, Loss2 : 0.024421, Train Loss : [0.02442] \n",
      "Epoch [958], Loss1 : 1.245660, Loss2 : 0.022713, Train Loss : [0.02271] \n",
      "Epoch [959], Loss1 : 1.209117, Loss2 : 0.023349, Train Loss : [0.02335] \n",
      "Epoch [960], Loss1 : 1.226123, Loss2 : 0.024250, Train Loss : [0.02425] \n",
      "Epoch [961], Loss1 : 1.182866, Loss2 : 0.023134, Train Loss : [0.02313] \n",
      "Epoch [962], Loss1 : 1.211115, Loss2 : 0.022757, Train Loss : [0.02276] \n",
      "Epoch [963], Loss1 : 1.212236, Loss2 : 0.023590, Train Loss : [0.02359] \n",
      "Epoch [964], Loss1 : 1.217569, Loss2 : 0.023011, Train Loss : [0.02301] \n",
      "Epoch [965], Loss1 : 1.250899, Loss2 : 0.022681, Train Loss : [0.02268] \n",
      "Epoch [966], Loss1 : 1.220013, Loss2 : 0.023274, Train Loss : [0.02327] \n",
      "Epoch [967], Loss1 : 1.246914, Loss2 : 0.022782, Train Loss : [0.02278] \n",
      "Epoch [968], Loss1 : 1.214879, Loss2 : 0.022709, Train Loss : [0.02271] \n",
      "Epoch [969], Loss1 : 1.201499, Loss2 : 0.023058, Train Loss : [0.02306] \n",
      "Epoch [970], Loss1 : 1.189294, Loss2 : 0.022601, Train Loss : [0.02260] \n",
      "Epoch [971], Loss1 : 1.217338, Loss2 : 0.022793, Train Loss : [0.02279] \n",
      "Epoch [972], Loss1 : 1.203490, Loss2 : 0.022832, Train Loss : [0.02283] \n",
      "Epoch [973], Loss1 : 1.212215, Loss2 : 0.022571, Train Loss : [0.02257] \n",
      "Epoch [974], Loss1 : 1.217502, Loss2 : 0.022820, Train Loss : [0.02282] \n",
      "Epoch [975], Loss1 : 1.221302, Loss2 : 0.022628, Train Loss : [0.02263] \n",
      "Epoch [976], Loss1 : 1.252112, Loss2 : 0.022654, Train Loss : [0.02265] \n",
      "Epoch [977], Loss1 : 1.214270, Loss2 : 0.022720, Train Loss : [0.02272] \n",
      "Epoch [978], Loss1 : 1.239307, Loss2 : 0.022561, Train Loss : [0.02256] - Model Saved!\n",
      "\n",
      "Epoch [979], Loss1 : 1.197268, Loss2 : 0.022703, Train Loss : [0.02270] \n",
      "Epoch [980], Loss1 : 1.213269, Loss2 : 0.022589, Train Loss : [0.02259] \n",
      "Epoch [981], Loss1 : 1.234098, Loss2 : 0.022611, Train Loss : [0.02261] \n",
      "Epoch [982], Loss1 : 1.177845, Loss2 : 0.022645, Train Loss : [0.02265] \n",
      "Epoch [983], Loss1 : 1.243112, Loss2 : 0.022554, Train Loss : [0.02255] - Model Saved!\n",
      "\n",
      "Epoch [984], Loss1 : 1.237356, Loss2 : 0.022640, Train Loss : [0.02264] \n",
      "Epoch [985], Loss1 : 1.229363, Loss2 : 0.022567, Train Loss : [0.02257] \n",
      "Epoch [986], Loss1 : 1.222240, Loss2 : 0.022592, Train Loss : [0.02259] \n",
      "Epoch [987], Loss1 : 1.214479, Loss2 : 0.022595, Train Loss : [0.02260] \n",
      "Epoch [988], Loss1 : 1.204309, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [989], Loss1 : 1.267406, Loss2 : 0.022601, Train Loss : [0.02260] \n",
      "Epoch [990], Loss1 : 1.235778, Loss2 : 0.022551, Train Loss : [0.02255] - Model Saved!\n",
      "\n",
      "Epoch [991], Loss1 : 1.200182, Loss2 : 0.022581, Train Loss : [0.02258] \n",
      "Epoch [992], Loss1 : 1.225077, Loss2 : 0.022568, Train Loss : [0.02257] \n",
      "Epoch [993], Loss1 : 1.209984, Loss2 : 0.022555, Train Loss : [0.02255] \n",
      "Epoch [994], Loss1 : 1.213091, Loss2 : 0.022577, Train Loss : [0.02258] \n",
      "Epoch [995], Loss1 : 1.203980, Loss2 : 0.022547, Train Loss : [0.02255] - Model Saved!\n",
      "\n",
      "Epoch [996], Loss1 : 1.250106, Loss2 : 0.022568, Train Loss : [0.02257] \n",
      "Epoch [997], Loss1 : 1.233429, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [998], Loss1 : 1.233600, Loss2 : 0.022555, Train Loss : [0.02255] \n",
      "Epoch [999], Loss1 : 1.229365, Loss2 : 0.022561, Train Loss : [0.02256] \n",
      "Epoch [1000], Loss1 : 1.236886, Loss2 : 0.022546, Train Loss : [0.02255] - Model Saved!\n",
      "\n",
      "Epoch [1001], Loss1 : 1.247686, Loss2 : 0.022560, Train Loss : [0.02256] \n",
      "Epoch [1002], Loss1 : 1.198634, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [1003], Loss1 : 1.212377, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [1004], Loss1 : 1.209936, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [1005], Loss1 : 1.206780, Loss2 : 0.022545, Train Loss : [0.02255] - Model Saved!\n",
      "\n",
      "Epoch [1006], Loss1 : 1.226575, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [1007], Loss1 : 1.219146, Loss2 : 0.022545, Train Loss : [0.02255] - Model Saved!\n",
      "\n",
      "Epoch [1008], Loss1 : 1.216851, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [1009], Loss1 : 1.181898, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [1010], Loss1 : 1.234499, Loss2 : 0.022545, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1011], Loss1 : 1.222299, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [1012], Loss1 : 1.221255, Loss2 : 0.022544, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1013], Loss1 : 1.240321, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [1014], Loss1 : 1.202908, Loss2 : 0.022545, Train Loss : [0.02255] \n",
      "Epoch [1015], Loss1 : 1.223932, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [1016], Loss1 : 1.226297, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [1017], Loss1 : 1.219590, Loss2 : 0.022543, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1018], Loss1 : 1.199101, Loss2 : 0.022545, Train Loss : [0.02254] \n",
      "Epoch [1019], Loss1 : 1.220163, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [1020], Loss1 : 1.206583, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1021], Loss1 : 1.211836, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [1022], Loss1 : 1.215351, Loss2 : 0.022542, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1023], Loss1 : 1.230109, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1024], Loss1 : 1.201074, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1025], Loss1 : 1.188491, Loss2 : 0.022542, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1026], Loss1 : 1.233416, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1027], Loss1 : 1.239591, Loss2 : 0.022542, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1028], Loss1 : 1.227046, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1029], Loss1 : 1.217785, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1030], Loss1 : 1.231287, Loss2 : 0.022542, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1031], Loss1 : 1.236981, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1032], Loss1 : 1.223406, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1033], Loss1 : 1.208114, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1034], Loss1 : 1.220446, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1035], Loss1 : 1.177986, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1036], Loss1 : 1.219430, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1037], Loss1 : 1.235948, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1038], Loss1 : 1.196693, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1039], Loss1 : 1.239676, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1040], Loss1 : 1.222101, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1041], Loss1 : 1.258850, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1042], Loss1 : 1.191993, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1043], Loss1 : 1.203813, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1044], Loss1 : 1.226656, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1045], Loss1 : 1.224621, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1046], Loss1 : 1.175398, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1047], Loss1 : 1.204409, Loss2 : 0.022541, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1048], Loss1 : 1.210685, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1049], Loss1 : 1.207355, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1050], Loss1 : 1.229542, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1051], Loss1 : 1.216294, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1052], Loss1 : 1.221952, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1053], Loss1 : 1.243410, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1054], Loss1 : 1.215774, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1055], Loss1 : 1.254184, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1056], Loss1 : 1.223830, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1057], Loss1 : 1.235656, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1058], Loss1 : 1.218568, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1059], Loss1 : 1.203890, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1060], Loss1 : 1.207407, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1061], Loss1 : 1.180825, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1062], Loss1 : 1.190267, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1063], Loss1 : 1.209222, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1064], Loss1 : 1.230874, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1065], Loss1 : 1.189271, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1066], Loss1 : 1.233607, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1067], Loss1 : 1.222420, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1068], Loss1 : 1.211001, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1069], Loss1 : 1.224597, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1070], Loss1 : 1.215407, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1071], Loss1 : 1.233759, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1072], Loss1 : 1.231416, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1073], Loss1 : 1.193624, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1074], Loss1 : 1.232012, Loss2 : 0.022540, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1075], Loss1 : 1.167505, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1076], Loss1 : 1.220815, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1077], Loss1 : 1.198664, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1078], Loss1 : 1.212540, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1079], Loss1 : 1.193765, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1080], Loss1 : 1.232589, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1081], Loss1 : 1.230325, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1082], Loss1 : 1.232454, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1083], Loss1 : 1.204369, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1084], Loss1 : 1.221957, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1085], Loss1 : 1.236935, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1086], Loss1 : 1.245568, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1087], Loss1 : 1.216265, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1088], Loss1 : 1.219950, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1089], Loss1 : 1.219591, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1090], Loss1 : 1.215103, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1091], Loss1 : 1.243416, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1092], Loss1 : 1.227109, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1093], Loss1 : 1.241880, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1094], Loss1 : 1.198315, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1095], Loss1 : 1.213079, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1096], Loss1 : 1.234690, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1097], Loss1 : 1.220789, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1098], Loss1 : 1.208830, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1099], Loss1 : 1.226490, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1100], Loss1 : 1.217516, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1101], Loss1 : 1.207708, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1102], Loss1 : 1.223228, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1103], Loss1 : 1.213776, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1104], Loss1 : 1.218648, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1105], Loss1 : 1.241928, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1106], Loss1 : 1.244722, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1107], Loss1 : 1.217049, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1108], Loss1 : 1.220772, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1109], Loss1 : 1.211781, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1110], Loss1 : 1.193202, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1111], Loss1 : 1.232769, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1112], Loss1 : 1.253084, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1113], Loss1 : 1.181060, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1114], Loss1 : 1.170365, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1115], Loss1 : 1.214468, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1116], Loss1 : 1.217382, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1117], Loss1 : 1.236928, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1118], Loss1 : 1.233786, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1119], Loss1 : 1.178198, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1120], Loss1 : 1.215513, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1121], Loss1 : 1.216490, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1122], Loss1 : 1.207040, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1123], Loss1 : 1.218207, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1124], Loss1 : 1.217145, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1125], Loss1 : 1.225157, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1126], Loss1 : 1.199069, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1127], Loss1 : 1.196299, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1128], Loss1 : 1.221769, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1129], Loss1 : 1.224883, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1130], Loss1 : 1.235353, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1131], Loss1 : 1.227808, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1132], Loss1 : 1.234958, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1133], Loss1 : 1.206553, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1134], Loss1 : 1.220754, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1135], Loss1 : 1.213205, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1136], Loss1 : 1.188310, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1137], Loss1 : 1.209830, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1138], Loss1 : 1.198194, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1139], Loss1 : 1.210614, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1140], Loss1 : 1.231994, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1141], Loss1 : 1.232309, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1142], Loss1 : 1.238284, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1143], Loss1 : 1.208086, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1144], Loss1 : 1.185820, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1145], Loss1 : 1.247391, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1146], Loss1 : 1.203763, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1147], Loss1 : 1.217032, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1148], Loss1 : 1.223526, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1149], Loss1 : 1.217940, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1150], Loss1 : 1.231125, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1151], Loss1 : 1.241879, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1152], Loss1 : 1.250525, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1153], Loss1 : 1.212544, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1154], Loss1 : 1.258857, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1155], Loss1 : 1.262919, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1156], Loss1 : 1.218253, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1157], Loss1 : 1.232693, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1158], Loss1 : 1.231762, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1159], Loss1 : 1.227619, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1160], Loss1 : 1.203909, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1161], Loss1 : 1.227566, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1162], Loss1 : 1.212905, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1163], Loss1 : 1.253733, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1164], Loss1 : 1.192899, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1165], Loss1 : 1.227002, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1166], Loss1 : 1.220560, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1167], Loss1 : 1.213683, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1168], Loss1 : 1.220068, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1169], Loss1 : 1.216223, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1170], Loss1 : 1.213207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1171], Loss1 : 1.212061, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1172], Loss1 : 1.235700, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1173], Loss1 : 1.199160, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1174], Loss1 : 1.209397, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1175], Loss1 : 1.215704, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1176], Loss1 : 1.199284, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1177], Loss1 : 1.177932, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1178], Loss1 : 1.232158, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1179], Loss1 : 1.213792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1180], Loss1 : 1.193599, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1181], Loss1 : 1.220192, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1182], Loss1 : 1.198799, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1183], Loss1 : 1.186852, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1184], Loss1 : 1.214162, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1185], Loss1 : 1.222676, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1186], Loss1 : 1.236568, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1187], Loss1 : 1.236977, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [1188], Loss1 : 1.208675, Loss2 : 0.022564, Train Loss : [0.02256] \n",
      "Epoch [1189], Loss1 : 1.215600, Loss2 : 0.022600, Train Loss : [0.02260] \n",
      "Epoch [1190], Loss1 : 1.241844, Loss2 : 0.022684, Train Loss : [0.02268] \n",
      "Epoch [1191], Loss1 : 1.234821, Loss2 : 0.022882, Train Loss : [0.02288] \n",
      "Epoch [1192], Loss1 : 1.226570, Loss2 : 0.023318, Train Loss : [0.02332] \n",
      "Epoch [1193], Loss1 : 1.215765, Loss2 : 0.024148, Train Loss : [0.02415] \n",
      "Epoch [1194], Loss1 : 1.182421, Loss2 : 0.025212, Train Loss : [0.02521] \n",
      "Epoch [1195], Loss1 : 1.204643, Loss2 : 0.025518, Train Loss : [0.02552] \n",
      "Epoch [1196], Loss1 : 1.229988, Loss2 : 0.024036, Train Loss : [0.02404] \n",
      "Epoch [1197], Loss1 : 1.211711, Loss2 : 0.022647, Train Loss : [0.02265] \n",
      "Epoch [1198], Loss1 : 1.219990, Loss2 : 0.023331, Train Loss : [0.02333] \n",
      "Epoch [1199], Loss1 : 1.226539, Loss2 : 0.024042, Train Loss : [0.02404] \n",
      "Epoch [1200], Loss1 : 1.224162, Loss2 : 0.023085, Train Loss : [0.02308] \n",
      "Epoch [1201], Loss1 : 1.190076, Loss2 : 0.022727, Train Loss : [0.02273] \n",
      "Epoch [1202], Loss1 : 1.186382, Loss2 : 0.023449, Train Loss : [0.02345] \n",
      "Epoch [1203], Loss1 : 1.199183, Loss2 : 0.023030, Train Loss : [0.02303] \n",
      "Epoch [1204], Loss1 : 1.225244, Loss2 : 0.022668, Train Loss : [0.02267] \n",
      "Epoch [1205], Loss1 : 1.241682, Loss2 : 0.023158, Train Loss : [0.02316] \n",
      "Epoch [1206], Loss1 : 1.220562, Loss2 : 0.022803, Train Loss : [0.02280] \n",
      "Epoch [1207], Loss1 : 1.228283, Loss2 : 0.022703, Train Loss : [0.02270] \n",
      "Epoch [1208], Loss1 : 1.197624, Loss2 : 0.022982, Train Loss : [0.02298] \n",
      "Epoch [1209], Loss1 : 1.229943, Loss2 : 0.022619, Train Loss : [0.02262] \n",
      "Epoch [1210], Loss1 : 1.187145, Loss2 : 0.022772, Train Loss : [0.02277] \n",
      "Epoch [1211], Loss1 : 1.202665, Loss2 : 0.022785, Train Loss : [0.02278] \n",
      "Epoch [1212], Loss1 : 1.235546, Loss2 : 0.022588, Train Loss : [0.02259] \n",
      "Epoch [1213], Loss1 : 1.239779, Loss2 : 0.022786, Train Loss : [0.02279] \n",
      "Epoch [1214], Loss1 : 1.227906, Loss2 : 0.022612, Train Loss : [0.02261] \n",
      "Epoch [1215], Loss1 : 1.210003, Loss2 : 0.022671, Train Loss : [0.02267] \n",
      "Epoch [1216], Loss1 : 1.202664, Loss2 : 0.022662, Train Loss : [0.02266] \n",
      "Epoch [1217], Loss1 : 1.210909, Loss2 : 0.022584, Train Loss : [0.02258] \n",
      "Epoch [1218], Loss1 : 1.203462, Loss2 : 0.022683, Train Loss : [0.02268] \n",
      "Epoch [1219], Loss1 : 1.214199, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [1220], Loss1 : 1.189509, Loss2 : 0.022641, Train Loss : [0.02264] \n",
      "Epoch [1221], Loss1 : 1.236530, Loss2 : 0.022593, Train Loss : [0.02259] \n",
      "Epoch [1222], Loss1 : 1.209092, Loss2 : 0.022569, Train Loss : [0.02257] \n",
      "Epoch [1223], Loss1 : 1.247528, Loss2 : 0.022620, Train Loss : [0.02262] \n",
      "Epoch [1224], Loss1 : 1.235193, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [1225], Loss1 : 1.225525, Loss2 : 0.022603, Train Loss : [0.02260] \n",
      "Epoch [1226], Loss1 : 1.207197, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [1227], Loss1 : 1.201643, Loss2 : 0.022576, Train Loss : [0.02258] \n",
      "Epoch [1228], Loss1 : 1.228728, Loss2 : 0.022571, Train Loss : [0.02257] \n",
      "Epoch [1229], Loss1 : 1.245680, Loss2 : 0.022551, Train Loss : [0.02255] \n",
      "Epoch [1230], Loss1 : 1.185962, Loss2 : 0.022578, Train Loss : [0.02258] \n",
      "Epoch [1231], Loss1 : 1.226794, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [1232], Loss1 : 1.260822, Loss2 : 0.022567, Train Loss : [0.02257] \n",
      "Epoch [1233], Loss1 : 1.184632, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [1234], Loss1 : 1.196217, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [1235], Loss1 : 1.213444, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [1236], Loss1 : 1.214478, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [1237], Loss1 : 1.183061, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [1238], Loss1 : 1.229348, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1239], Loss1 : 1.236762, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [1240], Loss1 : 1.217543, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1241], Loss1 : 1.213621, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [1242], Loss1 : 1.227108, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [1243], Loss1 : 1.220459, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1244], Loss1 : 1.220499, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [1245], Loss1 : 1.218916, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1246], Loss1 : 1.243588, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [1247], Loss1 : 1.204225, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1248], Loss1 : 1.228885, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1249], Loss1 : 1.239300, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1250], Loss1 : 1.199532, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1251], Loss1 : 1.201892, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [1252], Loss1 : 1.220993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1253], Loss1 : 1.222405, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [1254], Loss1 : 1.207821, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1255], Loss1 : 1.275027, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1256], Loss1 : 1.229772, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1257], Loss1 : 1.220294, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1258], Loss1 : 1.276145, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [1259], Loss1 : 1.221350, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1260], Loss1 : 1.222341, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1261], Loss1 : 1.201708, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1262], Loss1 : 1.205451, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1263], Loss1 : 1.250766, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1264], Loss1 : 1.215303, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1265], Loss1 : 1.207394, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [1266], Loss1 : 1.217735, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1267], Loss1 : 1.214744, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1268], Loss1 : 1.215605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1269], Loss1 : 1.226206, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1270], Loss1 : 1.236067, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1271], Loss1 : 1.264179, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1272], Loss1 : 1.220102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1273], Loss1 : 1.199591, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1274], Loss1 : 1.211671, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1275], Loss1 : 1.219128, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1276], Loss1 : 1.208907, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1277], Loss1 : 1.228167, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1278], Loss1 : 1.203281, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1279], Loss1 : 1.237947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1280], Loss1 : 1.208968, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1281], Loss1 : 1.224132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1282], Loss1 : 1.219770, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1283], Loss1 : 1.213206, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1284], Loss1 : 1.219718, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1285], Loss1 : 1.252236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1286], Loss1 : 1.191436, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1287], Loss1 : 1.216554, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1288], Loss1 : 1.235977, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1289], Loss1 : 1.232921, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1290], Loss1 : 1.268761, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1291], Loss1 : 1.232445, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1292], Loss1 : 1.211109, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1293], Loss1 : 1.201539, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1294], Loss1 : 1.193371, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1295], Loss1 : 1.231257, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1296], Loss1 : 1.240041, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1297], Loss1 : 1.171942, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1298], Loss1 : 1.204275, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1299], Loss1 : 1.199896, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1300], Loss1 : 1.224675, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1301], Loss1 : 1.209128, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1302], Loss1 : 1.207312, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1303], Loss1 : 1.223558, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1304], Loss1 : 1.198923, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1305], Loss1 : 1.207583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1306], Loss1 : 1.257071, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1307], Loss1 : 1.212803, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1308], Loss1 : 1.229006, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1309], Loss1 : 1.212253, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1310], Loss1 : 1.249903, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1311], Loss1 : 1.180660, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1312], Loss1 : 1.206710, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1313], Loss1 : 1.212036, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1314], Loss1 : 1.230754, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1315], Loss1 : 1.202426, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1316], Loss1 : 1.244423, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1317], Loss1 : 1.212332, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1318], Loss1 : 1.207949, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1319], Loss1 : 1.238796, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1320], Loss1 : 1.223116, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1321], Loss1 : 1.231235, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1322], Loss1 : 1.224145, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1323], Loss1 : 1.204780, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1324], Loss1 : 1.203001, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1325], Loss1 : 1.247213, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1326], Loss1 : 1.230197, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1327], Loss1 : 1.215282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1328], Loss1 : 1.214141, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1329], Loss1 : 1.234138, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1330], Loss1 : 1.208272, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1331], Loss1 : 1.219055, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1332], Loss1 : 1.252389, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1333], Loss1 : 1.216104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1334], Loss1 : 1.239836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1335], Loss1 : 1.227774, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1336], Loss1 : 1.247200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1337], Loss1 : 1.218352, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1338], Loss1 : 1.230308, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1339], Loss1 : 1.241822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1340], Loss1 : 1.203723, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1341], Loss1 : 1.224407, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1342], Loss1 : 1.206307, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1343], Loss1 : 1.224083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1344], Loss1 : 1.202019, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1345], Loss1 : 1.233696, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1346], Loss1 : 1.218792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1347], Loss1 : 1.200296, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1348], Loss1 : 1.232910, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1349], Loss1 : 1.262268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1350], Loss1 : 1.219197, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1351], Loss1 : 1.254849, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1352], Loss1 : 1.244590, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1353], Loss1 : 1.252885, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1354], Loss1 : 1.229501, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1355], Loss1 : 1.250353, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1356], Loss1 : 1.205724, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1357], Loss1 : 1.228592, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1358], Loss1 : 1.221338, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1359], Loss1 : 1.220620, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1360], Loss1 : 1.238600, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1361], Loss1 : 1.180720, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1362], Loss1 : 1.225622, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1363], Loss1 : 1.239027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1364], Loss1 : 1.236712, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1365], Loss1 : 1.219596, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1366], Loss1 : 1.227387, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1367], Loss1 : 1.247937, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1368], Loss1 : 1.249314, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1369], Loss1 : 1.225940, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1370], Loss1 : 1.225284, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1371], Loss1 : 1.224443, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1372], Loss1 : 1.200648, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1373], Loss1 : 1.230152, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1374], Loss1 : 1.244918, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1375], Loss1 : 1.218437, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1376], Loss1 : 1.224243, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1377], Loss1 : 1.241528, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1378], Loss1 : 1.234965, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1379], Loss1 : 1.248758, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1380], Loss1 : 1.231323, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1381], Loss1 : 1.233873, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1382], Loss1 : 1.183046, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1383], Loss1 : 1.226900, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1384], Loss1 : 1.204224, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1385], Loss1 : 1.229823, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1386], Loss1 : 1.196706, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1387], Loss1 : 1.232730, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1388], Loss1 : 1.184780, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1389], Loss1 : 1.233777, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1390], Loss1 : 1.261992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1391], Loss1 : 1.199767, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1392], Loss1 : 1.208419, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1393], Loss1 : 1.228319, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1394], Loss1 : 1.233297, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1395], Loss1 : 1.204519, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1396], Loss1 : 1.211546, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1397], Loss1 : 1.261091, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1398], Loss1 : 1.218380, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1399], Loss1 : 1.218634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1400], Loss1 : 1.209005, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1401], Loss1 : 1.254147, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1402], Loss1 : 1.182877, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1403], Loss1 : 1.206583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1404], Loss1 : 1.208357, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1405], Loss1 : 1.195822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1406], Loss1 : 1.198031, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1407], Loss1 : 1.213581, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1408], Loss1 : 1.240368, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1409], Loss1 : 1.191399, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1410], Loss1 : 1.208143, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1411], Loss1 : 1.240476, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1412], Loss1 : 1.214340, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1413], Loss1 : 1.239307, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1414], Loss1 : 1.189774, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1415], Loss1 : 1.207670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1416], Loss1 : 1.215270, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1417], Loss1 : 1.222216, Loss2 : 0.022539, Train Loss : [0.02254] - Model Saved!\n",
      "\n",
      "Epoch [1418], Loss1 : 1.205622, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1419], Loss1 : 1.206793, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1420], Loss1 : 1.229412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1421], Loss1 : 1.196407, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1422], Loss1 : 1.203348, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1423], Loss1 : 1.247532, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1424], Loss1 : 1.205459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1425], Loss1 : 1.202982, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1426], Loss1 : 1.235759, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1427], Loss1 : 1.232499, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1428], Loss1 : 1.210629, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1429], Loss1 : 1.232800, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1430], Loss1 : 1.205823, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1431], Loss1 : 1.199775, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1432], Loss1 : 1.230024, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1433], Loss1 : 1.233777, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1434], Loss1 : 1.204277, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1435], Loss1 : 1.221540, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1436], Loss1 : 1.195487, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1437], Loss1 : 1.227831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1438], Loss1 : 1.214142, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1439], Loss1 : 1.233755, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1440], Loss1 : 1.213836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1441], Loss1 : 1.216028, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1442], Loss1 : 1.207984, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1443], Loss1 : 1.247165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1444], Loss1 : 1.227548, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1445], Loss1 : 1.247613, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1446], Loss1 : 1.238287, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1447], Loss1 : 1.205020, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1448], Loss1 : 1.223941, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1449], Loss1 : 1.229243, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1450], Loss1 : 1.188876, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1451], Loss1 : 1.230535, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1452], Loss1 : 1.209884, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1453], Loss1 : 1.189668, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1454], Loss1 : 1.222681, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1455], Loss1 : 1.214922, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1456], Loss1 : 1.227692, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1457], Loss1 : 1.208702, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1458], Loss1 : 1.229470, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1459], Loss1 : 1.230227, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1460], Loss1 : 1.203059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1461], Loss1 : 1.223872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1462], Loss1 : 1.230288, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1463], Loss1 : 1.230521, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1464], Loss1 : 1.216319, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1465], Loss1 : 1.218318, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1466], Loss1 : 1.221546, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1467], Loss1 : 1.198366, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1468], Loss1 : 1.226556, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1469], Loss1 : 1.186916, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1470], Loss1 : 1.204759, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1471], Loss1 : 1.241992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1472], Loss1 : 1.228218, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1473], Loss1 : 1.249260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1474], Loss1 : 1.214059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1475], Loss1 : 1.244628, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1476], Loss1 : 1.235347, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1477], Loss1 : 1.219361, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1478], Loss1 : 1.242898, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1479], Loss1 : 1.223374, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1480], Loss1 : 1.208375, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1481], Loss1 : 1.208201, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1482], Loss1 : 1.202780, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1483], Loss1 : 1.222633, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1484], Loss1 : 1.212922, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1485], Loss1 : 1.193993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1486], Loss1 : 1.224535, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1487], Loss1 : 1.212698, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1488], Loss1 : 1.248974, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1489], Loss1 : 1.222977, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1490], Loss1 : 1.209517, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1491], Loss1 : 1.236761, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1492], Loss1 : 1.244289, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1493], Loss1 : 1.259650, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1494], Loss1 : 1.215156, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1495], Loss1 : 1.211039, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1496], Loss1 : 1.247806, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1497], Loss1 : 1.214653, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1498], Loss1 : 1.209615, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1499], Loss1 : 1.205655, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1500], Loss1 : 1.216366, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1501], Loss1 : 1.230836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1502], Loss1 : 1.216445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1503], Loss1 : 1.248167, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1504], Loss1 : 1.237505, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1505], Loss1 : 1.233357, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1506], Loss1 : 1.214745, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1507], Loss1 : 1.237016, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1508], Loss1 : 1.237951, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1509], Loss1 : 1.217743, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1510], Loss1 : 1.212070, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1511], Loss1 : 1.236086, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1512], Loss1 : 1.196830, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1513], Loss1 : 1.201418, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1514], Loss1 : 1.214402, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1515], Loss1 : 1.216443, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1516], Loss1 : 1.217646, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1517], Loss1 : 1.215760, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1518], Loss1 : 1.210100, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1519], Loss1 : 1.218943, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1520], Loss1 : 1.233935, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1521], Loss1 : 1.223919, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1522], Loss1 : 1.198069, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1523], Loss1 : 1.257796, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1524], Loss1 : 1.238283, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1525], Loss1 : 1.231905, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1526], Loss1 : 1.231692, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1527], Loss1 : 1.199538, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1528], Loss1 : 1.236530, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1529], Loss1 : 1.215751, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1530], Loss1 : 1.243875, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1531], Loss1 : 1.195064, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1532], Loss1 : 1.218327, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1533], Loss1 : 1.241354, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1534], Loss1 : 1.220584, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1535], Loss1 : 1.232472, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1536], Loss1 : 1.256842, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1537], Loss1 : 1.214971, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1538], Loss1 : 1.190461, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1539], Loss1 : 1.203011, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1540], Loss1 : 1.212763, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1541], Loss1 : 1.200249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1542], Loss1 : 1.176422, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1543], Loss1 : 1.224291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1544], Loss1 : 1.235910, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1545], Loss1 : 1.226729, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1546], Loss1 : 1.218978, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1547], Loss1 : 1.204882, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1548], Loss1 : 1.181855, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1549], Loss1 : 1.241781, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1550], Loss1 : 1.248272, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1551], Loss1 : 1.254453, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1552], Loss1 : 1.204059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1553], Loss1 : 1.225037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1554], Loss1 : 1.246404, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1555], Loss1 : 1.242286, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1556], Loss1 : 1.226273, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1557], Loss1 : 1.211926, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1558], Loss1 : 1.207715, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1559], Loss1 : 1.192359, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1560], Loss1 : 1.206986, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1561], Loss1 : 1.210115, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1562], Loss1 : 1.189826, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1563], Loss1 : 1.236397, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1564], Loss1 : 1.206013, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1565], Loss1 : 1.236838, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1566], Loss1 : 1.209383, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1567], Loss1 : 1.223476, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1568], Loss1 : 1.239159, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1569], Loss1 : 1.245745, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1570], Loss1 : 1.211901, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1571], Loss1 : 1.213732, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1572], Loss1 : 1.207901, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1573], Loss1 : 1.225002, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1574], Loss1 : 1.204435, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1575], Loss1 : 1.233806, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1576], Loss1 : 1.195135, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1577], Loss1 : 1.227371, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1578], Loss1 : 1.234240, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1579], Loss1 : 1.234830, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1580], Loss1 : 1.258089, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1581], Loss1 : 1.189581, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1582], Loss1 : 1.224113, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1583], Loss1 : 1.221696, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1584], Loss1 : 1.217152, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1585], Loss1 : 1.198202, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1586], Loss1 : 1.230459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1587], Loss1 : 1.247838, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1588], Loss1 : 1.202459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1589], Loss1 : 1.203020, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1590], Loss1 : 1.199550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1591], Loss1 : 1.222821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1592], Loss1 : 1.231853, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1593], Loss1 : 1.254270, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1594], Loss1 : 1.245641, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1595], Loss1 : 1.208979, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1596], Loss1 : 1.216088, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1597], Loss1 : 1.200623, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1598], Loss1 : 1.201442, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1599], Loss1 : 1.248110, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1600], Loss1 : 1.207762, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1601], Loss1 : 1.252503, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1602], Loss1 : 1.240105, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1603], Loss1 : 1.218839, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1604], Loss1 : 1.199657, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1605], Loss1 : 1.219636, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1606], Loss1 : 1.213172, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1607], Loss1 : 1.221560, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1608], Loss1 : 1.210739, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1609], Loss1 : 1.250054, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1610], Loss1 : 1.210789, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1611], Loss1 : 1.215138, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1612], Loss1 : 1.227200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1613], Loss1 : 1.210323, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1614], Loss1 : 1.200992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1615], Loss1 : 1.238978, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1616], Loss1 : 1.209238, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1617], Loss1 : 1.170055, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1618], Loss1 : 1.224981, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1619], Loss1 : 1.219498, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1620], Loss1 : 1.180359, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1621], Loss1 : 1.245690, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1622], Loss1 : 1.232171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1623], Loss1 : 1.214823, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1624], Loss1 : 1.262052, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1625], Loss1 : 1.235544, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1626], Loss1 : 1.247428, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1627], Loss1 : 1.217470, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1628], Loss1 : 1.200206, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1629], Loss1 : 1.191445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1630], Loss1 : 1.226122, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1631], Loss1 : 1.233173, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1632], Loss1 : 1.203623, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1633], Loss1 : 1.239910, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1634], Loss1 : 1.208463, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1635], Loss1 : 1.226942, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1636], Loss1 : 1.210484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1637], Loss1 : 1.212573, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1638], Loss1 : 1.189518, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1639], Loss1 : 1.169523, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1640], Loss1 : 1.224199, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1641], Loss1 : 1.213529, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1642], Loss1 : 1.238229, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1643], Loss1 : 1.220708, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1644], Loss1 : 1.232873, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1645], Loss1 : 1.208510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1646], Loss1 : 1.207261, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1647], Loss1 : 1.198893, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1648], Loss1 : 1.207782, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1649], Loss1 : 1.230583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1650], Loss1 : 1.225906, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1651], Loss1 : 1.226197, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1652], Loss1 : 1.227135, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1653], Loss1 : 1.231003, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1654], Loss1 : 1.213414, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1655], Loss1 : 1.175417, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1656], Loss1 : 1.221323, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1657], Loss1 : 1.232648, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1658], Loss1 : 1.256155, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1659], Loss1 : 1.220835, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1660], Loss1 : 1.238895, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1661], Loss1 : 1.210835, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1662], Loss1 : 1.199203, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1663], Loss1 : 1.222671, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1664], Loss1 : 1.205704, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1665], Loss1 : 1.205476, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1666], Loss1 : 1.189991, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1667], Loss1 : 1.229133, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1668], Loss1 : 1.236968, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1669], Loss1 : 1.209982, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1670], Loss1 : 1.205851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1671], Loss1 : 1.193290, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1672], Loss1 : 1.216431, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1673], Loss1 : 1.210253, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1674], Loss1 : 1.209824, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1675], Loss1 : 1.222291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1676], Loss1 : 1.212181, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1677], Loss1 : 1.216416, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1678], Loss1 : 1.237711, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1679], Loss1 : 1.196282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1680], Loss1 : 1.235055, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1681], Loss1 : 1.208789, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1682], Loss1 : 1.197217, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1683], Loss1 : 1.217291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1684], Loss1 : 1.204911, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1685], Loss1 : 1.237170, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1686], Loss1 : 1.220296, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1687], Loss1 : 1.238867, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1688], Loss1 : 1.200570, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1689], Loss1 : 1.235142, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1690], Loss1 : 1.195958, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1691], Loss1 : 1.219140, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1692], Loss1 : 1.220195, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1693], Loss1 : 1.214465, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1694], Loss1 : 1.221176, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1695], Loss1 : 1.189073, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1696], Loss1 : 1.229822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1697], Loss1 : 1.208746, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1698], Loss1 : 1.222698, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1699], Loss1 : 1.237605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1700], Loss1 : 1.210627, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1701], Loss1 : 1.198287, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1702], Loss1 : 1.220741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1703], Loss1 : 1.231159, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1704], Loss1 : 1.227911, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1705], Loss1 : 1.228139, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1706], Loss1 : 1.220562, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1707], Loss1 : 1.222357, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1708], Loss1 : 1.195441, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1709], Loss1 : 1.234474, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1710], Loss1 : 1.223821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1711], Loss1 : 1.201361, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1712], Loss1 : 1.225329, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1713], Loss1 : 1.223038, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1714], Loss1 : 1.190247, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1715], Loss1 : 1.213745, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1716], Loss1 : 1.178230, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1717], Loss1 : 1.227932, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1718], Loss1 : 1.207203, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1719], Loss1 : 1.227441, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1720], Loss1 : 1.206378, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1721], Loss1 : 1.212029, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1722], Loss1 : 1.235846, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1723], Loss1 : 1.213248, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1724], Loss1 : 1.198198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1725], Loss1 : 1.215165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1726], Loss1 : 1.198262, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1727], Loss1 : 1.243046, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1728], Loss1 : 1.213162, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1729], Loss1 : 1.233594, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1730], Loss1 : 1.202793, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1731], Loss1 : 1.223700, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1732], Loss1 : 1.212477, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1733], Loss1 : 1.232385, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1734], Loss1 : 1.224798, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1735], Loss1 : 1.230285, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1736], Loss1 : 1.248650, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1737], Loss1 : 1.176162, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1738], Loss1 : 1.227120, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1739], Loss1 : 1.240453, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1740], Loss1 : 1.218032, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1741], Loss1 : 1.211227, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1742], Loss1 : 1.246584, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1743], Loss1 : 1.199832, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1744], Loss1 : 1.216271, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1745], Loss1 : 1.256114, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1746], Loss1 : 1.206109, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1747], Loss1 : 1.213780, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1748], Loss1 : 1.220542, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1749], Loss1 : 1.233180, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1750], Loss1 : 1.220578, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1751], Loss1 : 1.223274, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1752], Loss1 : 1.231355, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1753], Loss1 : 1.226274, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1754], Loss1 : 1.230025, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1755], Loss1 : 1.212083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1756], Loss1 : 1.251430, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1757], Loss1 : 1.213619, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1758], Loss1 : 1.222144, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1759], Loss1 : 1.257867, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1760], Loss1 : 1.193172, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1761], Loss1 : 1.234732, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1762], Loss1 : 1.236166, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1763], Loss1 : 1.201034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1764], Loss1 : 1.204458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1765], Loss1 : 1.193123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1766], Loss1 : 1.231671, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1767], Loss1 : 1.191850, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1768], Loss1 : 1.219754, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1769], Loss1 : 1.192245, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1770], Loss1 : 1.201734, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1771], Loss1 : 1.233741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1772], Loss1 : 1.232459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1773], Loss1 : 1.232412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1774], Loss1 : 1.206795, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1775], Loss1 : 1.206213, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1776], Loss1 : 1.242115, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1777], Loss1 : 1.231024, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1778], Loss1 : 1.225703, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1779], Loss1 : 1.217060, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1780], Loss1 : 1.216254, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1781], Loss1 : 1.208656, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1782], Loss1 : 1.193738, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1783], Loss1 : 1.201092, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1784], Loss1 : 1.224562, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1785], Loss1 : 1.212615, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1786], Loss1 : 1.217111, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1787], Loss1 : 1.219011, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1788], Loss1 : 1.209249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1789], Loss1 : 1.266077, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1790], Loss1 : 1.212365, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1791], Loss1 : 1.224393, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1792], Loss1 : 1.203455, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1793], Loss1 : 1.213382, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1794], Loss1 : 1.190065, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1795], Loss1 : 1.236563, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1796], Loss1 : 1.212143, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1797], Loss1 : 1.205582, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1798], Loss1 : 1.205889, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1799], Loss1 : 1.238192, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1800], Loss1 : 1.206619, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1801], Loss1 : 1.201639, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1802], Loss1 : 1.223799, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1803], Loss1 : 1.225822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1804], Loss1 : 1.209072, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1805], Loss1 : 1.237500, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1806], Loss1 : 1.195503, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1807], Loss1 : 1.185327, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1808], Loss1 : 1.229041, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1809], Loss1 : 1.219969, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1810], Loss1 : 1.218179, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1811], Loss1 : 1.236058, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1812], Loss1 : 1.160995, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1813], Loss1 : 1.225448, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1814], Loss1 : 1.214073, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1815], Loss1 : 1.237167, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1816], Loss1 : 1.214766, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1817], Loss1 : 1.227825, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1818], Loss1 : 1.193033, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1819], Loss1 : 1.223329, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1820], Loss1 : 1.183454, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1821], Loss1 : 1.249326, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1822], Loss1 : 1.247249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1823], Loss1 : 1.200693, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1824], Loss1 : 1.230224, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1825], Loss1 : 1.207667, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1826], Loss1 : 1.189247, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1827], Loss1 : 1.171393, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1828], Loss1 : 1.230707, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1829], Loss1 : 1.228754, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1830], Loss1 : 1.230829, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1831], Loss1 : 1.224637, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1832], Loss1 : 1.234423, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1833], Loss1 : 1.213526, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1834], Loss1 : 1.217261, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1835], Loss1 : 1.224510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1836], Loss1 : 1.227342, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1837], Loss1 : 1.210715, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1838], Loss1 : 1.205407, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1839], Loss1 : 1.204806, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1840], Loss1 : 1.215098, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1841], Loss1 : 1.202143, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1842], Loss1 : 1.212477, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1843], Loss1 : 1.216296, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1844], Loss1 : 1.207681, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1845], Loss1 : 1.218222, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1846], Loss1 : 1.207996, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1847], Loss1 : 1.245518, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1848], Loss1 : 1.215448, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1849], Loss1 : 1.214558, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1850], Loss1 : 1.215225, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1851], Loss1 : 1.206819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1852], Loss1 : 1.222642, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1853], Loss1 : 1.226880, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1854], Loss1 : 1.212751, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1855], Loss1 : 1.217792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1856], Loss1 : 1.199414, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1857], Loss1 : 1.256891, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1858], Loss1 : 1.218726, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1859], Loss1 : 1.184051, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1860], Loss1 : 1.224641, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1861], Loss1 : 1.253104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1862], Loss1 : 1.246473, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1863], Loss1 : 1.209225, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1864], Loss1 : 1.242688, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1865], Loss1 : 1.205615, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1866], Loss1 : 1.199146, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1867], Loss1 : 1.236395, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1868], Loss1 : 1.222497, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1869], Loss1 : 1.205244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1870], Loss1 : 1.211881, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1871], Loss1 : 1.210818, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1872], Loss1 : 1.245351, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1873], Loss1 : 1.218161, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1874], Loss1 : 1.201063, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1875], Loss1 : 1.230101, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1876], Loss1 : 1.198118, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1877], Loss1 : 1.209125, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1878], Loss1 : 1.190097, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1879], Loss1 : 1.204366, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1880], Loss1 : 1.204147, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1881], Loss1 : 1.219111, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1882], Loss1 : 1.230592, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1883], Loss1 : 1.202466, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1884], Loss1 : 1.233478, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1885], Loss1 : 1.238152, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1886], Loss1 : 1.220064, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1887], Loss1 : 1.202422, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1888], Loss1 : 1.206252, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1889], Loss1 : 1.209561, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1890], Loss1 : 1.197306, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1891], Loss1 : 1.225801, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1892], Loss1 : 1.207571, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1893], Loss1 : 1.232337, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1894], Loss1 : 1.221789, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1895], Loss1 : 1.250003, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1896], Loss1 : 1.193726, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1897], Loss1 : 1.218318, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1898], Loss1 : 1.196202, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1899], Loss1 : 1.217991, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1900], Loss1 : 1.231791, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1901], Loss1 : 1.207119, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1902], Loss1 : 1.208107, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1903], Loss1 : 1.207603, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1904], Loss1 : 1.228417, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1905], Loss1 : 1.230843, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1906], Loss1 : 1.215377, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1907], Loss1 : 1.248338, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1908], Loss1 : 1.231826, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1909], Loss1 : 1.213593, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1910], Loss1 : 1.214646, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1911], Loss1 : 1.232497, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1912], Loss1 : 1.222506, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1913], Loss1 : 1.212494, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1914], Loss1 : 1.222145, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1915], Loss1 : 1.223503, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1916], Loss1 : 1.193271, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1917], Loss1 : 1.238901, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1918], Loss1 : 1.217716, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1919], Loss1 : 1.219014, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1920], Loss1 : 1.206103, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1921], Loss1 : 1.209700, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1922], Loss1 : 1.223550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1923], Loss1 : 1.209929, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1924], Loss1 : 1.221323, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1925], Loss1 : 1.240991, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1926], Loss1 : 1.234330, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1927], Loss1 : 1.204658, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1928], Loss1 : 1.219668, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1929], Loss1 : 1.215468, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1930], Loss1 : 1.205804, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1931], Loss1 : 1.197881, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1932], Loss1 : 1.238515, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1933], Loss1 : 1.223893, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1934], Loss1 : 1.213399, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1935], Loss1 : 1.230614, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1936], Loss1 : 1.240144, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1937], Loss1 : 1.236629, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1938], Loss1 : 1.237706, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1939], Loss1 : 1.248688, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1940], Loss1 : 1.217355, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1941], Loss1 : 1.215599, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1942], Loss1 : 1.212487, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1943], Loss1 : 1.224096, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1944], Loss1 : 1.231897, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1945], Loss1 : 1.217426, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1946], Loss1 : 1.219331, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1947], Loss1 : 1.227851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1948], Loss1 : 1.261976, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1949], Loss1 : 1.203369, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1950], Loss1 : 1.224038, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1951], Loss1 : 1.179859, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1952], Loss1 : 1.220579, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1953], Loss1 : 1.251517, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1954], Loss1 : 1.219396, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1955], Loss1 : 1.225207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1956], Loss1 : 1.228467, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1957], Loss1 : 1.246974, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1958], Loss1 : 1.205808, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1959], Loss1 : 1.241941, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1960], Loss1 : 1.215714, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1961], Loss1 : 1.208104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1962], Loss1 : 1.210490, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1963], Loss1 : 1.201670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1964], Loss1 : 1.237851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1965], Loss1 : 1.264662, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1966], Loss1 : 1.229123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1967], Loss1 : 1.165649, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1968], Loss1 : 1.235757, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1969], Loss1 : 1.223127, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1970], Loss1 : 1.216324, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1971], Loss1 : 1.226377, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1972], Loss1 : 1.226375, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1973], Loss1 : 1.236445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1974], Loss1 : 1.212540, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1975], Loss1 : 1.228645, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1976], Loss1 : 1.208957, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1977], Loss1 : 1.222753, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1978], Loss1 : 1.220659, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1979], Loss1 : 1.205836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1980], Loss1 : 1.229414, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1981], Loss1 : 1.230310, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1982], Loss1 : 1.208683, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [1983], Loss1 : 1.231862, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [1984], Loss1 : 1.226435, Loss2 : 0.022674, Train Loss : [0.02267] \n",
      "Epoch [1985], Loss1 : 1.238615, Loss2 : 0.026292, Train Loss : [0.02629] \n",
      "Epoch [1986], Loss1 : 1.211829, Loss2 : 0.097255, Train Loss : [0.09726] \n",
      "Epoch [1987], Loss1 : 1.201648, Loss2 : 0.135414, Train Loss : [0.13541] \n",
      "Epoch [1988], Loss1 : 1.228382, Loss2 : 0.395670, Train Loss : [0.39567] \n",
      "Epoch [1989], Loss1 : 1.205743, Loss2 : 0.194589, Train Loss : [0.19459] \n",
      "Epoch [1990], Loss1 : 1.200569, Loss2 : 0.155240, Train Loss : [0.15524] \n",
      "Epoch [1991], Loss1 : 1.208852, Loss2 : 0.129705, Train Loss : [0.12971] \n",
      "Epoch [1992], Loss1 : 1.252516, Loss2 : 0.127520, Train Loss : [0.12752] \n",
      "Epoch [1993], Loss1 : 1.214840, Loss2 : 0.129909, Train Loss : [0.12991] \n",
      "Epoch [1994], Loss1 : 1.210775, Loss2 : 0.146207, Train Loss : [0.14621] \n",
      "Epoch [1995], Loss1 : 1.236417, Loss2 : 0.117842, Train Loss : [0.11784] \n",
      "Epoch [1996], Loss1 : 1.255420, Loss2 : 0.098708, Train Loss : [0.09871] \n",
      "Epoch [1997], Loss1 : 1.222100, Loss2 : 0.093239, Train Loss : [0.09324] \n",
      "Epoch [1998], Loss1 : 1.229114, Loss2 : 0.087163, Train Loss : [0.08716] \n",
      "Epoch [1999], Loss1 : 1.205542, Loss2 : 0.083071, Train Loss : [0.08307] \n",
      "Epoch [2000], Loss1 : 1.235367, Loss2 : 0.081606, Train Loss : [0.08161] \n",
      "Epoch [2001], Loss1 : 1.204760, Loss2 : 0.077096, Train Loss : [0.07710] \n",
      "Epoch [2002], Loss1 : 1.247001, Loss2 : 0.074903, Train Loss : [0.07490] \n",
      "Epoch [2003], Loss1 : 1.210310, Loss2 : 0.075058, Train Loss : [0.07506] \n",
      "Epoch [2004], Loss1 : 1.249645, Loss2 : 0.072126, Train Loss : [0.07213] \n",
      "Epoch [2005], Loss1 : 1.209962, Loss2 : 0.068506, Train Loss : [0.06851] \n",
      "Epoch [2006], Loss1 : 1.189355, Loss2 : 0.067428, Train Loss : [0.06743] \n",
      "Epoch [2007], Loss1 : 1.211089, Loss2 : 0.065382, Train Loss : [0.06538] \n",
      "Epoch [2008], Loss1 : 1.214426, Loss2 : 0.061978, Train Loss : [0.06198] \n",
      "Epoch [2009], Loss1 : 1.201737, Loss2 : 0.060692, Train Loss : [0.06069] \n",
      "Epoch [2010], Loss1 : 1.228453, Loss2 : 0.060430, Train Loss : [0.06043] \n",
      "Epoch [2011], Loss1 : 1.217399, Loss2 : 0.058379, Train Loss : [0.05838] \n",
      "Epoch [2012], Loss1 : 1.231263, Loss2 : 0.056935, Train Loss : [0.05694] \n",
      "Epoch [2013], Loss1 : 1.209161, Loss2 : 0.056537, Train Loss : [0.05654] \n",
      "Epoch [2014], Loss1 : 1.207782, Loss2 : 0.055671, Train Loss : [0.05567] \n",
      "Epoch [2015], Loss1 : 1.211405, Loss2 : 0.054870, Train Loss : [0.05487] \n",
      "Epoch [2016], Loss1 : 1.216613, Loss2 : 0.054667, Train Loss : [0.05467] \n",
      "Epoch [2017], Loss1 : 1.235694, Loss2 : 0.054259, Train Loss : [0.05426] \n",
      "Epoch [2018], Loss1 : 1.202264, Loss2 : 0.053573, Train Loss : [0.05357] \n",
      "Epoch [2019], Loss1 : 1.223163, Loss2 : 0.053049, Train Loss : [0.05305] \n",
      "Epoch [2020], Loss1 : 1.265830, Loss2 : 0.051916, Train Loss : [0.05192] \n",
      "Epoch [2021], Loss1 : 1.193635, Loss2 : 0.050318, Train Loss : [0.05032] \n",
      "Epoch [2022], Loss1 : 1.229065, Loss2 : 0.049387, Train Loss : [0.04939] \n",
      "Epoch [2023], Loss1 : 1.202463, Loss2 : 0.049126, Train Loss : [0.04913] \n",
      "Epoch [2024], Loss1 : 1.218364, Loss2 : 0.048757, Train Loss : [0.04876] \n",
      "Epoch [2025], Loss1 : 1.208743, Loss2 : 0.047855, Train Loss : [0.04785] \n",
      "Epoch [2026], Loss1 : 1.227183, Loss2 : 0.047278, Train Loss : [0.04728] \n",
      "Epoch [2027], Loss1 : 1.218348, Loss2 : 0.047005, Train Loss : [0.04701] \n",
      "Epoch [2028], Loss1 : 1.174337, Loss2 : 0.046484, Train Loss : [0.04648] \n",
      "Epoch [2029], Loss1 : 1.200604, Loss2 : 0.045871, Train Loss : [0.04587] \n",
      "Epoch [2030], Loss1 : 1.214308, Loss2 : 0.045721, Train Loss : [0.04572] \n",
      "Epoch [2031], Loss1 : 1.233104, Loss2 : 0.045294, Train Loss : [0.04529] \n",
      "Epoch [2032], Loss1 : 1.227145, Loss2 : 0.044530, Train Loss : [0.04453] \n",
      "Epoch [2033], Loss1 : 1.267556, Loss2 : 0.044273, Train Loss : [0.04427] \n",
      "Epoch [2034], Loss1 : 1.243926, Loss2 : 0.043888, Train Loss : [0.04389] \n",
      "Epoch [2035], Loss1 : 1.204985, Loss2 : 0.043262, Train Loss : [0.04326] \n",
      "Epoch [2036], Loss1 : 1.251620, Loss2 : 0.042736, Train Loss : [0.04274] \n",
      "Epoch [2037], Loss1 : 1.240515, Loss2 : 0.042257, Train Loss : [0.04226] \n",
      "Epoch [2038], Loss1 : 1.208549, Loss2 : 0.041587, Train Loss : [0.04159] \n",
      "Epoch [2039], Loss1 : 1.254092, Loss2 : 0.040945, Train Loss : [0.04095] \n",
      "Epoch [2040], Loss1 : 1.215975, Loss2 : 0.040282, Train Loss : [0.04028] \n",
      "Epoch [2041], Loss1 : 1.184922, Loss2 : 0.039629, Train Loss : [0.03963] \n",
      "Epoch [2042], Loss1 : 1.235434, Loss2 : 0.039037, Train Loss : [0.03904] \n",
      "Epoch [2043], Loss1 : 1.250075, Loss2 : 0.038498, Train Loss : [0.03850] \n",
      "Epoch [2044], Loss1 : 1.224881, Loss2 : 0.038048, Train Loss : [0.03805] \n",
      "Epoch [2045], Loss1 : 1.224330, Loss2 : 0.037764, Train Loss : [0.03776] \n",
      "Epoch [2046], Loss1 : 1.205689, Loss2 : 0.037498, Train Loss : [0.03750] \n",
      "Epoch [2047], Loss1 : 1.217595, Loss2 : 0.037253, Train Loss : [0.03725] \n",
      "Epoch [2048], Loss1 : 1.188139, Loss2 : 0.037018, Train Loss : [0.03702] \n",
      "Epoch [2049], Loss1 : 1.196498, Loss2 : 0.036710, Train Loss : [0.03671] \n",
      "Epoch [2050], Loss1 : 1.237823, Loss2 : 0.036412, Train Loss : [0.03641] \n",
      "Epoch [2051], Loss1 : 1.224764, Loss2 : 0.036142, Train Loss : [0.03614] \n",
      "Epoch [2052], Loss1 : 1.191873, Loss2 : 0.035884, Train Loss : [0.03588] \n",
      "Epoch [2053], Loss1 : 1.237788, Loss2 : 0.035667, Train Loss : [0.03567] \n",
      "Epoch [2054], Loss1 : 1.200426, Loss2 : 0.035458, Train Loss : [0.03546] \n",
      "Epoch [2055], Loss1 : 1.214558, Loss2 : 0.035268, Train Loss : [0.03527] \n",
      "Epoch [2056], Loss1 : 1.218597, Loss2 : 0.035113, Train Loss : [0.03511] \n",
      "Epoch [2057], Loss1 : 1.235964, Loss2 : 0.034966, Train Loss : [0.03497] \n",
      "Epoch [2058], Loss1 : 1.206216, Loss2 : 0.034831, Train Loss : [0.03483] \n",
      "Epoch [2059], Loss1 : 1.213263, Loss2 : 0.034727, Train Loss : [0.03473] \n",
      "Epoch [2060], Loss1 : 1.255456, Loss2 : 0.034631, Train Loss : [0.03463] \n",
      "Epoch [2061], Loss1 : 1.239077, Loss2 : 0.034544, Train Loss : [0.03454] \n",
      "Epoch [2062], Loss1 : 1.235930, Loss2 : 0.034461, Train Loss : [0.03446] \n",
      "Epoch [2063], Loss1 : 1.211761, Loss2 : 0.034374, Train Loss : [0.03437] \n",
      "Epoch [2064], Loss1 : 1.228717, Loss2 : 0.034287, Train Loss : [0.03429] \n",
      "Epoch [2065], Loss1 : 1.241269, Loss2 : 0.034181, Train Loss : [0.03418] \n",
      "Epoch [2066], Loss1 : 1.230952, Loss2 : 0.034055, Train Loss : [0.03405] \n",
      "Epoch [2067], Loss1 : 1.197036, Loss2 : 0.033930, Train Loss : [0.03393] \n",
      "Epoch [2068], Loss1 : 1.244039, Loss2 : 0.033801, Train Loss : [0.03380] \n",
      "Epoch [2069], Loss1 : 1.237589, Loss2 : 0.033668, Train Loss : [0.03367] \n",
      "Epoch [2070], Loss1 : 1.253231, Loss2 : 0.033536, Train Loss : [0.03354] \n",
      "Epoch [2071], Loss1 : 1.229983, Loss2 : 0.033396, Train Loss : [0.03340] \n",
      "Epoch [2072], Loss1 : 1.204083, Loss2 : 0.033240, Train Loss : [0.03324] \n",
      "Epoch [2073], Loss1 : 1.177297, Loss2 : 0.033065, Train Loss : [0.03307] \n",
      "Epoch [2074], Loss1 : 1.250070, Loss2 : 0.032870, Train Loss : [0.03287] \n",
      "Epoch [2075], Loss1 : 1.220106, Loss2 : 0.032657, Train Loss : [0.03266] \n",
      "Epoch [2076], Loss1 : 1.219721, Loss2 : 0.032422, Train Loss : [0.03242] \n",
      "Epoch [2077], Loss1 : 1.222583, Loss2 : 0.032160, Train Loss : [0.03216] \n",
      "Epoch [2078], Loss1 : 1.240455, Loss2 : 0.031867, Train Loss : [0.03187] \n",
      "Epoch [2079], Loss1 : 1.240202, Loss2 : 0.031539, Train Loss : [0.03154] \n",
      "Epoch [2080], Loss1 : 1.209257, Loss2 : 0.031168, Train Loss : [0.03117] \n",
      "Epoch [2081], Loss1 : 1.237190, Loss2 : 0.030752, Train Loss : [0.03075] \n",
      "Epoch [2082], Loss1 : 1.229968, Loss2 : 0.030288, Train Loss : [0.03029] \n",
      "Epoch [2083], Loss1 : 1.221918, Loss2 : 0.029775, Train Loss : [0.02977] \n",
      "Epoch [2084], Loss1 : 1.227289, Loss2 : 0.029214, Train Loss : [0.02921] \n",
      "Epoch [2085], Loss1 : 1.203643, Loss2 : 0.028616, Train Loss : [0.02862] \n",
      "Epoch [2086], Loss1 : 1.200404, Loss2 : 0.028001, Train Loss : [0.02800] \n",
      "Epoch [2087], Loss1 : 1.215999, Loss2 : 0.027396, Train Loss : [0.02740] \n",
      "Epoch [2088], Loss1 : 1.215655, Loss2 : 0.026838, Train Loss : [0.02684] \n",
      "Epoch [2089], Loss1 : 1.227165, Loss2 : 0.026364, Train Loss : [0.02636] \n",
      "Epoch [2090], Loss1 : 1.204066, Loss2 : 0.025999, Train Loss : [0.02600] \n",
      "Epoch [2091], Loss1 : 1.199505, Loss2 : 0.025746, Train Loss : [0.02575] \n",
      "Epoch [2092], Loss1 : 1.208361, Loss2 : 0.025578, Train Loss : [0.02558] \n",
      "Epoch [2093], Loss1 : 1.228694, Loss2 : 0.025451, Train Loss : [0.02545] \n",
      "Epoch [2094], Loss1 : 1.213173, Loss2 : 0.025325, Train Loss : [0.02533] \n",
      "Epoch [2095], Loss1 : 1.223922, Loss2 : 0.025183, Train Loss : [0.02518] \n",
      "Epoch [2096], Loss1 : 1.224572, Loss2 : 0.025026, Train Loss : [0.02503] \n",
      "Epoch [2097], Loss1 : 1.193968, Loss2 : 0.024865, Train Loss : [0.02487] \n",
      "Epoch [2098], Loss1 : 1.231762, Loss2 : 0.024712, Train Loss : [0.02471] \n",
      "Epoch [2099], Loss1 : 1.215307, Loss2 : 0.024571, Train Loss : [0.02457] \n",
      "Epoch [2100], Loss1 : 1.211369, Loss2 : 0.024442, Train Loss : [0.02444] \n",
      "Epoch [2101], Loss1 : 1.216329, Loss2 : 0.024320, Train Loss : [0.02432] \n",
      "Epoch [2102], Loss1 : 1.227545, Loss2 : 0.024203, Train Loss : [0.02420] \n",
      "Epoch [2103], Loss1 : 1.227981, Loss2 : 0.024090, Train Loss : [0.02409] \n",
      "Epoch [2104], Loss1 : 1.211655, Loss2 : 0.023984, Train Loss : [0.02398] \n",
      "Epoch [2105], Loss1 : 1.233197, Loss2 : 0.023891, Train Loss : [0.02389] \n",
      "Epoch [2106], Loss1 : 1.215363, Loss2 : 0.023815, Train Loss : [0.02381] \n",
      "Epoch [2107], Loss1 : 1.243398, Loss2 : 0.023755, Train Loss : [0.02376] \n",
      "Epoch [2108], Loss1 : 1.228852, Loss2 : 0.023709, Train Loss : [0.02371] \n",
      "Epoch [2109], Loss1 : 1.266876, Loss2 : 0.023670, Train Loss : [0.02367] \n",
      "Epoch [2110], Loss1 : 1.247347, Loss2 : 0.023633, Train Loss : [0.02363] \n",
      "Epoch [2111], Loss1 : 1.207227, Loss2 : 0.023598, Train Loss : [0.02360] \n",
      "Epoch [2112], Loss1 : 1.254358, Loss2 : 0.023563, Train Loss : [0.02356] \n",
      "Epoch [2113], Loss1 : 1.214494, Loss2 : 0.023532, Train Loss : [0.02353] \n",
      "Epoch [2114], Loss1 : 1.215317, Loss2 : 0.023504, Train Loss : [0.02350] \n",
      "Epoch [2115], Loss1 : 1.230097, Loss2 : 0.023478, Train Loss : [0.02348] \n",
      "Epoch [2116], Loss1 : 1.243331, Loss2 : 0.023451, Train Loss : [0.02345] \n",
      "Epoch [2117], Loss1 : 1.189610, Loss2 : 0.023424, Train Loss : [0.02342] \n",
      "Epoch [2118], Loss1 : 1.232918, Loss2 : 0.023395, Train Loss : [0.02339] \n",
      "Epoch [2119], Loss1 : 1.222663, Loss2 : 0.023366, Train Loss : [0.02337] \n",
      "Epoch [2120], Loss1 : 1.228678, Loss2 : 0.023338, Train Loss : [0.02334] \n",
      "Epoch [2121], Loss1 : 1.166702, Loss2 : 0.023313, Train Loss : [0.02331] \n",
      "Epoch [2122], Loss1 : 1.194129, Loss2 : 0.023290, Train Loss : [0.02329] \n",
      "Epoch [2123], Loss1 : 1.213238, Loss2 : 0.023269, Train Loss : [0.02327] \n",
      "Epoch [2124], Loss1 : 1.219539, Loss2 : 0.023250, Train Loss : [0.02325] \n",
      "Epoch [2125], Loss1 : 1.232315, Loss2 : 0.023232, Train Loss : [0.02323] \n",
      "Epoch [2126], Loss1 : 1.182640, Loss2 : 0.023215, Train Loss : [0.02322] \n",
      "Epoch [2127], Loss1 : 1.223373, Loss2 : 0.023199, Train Loss : [0.02320] \n",
      "Epoch [2128], Loss1 : 1.243702, Loss2 : 0.023184, Train Loss : [0.02318] \n",
      "Epoch [2129], Loss1 : 1.225725, Loss2 : 0.023169, Train Loss : [0.02317] \n",
      "Epoch [2130], Loss1 : 1.200709, Loss2 : 0.023154, Train Loss : [0.02315] \n",
      "Epoch [2131], Loss1 : 1.209502, Loss2 : 0.023139, Train Loss : [0.02314] \n",
      "Epoch [2132], Loss1 : 1.219525, Loss2 : 0.023125, Train Loss : [0.02312] \n",
      "Epoch [2133], Loss1 : 1.219859, Loss2 : 0.023110, Train Loss : [0.02311] \n",
      "Epoch [2134], Loss1 : 1.193439, Loss2 : 0.023096, Train Loss : [0.02310] \n",
      "Epoch [2135], Loss1 : 1.230048, Loss2 : 0.023081, Train Loss : [0.02308] \n",
      "Epoch [2136], Loss1 : 1.237904, Loss2 : 0.023067, Train Loss : [0.02307] \n",
      "Epoch [2137], Loss1 : 1.237591, Loss2 : 0.023053, Train Loss : [0.02305] \n",
      "Epoch [2138], Loss1 : 1.234210, Loss2 : 0.023040, Train Loss : [0.02304] \n",
      "Epoch [2139], Loss1 : 1.230656, Loss2 : 0.023028, Train Loss : [0.02303] \n",
      "Epoch [2140], Loss1 : 1.238771, Loss2 : 0.023017, Train Loss : [0.02302] \n",
      "Epoch [2141], Loss1 : 1.253851, Loss2 : 0.023005, Train Loss : [0.02301] \n",
      "Epoch [2142], Loss1 : 1.238443, Loss2 : 0.022994, Train Loss : [0.02299] \n",
      "Epoch [2143], Loss1 : 1.227812, Loss2 : 0.022983, Train Loss : [0.02298] \n",
      "Epoch [2144], Loss1 : 1.212106, Loss2 : 0.022972, Train Loss : [0.02297] \n",
      "Epoch [2145], Loss1 : 1.219160, Loss2 : 0.022962, Train Loss : [0.02296] \n",
      "Epoch [2146], Loss1 : 1.223157, Loss2 : 0.022952, Train Loss : [0.02295] \n",
      "Epoch [2147], Loss1 : 1.190574, Loss2 : 0.022943, Train Loss : [0.02294] \n",
      "Epoch [2148], Loss1 : 1.240771, Loss2 : 0.022934, Train Loss : [0.02293] \n",
      "Epoch [2149], Loss1 : 1.223151, Loss2 : 0.022927, Train Loss : [0.02293] \n",
      "Epoch [2150], Loss1 : 1.203519, Loss2 : 0.022922, Train Loss : [0.02292] \n",
      "Epoch [2151], Loss1 : 1.186445, Loss2 : 0.022921, Train Loss : [0.02292] \n",
      "Epoch [2152], Loss1 : 1.215531, Loss2 : 0.022927, Train Loss : [0.02293] \n",
      "Epoch [2153], Loss1 : 1.183662, Loss2 : 0.022945, Train Loss : [0.02294] \n",
      "Epoch [2154], Loss1 : 1.230400, Loss2 : 0.022983, Train Loss : [0.02298] \n",
      "Epoch [2155], Loss1 : 1.229038, Loss2 : 0.023057, Train Loss : [0.02306] \n",
      "Epoch [2156], Loss1 : 1.231026, Loss2 : 0.023187, Train Loss : [0.02319] \n",
      "Epoch [2157], Loss1 : 1.190956, Loss2 : 0.023397, Train Loss : [0.02340] \n",
      "Epoch [2158], Loss1 : 1.227231, Loss2 : 0.023682, Train Loss : [0.02368] \n",
      "Epoch [2159], Loss1 : 1.222336, Loss2 : 0.023949, Train Loss : [0.02395] \n",
      "Epoch [2160], Loss1 : 1.216793, Loss2 : 0.023971, Train Loss : [0.02397] \n",
      "Epoch [2161], Loss1 : 1.212687, Loss2 : 0.023565, Train Loss : [0.02356] \n",
      "Epoch [2162], Loss1 : 1.215988, Loss2 : 0.022996, Train Loss : [0.02300] \n",
      "Epoch [2163], Loss1 : 1.227171, Loss2 : 0.022845, Train Loss : [0.02284] \n",
      "Epoch [2164], Loss1 : 1.245203, Loss2 : 0.023142, Train Loss : [0.02314] \n",
      "Epoch [2165], Loss1 : 1.243511, Loss2 : 0.023262, Train Loss : [0.02326] \n",
      "Epoch [2166], Loss1 : 1.242731, Loss2 : 0.022966, Train Loss : [0.02297] \n",
      "Epoch [2167], Loss1 : 1.257265, Loss2 : 0.022793, Train Loss : [0.02279] \n",
      "Epoch [2168], Loss1 : 1.248774, Loss2 : 0.022982, Train Loss : [0.02298] \n",
      "Epoch [2169], Loss1 : 1.232579, Loss2 : 0.023012, Train Loss : [0.02301] \n",
      "Epoch [2170], Loss1 : 1.220773, Loss2 : 0.022798, Train Loss : [0.02280] \n",
      "Epoch [2171], Loss1 : 1.277117, Loss2 : 0.022819, Train Loss : [0.02282] \n",
      "Epoch [2172], Loss1 : 1.216967, Loss2 : 0.022920, Train Loss : [0.02292] \n",
      "Epoch [2173], Loss1 : 1.232369, Loss2 : 0.022795, Train Loss : [0.02279] \n",
      "Epoch [2174], Loss1 : 1.219503, Loss2 : 0.022773, Train Loss : [0.02277] \n",
      "Epoch [2175], Loss1 : 1.241198, Loss2 : 0.022851, Train Loss : [0.02285] \n",
      "Epoch [2176], Loss1 : 1.215542, Loss2 : 0.022762, Train Loss : [0.02276] \n",
      "Epoch [2177], Loss1 : 1.224476, Loss2 : 0.022748, Train Loss : [0.02275] \n",
      "Epoch [2178], Loss1 : 1.241993, Loss2 : 0.022802, Train Loss : [0.02280] \n",
      "Epoch [2179], Loss1 : 1.203260, Loss2 : 0.022734, Train Loss : [0.02273] \n",
      "Epoch [2180], Loss1 : 1.233396, Loss2 : 0.022733, Train Loss : [0.02273] \n",
      "Epoch [2181], Loss1 : 1.205715, Loss2 : 0.022763, Train Loss : [0.02276] \n",
      "Epoch [2182], Loss1 : 1.226704, Loss2 : 0.022708, Train Loss : [0.02271] \n",
      "Epoch [2183], Loss1 : 1.162757, Loss2 : 0.022721, Train Loss : [0.02272] \n",
      "Epoch [2184], Loss1 : 1.236575, Loss2 : 0.022730, Train Loss : [0.02273] \n",
      "Epoch [2185], Loss1 : 1.193463, Loss2 : 0.022690, Train Loss : [0.02269] \n",
      "Epoch [2186], Loss1 : 1.249771, Loss2 : 0.022710, Train Loss : [0.02271] \n",
      "Epoch [2187], Loss1 : 1.190058, Loss2 : 0.022700, Train Loss : [0.02270] \n",
      "Epoch [2188], Loss1 : 1.192960, Loss2 : 0.022679, Train Loss : [0.02268] \n",
      "Epoch [2189], Loss1 : 1.186941, Loss2 : 0.022696, Train Loss : [0.02270] \n",
      "Epoch [2190], Loss1 : 1.235239, Loss2 : 0.022676, Train Loss : [0.02268] \n",
      "Epoch [2191], Loss1 : 1.225434, Loss2 : 0.022670, Train Loss : [0.02267] \n",
      "Epoch [2192], Loss1 : 1.220254, Loss2 : 0.022679, Train Loss : [0.02268] \n",
      "Epoch [2193], Loss1 : 1.240902, Loss2 : 0.022660, Train Loss : [0.02266] \n",
      "Epoch [2194], Loss1 : 1.212044, Loss2 : 0.022663, Train Loss : [0.02266] \n",
      "Epoch [2195], Loss1 : 1.196965, Loss2 : 0.022661, Train Loss : [0.02266] \n",
      "Epoch [2196], Loss1 : 1.219621, Loss2 : 0.022648, Train Loss : [0.02265] \n",
      "Epoch [2197], Loss1 : 1.207235, Loss2 : 0.022654, Train Loss : [0.02265] \n",
      "Epoch [2198], Loss1 : 1.219996, Loss2 : 0.022646, Train Loss : [0.02265] \n",
      "Epoch [2199], Loss1 : 1.226331, Loss2 : 0.022641, Train Loss : [0.02264] \n",
      "Epoch [2200], Loss1 : 1.231132, Loss2 : 0.022643, Train Loss : [0.02264] \n",
      "Epoch [2201], Loss1 : 1.215448, Loss2 : 0.022634, Train Loss : [0.02263] \n",
      "Epoch [2202], Loss1 : 1.263596, Loss2 : 0.022633, Train Loss : [0.02263] \n",
      "Epoch [2203], Loss1 : 1.197389, Loss2 : 0.022632, Train Loss : [0.02263] \n",
      "Epoch [2204], Loss1 : 1.229156, Loss2 : 0.022625, Train Loss : [0.02263] \n",
      "Epoch [2205], Loss1 : 1.205325, Loss2 : 0.022626, Train Loss : [0.02263] \n",
      "Epoch [2206], Loss1 : 1.232654, Loss2 : 0.022622, Train Loss : [0.02262] \n",
      "Epoch [2207], Loss1 : 1.215343, Loss2 : 0.022618, Train Loss : [0.02262] \n",
      "Epoch [2208], Loss1 : 1.223937, Loss2 : 0.022618, Train Loss : [0.02262] \n",
      "Epoch [2209], Loss1 : 1.211576, Loss2 : 0.022613, Train Loss : [0.02261] \n",
      "Epoch [2210], Loss1 : 1.219875, Loss2 : 0.022612, Train Loss : [0.02261] \n",
      "Epoch [2211], Loss1 : 1.229313, Loss2 : 0.022610, Train Loss : [0.02261] \n",
      "Epoch [2212], Loss1 : 1.204498, Loss2 : 0.022606, Train Loss : [0.02261] \n",
      "Epoch [2213], Loss1 : 1.241729, Loss2 : 0.022606, Train Loss : [0.02261] \n",
      "Epoch [2214], Loss1 : 1.246597, Loss2 : 0.022603, Train Loss : [0.02260] \n",
      "Epoch [2215], Loss1 : 1.221676, Loss2 : 0.022600, Train Loss : [0.02260] \n",
      "Epoch [2216], Loss1 : 1.259833, Loss2 : 0.022600, Train Loss : [0.02260] \n",
      "Epoch [2217], Loss1 : 1.258695, Loss2 : 0.022597, Train Loss : [0.02260] \n",
      "Epoch [2218], Loss1 : 1.213305, Loss2 : 0.022595, Train Loss : [0.02260] \n",
      "Epoch [2219], Loss1 : 1.210777, Loss2 : 0.022594, Train Loss : [0.02259] \n",
      "Epoch [2220], Loss1 : 1.197596, Loss2 : 0.022591, Train Loss : [0.02259] \n",
      "Epoch [2221], Loss1 : 1.215245, Loss2 : 0.022590, Train Loss : [0.02259] \n",
      "Epoch [2222], Loss1 : 1.222531, Loss2 : 0.022589, Train Loss : [0.02259] \n",
      "Epoch [2223], Loss1 : 1.219990, Loss2 : 0.022587, Train Loss : [0.02259] \n",
      "Epoch [2224], Loss1 : 1.212741, Loss2 : 0.022586, Train Loss : [0.02259] \n",
      "Epoch [2225], Loss1 : 1.222840, Loss2 : 0.022584, Train Loss : [0.02258] \n",
      "Epoch [2226], Loss1 : 1.254016, Loss2 : 0.022582, Train Loss : [0.02258] \n",
      "Epoch [2227], Loss1 : 1.225865, Loss2 : 0.022581, Train Loss : [0.02258] \n",
      "Epoch [2228], Loss1 : 1.237195, Loss2 : 0.022580, Train Loss : [0.02258] \n",
      "Epoch [2229], Loss1 : 1.235423, Loss2 : 0.022578, Train Loss : [0.02258] \n",
      "Epoch [2230], Loss1 : 1.217520, Loss2 : 0.022577, Train Loss : [0.02258] \n",
      "Epoch [2231], Loss1 : 1.236092, Loss2 : 0.022576, Train Loss : [0.02258] \n",
      "Epoch [2232], Loss1 : 1.230572, Loss2 : 0.022575, Train Loss : [0.02257] \n",
      "Epoch [2233], Loss1 : 1.229281, Loss2 : 0.022574, Train Loss : [0.02257] \n",
      "Epoch [2234], Loss1 : 1.221339, Loss2 : 0.022572, Train Loss : [0.02257] \n",
      "Epoch [2235], Loss1 : 1.207376, Loss2 : 0.022571, Train Loss : [0.02257] \n",
      "Epoch [2236], Loss1 : 1.224109, Loss2 : 0.022570, Train Loss : [0.02257] \n",
      "Epoch [2237], Loss1 : 1.202290, Loss2 : 0.022569, Train Loss : [0.02257] \n",
      "Epoch [2238], Loss1 : 1.229373, Loss2 : 0.022568, Train Loss : [0.02257] \n",
      "Epoch [2239], Loss1 : 1.222613, Loss2 : 0.022567, Train Loss : [0.02257] \n",
      "Epoch [2240], Loss1 : 1.206290, Loss2 : 0.022566, Train Loss : [0.02257] \n",
      "Epoch [2241], Loss1 : 1.199465, Loss2 : 0.022565, Train Loss : [0.02257] \n",
      "Epoch [2242], Loss1 : 1.203333, Loss2 : 0.022564, Train Loss : [0.02256] \n",
      "Epoch [2243], Loss1 : 1.224630, Loss2 : 0.022564, Train Loss : [0.02256] \n",
      "Epoch [2244], Loss1 : 1.231123, Loss2 : 0.022563, Train Loss : [0.02256] \n",
      "Epoch [2245], Loss1 : 1.215001, Loss2 : 0.022562, Train Loss : [0.02256] \n",
      "Epoch [2246], Loss1 : 1.206187, Loss2 : 0.022561, Train Loss : [0.02256] \n",
      "Epoch [2247], Loss1 : 1.232083, Loss2 : 0.022560, Train Loss : [0.02256] \n",
      "Epoch [2248], Loss1 : 1.222055, Loss2 : 0.022560, Train Loss : [0.02256] \n",
      "Epoch [2249], Loss1 : 1.192053, Loss2 : 0.022559, Train Loss : [0.02256] \n",
      "Epoch [2250], Loss1 : 1.239208, Loss2 : 0.022558, Train Loss : [0.02256] \n",
      "Epoch [2251], Loss1 : 1.239810, Loss2 : 0.022558, Train Loss : [0.02256] \n",
      "Epoch [2252], Loss1 : 1.246174, Loss2 : 0.022557, Train Loss : [0.02256] \n",
      "Epoch [2253], Loss1 : 1.213122, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [2254], Loss1 : 1.221740, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [2255], Loss1 : 1.203727, Loss2 : 0.022555, Train Loss : [0.02256] \n",
      "Epoch [2256], Loss1 : 1.222207, Loss2 : 0.022555, Train Loss : [0.02255] \n",
      "Epoch [2257], Loss1 : 1.218060, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [2258], Loss1 : 1.205973, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [2259], Loss1 : 1.205972, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [2260], Loss1 : 1.218268, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [2261], Loss1 : 1.226766, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2262], Loss1 : 1.205128, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2263], Loss1 : 1.222187, Loss2 : 0.022551, Train Loss : [0.02255] \n",
      "Epoch [2264], Loss1 : 1.204274, Loss2 : 0.022551, Train Loss : [0.02255] \n",
      "Epoch [2265], Loss1 : 1.209487, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2266], Loss1 : 1.252742, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2267], Loss1 : 1.236224, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2268], Loss1 : 1.202146, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [2269], Loss1 : 1.202157, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [2270], Loss1 : 1.232735, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2271], Loss1 : 1.224604, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2272], Loss1 : 1.213871, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2273], Loss1 : 1.213387, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2274], Loss1 : 1.172853, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2275], Loss1 : 1.241132, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2276], Loss1 : 1.223684, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2277], Loss1 : 1.226629, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2278], Loss1 : 1.232068, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2279], Loss1 : 1.201523, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2280], Loss1 : 1.196563, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2281], Loss1 : 1.188242, Loss2 : 0.022545, Train Loss : [0.02255] \n",
      "Epoch [2282], Loss1 : 1.212817, Loss2 : 0.022545, Train Loss : [0.02255] \n",
      "Epoch [2283], Loss1 : 1.200923, Loss2 : 0.022545, Train Loss : [0.02254] \n",
      "Epoch [2284], Loss1 : 1.265425, Loss2 : 0.022545, Train Loss : [0.02254] \n",
      "Epoch [2285], Loss1 : 1.254064, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2286], Loss1 : 1.221952, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2287], Loss1 : 1.200448, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2288], Loss1 : 1.209633, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2289], Loss1 : 1.201240, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2290], Loss1 : 1.216958, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2291], Loss1 : 1.219647, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2292], Loss1 : 1.227227, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2293], Loss1 : 1.203250, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2294], Loss1 : 1.217915, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2295], Loss1 : 1.230454, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2296], Loss1 : 1.260900, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2297], Loss1 : 1.230586, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2298], Loss1 : 1.227908, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2299], Loss1 : 1.210388, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2300], Loss1 : 1.243191, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2301], Loss1 : 1.219063, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2302], Loss1 : 1.217099, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2303], Loss1 : 1.258853, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2304], Loss1 : 1.257850, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2305], Loss1 : 1.219524, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2306], Loss1 : 1.204672, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2307], Loss1 : 1.243917, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2308], Loss1 : 1.218552, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2309], Loss1 : 1.215935, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2310], Loss1 : 1.206046, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2311], Loss1 : 1.220024, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2312], Loss1 : 1.214568, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2313], Loss1 : 1.236430, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2314], Loss1 : 1.227269, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2315], Loss1 : 1.222252, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2316], Loss1 : 1.212325, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2317], Loss1 : 1.229538, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2318], Loss1 : 1.242653, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2319], Loss1 : 1.199775, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2320], Loss1 : 1.172658, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2321], Loss1 : 1.213895, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2322], Loss1 : 1.226602, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2323], Loss1 : 1.250058, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2324], Loss1 : 1.208496, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2325], Loss1 : 1.229379, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2326], Loss1 : 1.203934, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2327], Loss1 : 1.204512, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2328], Loss1 : 1.242605, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2329], Loss1 : 1.200550, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2330], Loss1 : 1.242021, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2331], Loss1 : 1.203905, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2332], Loss1 : 1.218497, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2333], Loss1 : 1.228783, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2334], Loss1 : 1.212351, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2335], Loss1 : 1.240888, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2336], Loss1 : 1.198673, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2337], Loss1 : 1.229305, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2338], Loss1 : 1.211339, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2339], Loss1 : 1.200415, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [2340], Loss1 : 1.226028, Loss2 : 0.022565, Train Loss : [0.02257] \n",
      "Epoch [2341], Loss1 : 1.235466, Loss2 : 0.022591, Train Loss : [0.02259] \n",
      "Epoch [2342], Loss1 : 1.211555, Loss2 : 0.022640, Train Loss : [0.02264] \n",
      "Epoch [2343], Loss1 : 1.221991, Loss2 : 0.022742, Train Loss : [0.02274] \n",
      "Epoch [2344], Loss1 : 1.230947, Loss2 : 0.022927, Train Loss : [0.02293] \n",
      "Epoch [2345], Loss1 : 1.235003, Loss2 : 0.023302, Train Loss : [0.02330] \n",
      "Epoch [2346], Loss1 : 1.246400, Loss2 : 0.023803, Train Loss : [0.02380] \n",
      "Epoch [2347], Loss1 : 1.233682, Loss2 : 0.024590, Train Loss : [0.02459] \n",
      "Epoch [2348], Loss1 : 1.229214, Loss2 : 0.024586, Train Loss : [0.02459] \n",
      "Epoch [2349], Loss1 : 1.211979, Loss2 : 0.024037, Train Loss : [0.02404] \n",
      "Epoch [2350], Loss1 : 1.208450, Loss2 : 0.022815, Train Loss : [0.02282] \n",
      "Epoch [2351], Loss1 : 1.209145, Loss2 : 0.022800, Train Loss : [0.02280] \n",
      "Epoch [2352], Loss1 : 1.192929, Loss2 : 0.023428, Train Loss : [0.02343] \n",
      "Epoch [2353], Loss1 : 1.228710, Loss2 : 0.023087, Train Loss : [0.02309] \n",
      "Epoch [2354], Loss1 : 1.212202, Loss2 : 0.022692, Train Loss : [0.02269] \n",
      "Epoch [2355], Loss1 : 1.230337, Loss2 : 0.022970, Train Loss : [0.02297] \n",
      "Epoch [2356], Loss1 : 1.221636, Loss2 : 0.022880, Train Loss : [0.02288] \n",
      "Epoch [2357], Loss1 : 1.217656, Loss2 : 0.022607, Train Loss : [0.02261] \n",
      "Epoch [2358], Loss1 : 1.232594, Loss2 : 0.022832, Train Loss : [0.02283] \n",
      "Epoch [2359], Loss1 : 1.229396, Loss2 : 0.022753, Train Loss : [0.02275] \n",
      "Epoch [2360], Loss1 : 1.212554, Loss2 : 0.022644, Train Loss : [0.02264] \n",
      "Epoch [2361], Loss1 : 1.236298, Loss2 : 0.022749, Train Loss : [0.02275] \n",
      "Epoch [2362], Loss1 : 1.230543, Loss2 : 0.022596, Train Loss : [0.02260] \n",
      "Epoch [2363], Loss1 : 1.240812, Loss2 : 0.022671, Train Loss : [0.02267] \n",
      "Epoch [2364], Loss1 : 1.220934, Loss2 : 0.022678, Train Loss : [0.02268] \n",
      "Epoch [2365], Loss1 : 1.216882, Loss2 : 0.022608, Train Loss : [0.02261] \n",
      "Epoch [2366], Loss1 : 1.216441, Loss2 : 0.022644, Train Loss : [0.02264] \n",
      "Epoch [2367], Loss1 : 1.212422, Loss2 : 0.022575, Train Loss : [0.02258] \n",
      "Epoch [2368], Loss1 : 1.213503, Loss2 : 0.022641, Train Loss : [0.02264] \n",
      "Epoch [2369], Loss1 : 1.237000, Loss2 : 0.022598, Train Loss : [0.02260] \n",
      "Epoch [2370], Loss1 : 1.213268, Loss2 : 0.022586, Train Loss : [0.02259] \n",
      "Epoch [2371], Loss1 : 1.248850, Loss2 : 0.022584, Train Loss : [0.02258] \n",
      "Epoch [2372], Loss1 : 1.220602, Loss2 : 0.022577, Train Loss : [0.02258] \n",
      "Epoch [2373], Loss1 : 1.233305, Loss2 : 0.022598, Train Loss : [0.02260] \n",
      "Epoch [2374], Loss1 : 1.223566, Loss2 : 0.022557, Train Loss : [0.02256] \n",
      "Epoch [2375], Loss1 : 1.223317, Loss2 : 0.022587, Train Loss : [0.02259] \n",
      "Epoch [2376], Loss1 : 1.235872, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2377], Loss1 : 1.215077, Loss2 : 0.022568, Train Loss : [0.02257] \n",
      "Epoch [2378], Loss1 : 1.213880, Loss2 : 0.022566, Train Loss : [0.02257] \n",
      "Epoch [2379], Loss1 : 1.205063, Loss2 : 0.022558, Train Loss : [0.02256] \n",
      "Epoch [2380], Loss1 : 1.227986, Loss2 : 0.022560, Train Loss : [0.02256] \n",
      "Epoch [2381], Loss1 : 1.183653, Loss2 : 0.022545, Train Loss : [0.02255] \n",
      "Epoch [2382], Loss1 : 1.234787, Loss2 : 0.022563, Train Loss : [0.02256] \n",
      "Epoch [2383], Loss1 : 1.222858, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [2384], Loss1 : 1.224009, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [2385], Loss1 : 1.220484, Loss2 : 0.022545, Train Loss : [0.02255] \n",
      "Epoch [2386], Loss1 : 1.187984, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2387], Loss1 : 1.184557, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2388], Loss1 : 1.216882, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2389], Loss1 : 1.247398, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2390], Loss1 : 1.224071, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2391], Loss1 : 1.230016, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2392], Loss1 : 1.237909, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2393], Loss1 : 1.204727, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2394], Loss1 : 1.206541, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2395], Loss1 : 1.215839, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2396], Loss1 : 1.225828, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2397], Loss1 : 1.208393, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2398], Loss1 : 1.232149, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2399], Loss1 : 1.237848, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2400], Loss1 : 1.225552, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2401], Loss1 : 1.223326, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2402], Loss1 : 1.221512, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2403], Loss1 : 1.214676, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2404], Loss1 : 1.219490, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2405], Loss1 : 1.210830, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2406], Loss1 : 1.215433, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2407], Loss1 : 1.223777, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2408], Loss1 : 1.193170, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2409], Loss1 : 1.238066, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2410], Loss1 : 1.218270, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2411], Loss1 : 1.249275, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2412], Loss1 : 1.254460, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2413], Loss1 : 1.193236, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2414], Loss1 : 1.217774, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2415], Loss1 : 1.281745, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2416], Loss1 : 1.235424, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2417], Loss1 : 1.216208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2418], Loss1 : 1.223481, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2419], Loss1 : 1.205318, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2420], Loss1 : 1.228710, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2421], Loss1 : 1.218315, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2422], Loss1 : 1.236102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2423], Loss1 : 1.212564, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2424], Loss1 : 1.227132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2425], Loss1 : 1.202266, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2426], Loss1 : 1.226122, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2427], Loss1 : 1.256030, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2428], Loss1 : 1.217577, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2429], Loss1 : 1.218753, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2430], Loss1 : 1.196257, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2431], Loss1 : 1.229096, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2432], Loss1 : 1.201329, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2433], Loss1 : 1.260471, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2434], Loss1 : 1.225185, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2435], Loss1 : 1.211083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2436], Loss1 : 1.197042, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2437], Loss1 : 1.223364, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2438], Loss1 : 1.206531, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2439], Loss1 : 1.217741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2440], Loss1 : 1.193780, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2441], Loss1 : 1.228786, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2442], Loss1 : 1.222605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2443], Loss1 : 1.229387, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2444], Loss1 : 1.224511, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2445], Loss1 : 1.210801, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2446], Loss1 : 1.220992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2447], Loss1 : 1.192626, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2448], Loss1 : 1.225887, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2449], Loss1 : 1.236757, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2450], Loss1 : 1.209454, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2451], Loss1 : 1.255206, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2452], Loss1 : 1.224626, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2453], Loss1 : 1.247360, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2454], Loss1 : 1.207481, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2455], Loss1 : 1.233067, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2456], Loss1 : 1.230158, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2457], Loss1 : 1.245990, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2458], Loss1 : 1.215182, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2459], Loss1 : 1.216742, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2460], Loss1 : 1.188083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2461], Loss1 : 1.245312, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2462], Loss1 : 1.221040, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2463], Loss1 : 1.234605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2464], Loss1 : 1.226746, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2465], Loss1 : 1.204635, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2466], Loss1 : 1.210443, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2467], Loss1 : 1.228953, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2468], Loss1 : 1.205977, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2469], Loss1 : 1.218540, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2470], Loss1 : 1.181171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2471], Loss1 : 1.226550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2472], Loss1 : 1.238600, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2473], Loss1 : 1.223949, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2474], Loss1 : 1.220714, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2475], Loss1 : 1.201722, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2476], Loss1 : 1.221036, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2477], Loss1 : 1.216594, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2478], Loss1 : 1.213536, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2479], Loss1 : 1.234758, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2480], Loss1 : 1.237956, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2481], Loss1 : 1.235765, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2482], Loss1 : 1.245883, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2483], Loss1 : 1.232141, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2484], Loss1 : 1.223158, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2485], Loss1 : 1.233085, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2486], Loss1 : 1.225680, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2487], Loss1 : 1.196611, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2488], Loss1 : 1.221684, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2489], Loss1 : 1.227896, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2490], Loss1 : 1.213126, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2491], Loss1 : 1.230373, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2492], Loss1 : 1.245480, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2493], Loss1 : 1.209736, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2494], Loss1 : 1.211169, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2495], Loss1 : 1.221662, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2496], Loss1 : 1.190209, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2497], Loss1 : 1.224011, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2498], Loss1 : 1.206790, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2499], Loss1 : 1.234438, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2500], Loss1 : 1.223154, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2501], Loss1 : 1.236325, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2502], Loss1 : 1.217993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2503], Loss1 : 1.240880, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2504], Loss1 : 1.220813, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2505], Loss1 : 1.226484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2506], Loss1 : 1.257121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2507], Loss1 : 1.251361, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2508], Loss1 : 1.246208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2509], Loss1 : 1.235769, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2510], Loss1 : 1.199442, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2511], Loss1 : 1.237170, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2512], Loss1 : 1.243033, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2513], Loss1 : 1.220022, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2514], Loss1 : 1.237421, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2515], Loss1 : 1.226994, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2516], Loss1 : 1.237330, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2517], Loss1 : 1.233390, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2518], Loss1 : 1.195986, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2519], Loss1 : 1.183122, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2520], Loss1 : 1.233955, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2521], Loss1 : 1.243246, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2522], Loss1 : 1.222837, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2523], Loss1 : 1.258877, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2524], Loss1 : 1.245329, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2525], Loss1 : 1.226418, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2526], Loss1 : 1.256318, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2527], Loss1 : 1.252764, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2528], Loss1 : 1.237442, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2529], Loss1 : 1.214426, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2530], Loss1 : 1.224015, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2531], Loss1 : 1.187132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2532], Loss1 : 1.205560, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2533], Loss1 : 1.242274, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2534], Loss1 : 1.237300, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2535], Loss1 : 1.212628, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2536], Loss1 : 1.231786, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2537], Loss1 : 1.230438, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2538], Loss1 : 1.207529, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2539], Loss1 : 1.243555, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2540], Loss1 : 1.201531, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2541], Loss1 : 1.216562, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2542], Loss1 : 1.207634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2543], Loss1 : 1.223831, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2544], Loss1 : 1.212960, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2545], Loss1 : 1.215046, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2546], Loss1 : 1.221473, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2547], Loss1 : 1.218456, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2548], Loss1 : 1.212267, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2549], Loss1 : 1.216362, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [2550], Loss1 : 1.205152, Loss2 : 0.022563, Train Loss : [0.02256] \n",
      "Epoch [2551], Loss1 : 1.213939, Loss2 : 0.022579, Train Loss : [0.02258] \n",
      "Epoch [2552], Loss1 : 1.218396, Loss2 : 0.022604, Train Loss : [0.02260] \n",
      "Epoch [2553], Loss1 : 1.203672, Loss2 : 0.022651, Train Loss : [0.02265] \n",
      "Epoch [2554], Loss1 : 1.242064, Loss2 : 0.022715, Train Loss : [0.02272] \n",
      "Epoch [2555], Loss1 : 1.231193, Loss2 : 0.022841, Train Loss : [0.02284] \n",
      "Epoch [2556], Loss1 : 1.210809, Loss2 : 0.022981, Train Loss : [0.02298] \n",
      "Epoch [2557], Loss1 : 1.245492, Loss2 : 0.023261, Train Loss : [0.02326] \n",
      "Epoch [2558], Loss1 : 1.223268, Loss2 : 0.023417, Train Loss : [0.02342] \n",
      "Epoch [2559], Loss1 : 1.251938, Loss2 : 0.023739, Train Loss : [0.02374] \n",
      "Epoch [2560], Loss1 : 1.235809, Loss2 : 0.023522, Train Loss : [0.02352] \n",
      "Epoch [2561], Loss1 : 1.204251, Loss2 : 0.023353, Train Loss : [0.02335] \n",
      "Epoch [2562], Loss1 : 1.183298, Loss2 : 0.022869, Train Loss : [0.02287] \n",
      "Epoch [2563], Loss1 : 1.215199, Loss2 : 0.022644, Train Loss : [0.02264] \n",
      "Epoch [2564], Loss1 : 1.212272, Loss2 : 0.022677, Train Loss : [0.02268] \n",
      "Epoch [2565], Loss1 : 1.208153, Loss2 : 0.022804, Train Loss : [0.02280] \n",
      "Epoch [2566], Loss1 : 1.227512, Loss2 : 0.022840, Train Loss : [0.02284] \n",
      "Epoch [2567], Loss1 : 1.212838, Loss2 : 0.022696, Train Loss : [0.02270] \n",
      "Epoch [2568], Loss1 : 1.241624, Loss2 : 0.022653, Train Loss : [0.02265] \n",
      "Epoch [2569], Loss1 : 1.207316, Loss2 : 0.022735, Train Loss : [0.02274] \n",
      "Epoch [2570], Loss1 : 1.208962, Loss2 : 0.022768, Train Loss : [0.02277] \n",
      "Epoch [2571], Loss1 : 1.247515, Loss2 : 0.022657, Train Loss : [0.02266] \n",
      "Epoch [2572], Loss1 : 1.211892, Loss2 : 0.022547, Train Loss : [0.02255] \n",
      "Epoch [2573], Loss1 : 1.206133, Loss2 : 0.022588, Train Loss : [0.02259] \n",
      "Epoch [2574], Loss1 : 1.216467, Loss2 : 0.022669, Train Loss : [0.02267] \n",
      "Epoch [2575], Loss1 : 1.231730, Loss2 : 0.022645, Train Loss : [0.02264] \n",
      "Epoch [2576], Loss1 : 1.230748, Loss2 : 0.022592, Train Loss : [0.02259] \n",
      "Epoch [2577], Loss1 : 1.231969, Loss2 : 0.022605, Train Loss : [0.02260] \n",
      "Epoch [2578], Loss1 : 1.207882, Loss2 : 0.022613, Train Loss : [0.02261] \n",
      "Epoch [2579], Loss1 : 1.235116, Loss2 : 0.022573, Train Loss : [0.02257] \n",
      "Epoch [2580], Loss1 : 1.226449, Loss2 : 0.022545, Train Loss : [0.02254] \n",
      "Epoch [2581], Loss1 : 1.225799, Loss2 : 0.022577, Train Loss : [0.02258] \n",
      "Epoch [2582], Loss1 : 1.204784, Loss2 : 0.022602, Train Loss : [0.02260] \n",
      "Epoch [2583], Loss1 : 1.255704, Loss2 : 0.022576, Train Loss : [0.02258] \n",
      "Epoch [2584], Loss1 : 1.227219, Loss2 : 0.022561, Train Loss : [0.02256] \n",
      "Epoch [2585], Loss1 : 1.196304, Loss2 : 0.022568, Train Loss : [0.02257] \n",
      "Epoch [2586], Loss1 : 1.232664, Loss2 : 0.022562, Train Loss : [0.02256] \n",
      "Epoch [2587], Loss1 : 1.215346, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2588], Loss1 : 1.206985, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2589], Loss1 : 1.204382, Loss2 : 0.022564, Train Loss : [0.02256] \n",
      "Epoch [2590], Loss1 : 1.228853, Loss2 : 0.022560, Train Loss : [0.02256] \n",
      "Epoch [2591], Loss1 : 1.216799, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2592], Loss1 : 1.195086, Loss2 : 0.022551, Train Loss : [0.02255] \n",
      "Epoch [2593], Loss1 : 1.230068, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [2594], Loss1 : 1.206622, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2595], Loss1 : 1.218045, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2596], Loss1 : 1.212814, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2597], Loss1 : 1.192435, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2598], Loss1 : 1.213207, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2599], Loss1 : 1.207610, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2600], Loss1 : 1.240032, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2601], Loss1 : 1.195099, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2602], Loss1 : 1.195829, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2603], Loss1 : 1.228842, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2604], Loss1 : 1.201151, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2605], Loss1 : 1.237403, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2606], Loss1 : 1.211164, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2607], Loss1 : 1.252336, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2608], Loss1 : 1.214981, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2609], Loss1 : 1.243263, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2610], Loss1 : 1.226107, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2611], Loss1 : 1.212554, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2612], Loss1 : 1.206799, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2613], Loss1 : 1.273150, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2614], Loss1 : 1.185603, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2615], Loss1 : 1.240786, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2616], Loss1 : 1.208368, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2617], Loss1 : 1.226207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2618], Loss1 : 1.243171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2619], Loss1 : 1.226521, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2620], Loss1 : 1.229429, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2621], Loss1 : 1.238299, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2622], Loss1 : 1.218922, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2623], Loss1 : 1.236111, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2624], Loss1 : 1.201505, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2625], Loss1 : 1.243061, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2626], Loss1 : 1.212030, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2627], Loss1 : 1.205131, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2628], Loss1 : 1.258877, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2629], Loss1 : 1.221517, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2630], Loss1 : 1.240218, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2631], Loss1 : 1.212944, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2632], Loss1 : 1.228317, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2633], Loss1 : 1.252448, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2634], Loss1 : 1.219263, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2635], Loss1 : 1.224093, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2636], Loss1 : 1.212619, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2637], Loss1 : 1.226173, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2638], Loss1 : 1.231893, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2639], Loss1 : 1.253338, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2640], Loss1 : 1.223233, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2641], Loss1 : 1.233646, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2642], Loss1 : 1.202548, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2643], Loss1 : 1.209792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2644], Loss1 : 1.214404, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2645], Loss1 : 1.219826, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2646], Loss1 : 1.245895, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2647], Loss1 : 1.192282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2648], Loss1 : 1.186775, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2649], Loss1 : 1.224125, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2650], Loss1 : 1.228226, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2651], Loss1 : 1.227386, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2652], Loss1 : 1.239343, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2653], Loss1 : 1.214749, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2654], Loss1 : 1.229292, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2655], Loss1 : 1.226535, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2656], Loss1 : 1.208390, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2657], Loss1 : 1.235459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2658], Loss1 : 1.251271, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2659], Loss1 : 1.183479, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2660], Loss1 : 1.217305, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2661], Loss1 : 1.246744, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2662], Loss1 : 1.224275, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2663], Loss1 : 1.185597, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2664], Loss1 : 1.238653, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2665], Loss1 : 1.251476, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2666], Loss1 : 1.202183, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2667], Loss1 : 1.205644, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2668], Loss1 : 1.223699, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2669], Loss1 : 1.220299, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2670], Loss1 : 1.214982, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2671], Loss1 : 1.239498, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2672], Loss1 : 1.242037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2673], Loss1 : 1.217707, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2674], Loss1 : 1.206897, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2675], Loss1 : 1.263559, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2676], Loss1 : 1.207839, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2677], Loss1 : 1.202959, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2678], Loss1 : 1.233836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2679], Loss1 : 1.219576, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2680], Loss1 : 1.267239, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2681], Loss1 : 1.226215, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2682], Loss1 : 1.256542, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2683], Loss1 : 1.243457, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2684], Loss1 : 1.228060, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2685], Loss1 : 1.283384, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2686], Loss1 : 1.217718, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2687], Loss1 : 1.238231, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2688], Loss1 : 1.234676, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2689], Loss1 : 1.260126, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2690], Loss1 : 1.212194, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2691], Loss1 : 1.205426, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2692], Loss1 : 1.208143, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2693], Loss1 : 1.211819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2694], Loss1 : 1.209822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2695], Loss1 : 1.215721, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2696], Loss1 : 1.202708, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2697], Loss1 : 1.220816, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2698], Loss1 : 1.234991, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2699], Loss1 : 1.205301, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2700], Loss1 : 1.218493, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2701], Loss1 : 1.232456, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2702], Loss1 : 1.266420, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2703], Loss1 : 1.223634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2704], Loss1 : 1.231622, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2705], Loss1 : 1.231701, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2706], Loss1 : 1.252216, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2707], Loss1 : 1.246827, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2708], Loss1 : 1.237493, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2709], Loss1 : 1.199803, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2710], Loss1 : 1.219801, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2711], Loss1 : 1.236889, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2712], Loss1 : 1.234312, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2713], Loss1 : 1.230946, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2714], Loss1 : 1.224610, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2715], Loss1 : 1.178609, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2716], Loss1 : 1.223739, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2717], Loss1 : 1.223281, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2718], Loss1 : 1.239956, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2719], Loss1 : 1.239871, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2720], Loss1 : 1.199686, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2721], Loss1 : 1.246472, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2722], Loss1 : 1.230054, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2723], Loss1 : 1.249117, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2724], Loss1 : 1.199342, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2725], Loss1 : 1.233634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2726], Loss1 : 1.191033, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2727], Loss1 : 1.193306, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2728], Loss1 : 1.232244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2729], Loss1 : 1.235076, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2730], Loss1 : 1.205897, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2731], Loss1 : 1.232064, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2732], Loss1 : 1.239436, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2733], Loss1 : 1.212512, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2734], Loss1 : 1.235965, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2735], Loss1 : 1.205066, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2736], Loss1 : 1.174924, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2737], Loss1 : 1.241616, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2738], Loss1 : 1.220263, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2739], Loss1 : 1.222123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2740], Loss1 : 1.241719, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2741], Loss1 : 1.207104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2742], Loss1 : 1.228178, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2743], Loss1 : 1.236606, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2744], Loss1 : 1.210340, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2745], Loss1 : 1.225414, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2746], Loss1 : 1.213190, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2747], Loss1 : 1.191067, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2748], Loss1 : 1.220335, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2749], Loss1 : 1.218690, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2750], Loss1 : 1.184244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2751], Loss1 : 1.219284, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2752], Loss1 : 1.225908, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2753], Loss1 : 1.216234, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2754], Loss1 : 1.225581, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2755], Loss1 : 1.236418, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2756], Loss1 : 1.188096, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2757], Loss1 : 1.223881, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2758], Loss1 : 1.215106, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2759], Loss1 : 1.256384, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2760], Loss1 : 1.200124, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2761], Loss1 : 1.166548, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2762], Loss1 : 1.205813, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2763], Loss1 : 1.239994, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2764], Loss1 : 1.231265, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2765], Loss1 : 1.214818, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2766], Loss1 : 1.213746, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2767], Loss1 : 1.225207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2768], Loss1 : 1.194411, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2769], Loss1 : 1.230065, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2770], Loss1 : 1.220881, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2771], Loss1 : 1.193066, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2772], Loss1 : 1.194713, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2773], Loss1 : 1.219337, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2774], Loss1 : 1.223249, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2775], Loss1 : 1.257285, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2776], Loss1 : 1.224231, Loss2 : 0.022546, Train Loss : [0.02255] \n",
      "Epoch [2777], Loss1 : 1.219116, Loss2 : 0.022550, Train Loss : [0.02255] \n",
      "Epoch [2778], Loss1 : 1.211190, Loss2 : 0.022556, Train Loss : [0.02256] \n",
      "Epoch [2779], Loss1 : 1.246507, Loss2 : 0.022566, Train Loss : [0.02257] \n",
      "Epoch [2780], Loss1 : 1.236999, Loss2 : 0.022581, Train Loss : [0.02258] \n",
      "Epoch [2781], Loss1 : 1.235036, Loss2 : 0.022603, Train Loss : [0.02260] \n",
      "Epoch [2782], Loss1 : 1.244559, Loss2 : 0.022641, Train Loss : [0.02264] \n",
      "Epoch [2783], Loss1 : 1.228679, Loss2 : 0.022691, Train Loss : [0.02269] \n",
      "Epoch [2784], Loss1 : 1.215591, Loss2 : 0.022775, Train Loss : [0.02278] \n",
      "Epoch [2785], Loss1 : 1.218671, Loss2 : 0.022871, Train Loss : [0.02287] \n",
      "Epoch [2786], Loss1 : 1.243953, Loss2 : 0.023023, Train Loss : [0.02302] \n",
      "Epoch [2787], Loss1 : 1.241574, Loss2 : 0.023127, Train Loss : [0.02313] \n",
      "Epoch [2788], Loss1 : 1.234747, Loss2 : 0.023261, Train Loss : [0.02326] \n",
      "Epoch [2789], Loss1 : 1.194625, Loss2 : 0.023183, Train Loss : [0.02318] \n",
      "Epoch [2790], Loss1 : 1.208966, Loss2 : 0.023057, Train Loss : [0.02306] \n",
      "Epoch [2791], Loss1 : 1.210863, Loss2 : 0.022776, Train Loss : [0.02278] \n",
      "Epoch [2792], Loss1 : 1.244295, Loss2 : 0.022589, Train Loss : [0.02259] \n",
      "Epoch [2793], Loss1 : 1.245494, Loss2 : 0.022559, Train Loss : [0.02256] \n",
      "Epoch [2794], Loss1 : 1.220396, Loss2 : 0.022655, Train Loss : [0.02266] \n",
      "Epoch [2795], Loss1 : 1.222470, Loss2 : 0.022755, Train Loss : [0.02275] \n",
      "Epoch [2796], Loss1 : 1.234469, Loss2 : 0.022721, Train Loss : [0.02272] \n",
      "Epoch [2797], Loss1 : 1.249482, Loss2 : 0.022635, Train Loss : [0.02264] \n",
      "Epoch [2798], Loss1 : 1.235832, Loss2 : 0.022573, Train Loss : [0.02257] \n",
      "Epoch [2799], Loss1 : 1.236200, Loss2 : 0.022589, Train Loss : [0.02259] \n",
      "Epoch [2800], Loss1 : 1.222927, Loss2 : 0.022622, Train Loss : [0.02262] \n",
      "Epoch [2801], Loss1 : 1.222612, Loss2 : 0.022609, Train Loss : [0.02261] \n",
      "Epoch [2802], Loss1 : 1.211578, Loss2 : 0.022590, Train Loss : [0.02259] \n",
      "Epoch [2803], Loss1 : 1.204129, Loss2 : 0.022591, Train Loss : [0.02259] \n",
      "Epoch [2804], Loss1 : 1.245713, Loss2 : 0.022597, Train Loss : [0.02260] \n",
      "Epoch [2805], Loss1 : 1.236274, Loss2 : 0.022573, Train Loss : [0.02257] \n",
      "Epoch [2806], Loss1 : 1.228139, Loss2 : 0.022548, Train Loss : [0.02255] \n",
      "Epoch [2807], Loss1 : 1.228385, Loss2 : 0.022561, Train Loss : [0.02256] \n",
      "Epoch [2808], Loss1 : 1.218044, Loss2 : 0.022588, Train Loss : [0.02259] \n",
      "Epoch [2809], Loss1 : 1.227376, Loss2 : 0.022584, Train Loss : [0.02258] \n",
      "Epoch [2810], Loss1 : 1.230241, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [2811], Loss1 : 1.239001, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2812], Loss1 : 1.212433, Loss2 : 0.022554, Train Loss : [0.02255] \n",
      "Epoch [2813], Loss1 : 1.218671, Loss2 : 0.022562, Train Loss : [0.02256] \n",
      "Epoch [2814], Loss1 : 1.245710, Loss2 : 0.022557, Train Loss : [0.02256] \n",
      "Epoch [2815], Loss1 : 1.210663, Loss2 : 0.022553, Train Loss : [0.02255] \n",
      "Epoch [2816], Loss1 : 1.220850, Loss2 : 0.022555, Train Loss : [0.02255] \n",
      "Epoch [2817], Loss1 : 1.207184, Loss2 : 0.022549, Train Loss : [0.02255] \n",
      "Epoch [2818], Loss1 : 1.230458, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2819], Loss1 : 1.236247, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2820], Loss1 : 1.249771, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2821], Loss1 : 1.220420, Loss2 : 0.022552, Train Loss : [0.02255] \n",
      "Epoch [2822], Loss1 : 1.246608, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2823], Loss1 : 1.229819, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2824], Loss1 : 1.212248, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2825], Loss1 : 1.248150, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2826], Loss1 : 1.203245, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2827], Loss1 : 1.206645, Loss2 : 0.022543, Train Loss : [0.02254] \n",
      "Epoch [2828], Loss1 : 1.235561, Loss2 : 0.022544, Train Loss : [0.02254] \n",
      "Epoch [2829], Loss1 : 1.258942, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2830], Loss1 : 1.215439, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2831], Loss1 : 1.207833, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2832], Loss1 : 1.236199, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2833], Loss1 : 1.201713, Loss2 : 0.022542, Train Loss : [0.02254] \n",
      "Epoch [2834], Loss1 : 1.223957, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2835], Loss1 : 1.229795, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2836], Loss1 : 1.249310, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2837], Loss1 : 1.231568, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2838], Loss1 : 1.224679, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2839], Loss1 : 1.218093, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2840], Loss1 : 1.213812, Loss2 : 0.022541, Train Loss : [0.02254] \n",
      "Epoch [2841], Loss1 : 1.220168, Loss2 : 0.022540, Train Loss : [0.02254] \n",
      "Epoch [2842], Loss1 : 1.228277, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2843], Loss1 : 1.205371, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2844], Loss1 : 1.213239, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2845], Loss1 : 1.237260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2846], Loss1 : 1.242322, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2847], Loss1 : 1.244029, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2848], Loss1 : 1.213351, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2849], Loss1 : 1.254236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2850], Loss1 : 1.224538, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2851], Loss1 : 1.203244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2852], Loss1 : 1.247856, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2853], Loss1 : 1.215878, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2854], Loss1 : 1.222426, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2855], Loss1 : 1.270997, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2856], Loss1 : 1.244741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2857], Loss1 : 1.239802, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2858], Loss1 : 1.194017, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2859], Loss1 : 1.248757, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2860], Loss1 : 1.219044, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2861], Loss1 : 1.214084, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2862], Loss1 : 1.256197, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2863], Loss1 : 1.228592, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2864], Loss1 : 1.232766, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2865], Loss1 : 1.219662, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2866], Loss1 : 1.225734, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2867], Loss1 : 1.218496, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2868], Loss1 : 1.224831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2869], Loss1 : 1.207537, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2870], Loss1 : 1.225998, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2871], Loss1 : 1.247225, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2872], Loss1 : 1.223547, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2873], Loss1 : 1.220953, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2874], Loss1 : 1.207419, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2875], Loss1 : 1.228155, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2876], Loss1 : 1.238585, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2877], Loss1 : 1.208061, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2878], Loss1 : 1.233944, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2879], Loss1 : 1.225332, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2880], Loss1 : 1.227833, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2881], Loss1 : 1.262362, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2882], Loss1 : 1.202568, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2883], Loss1 : 1.218268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2884], Loss1 : 1.231056, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2885], Loss1 : 1.227638, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2886], Loss1 : 1.205999, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2887], Loss1 : 1.225144, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2888], Loss1 : 1.257160, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2889], Loss1 : 1.228049, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2890], Loss1 : 1.229928, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2891], Loss1 : 1.217788, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2892], Loss1 : 1.241201, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2893], Loss1 : 1.225153, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2894], Loss1 : 1.210969, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2895], Loss1 : 1.224898, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2896], Loss1 : 1.235445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2897], Loss1 : 1.223938, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2898], Loss1 : 1.235651, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2899], Loss1 : 1.229236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2900], Loss1 : 1.241645, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2901], Loss1 : 1.202339, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2902], Loss1 : 1.215914, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2903], Loss1 : 1.213233, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2904], Loss1 : 1.178956, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2905], Loss1 : 1.230555, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2906], Loss1 : 1.240921, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2907], Loss1 : 1.215121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2908], Loss1 : 1.233165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2909], Loss1 : 1.227422, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2910], Loss1 : 1.230055, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2911], Loss1 : 1.224335, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2912], Loss1 : 1.250239, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2913], Loss1 : 1.247268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2914], Loss1 : 1.213861, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2915], Loss1 : 1.225626, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2916], Loss1 : 1.218005, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2917], Loss1 : 1.221499, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2918], Loss1 : 1.218686, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2919], Loss1 : 1.248707, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2920], Loss1 : 1.240034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2921], Loss1 : 1.220887, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2922], Loss1 : 1.195511, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2923], Loss1 : 1.219260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2924], Loss1 : 1.242136, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2925], Loss1 : 1.226412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2926], Loss1 : 1.241291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2927], Loss1 : 1.218886, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2928], Loss1 : 1.222583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2929], Loss1 : 1.221954, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2930], Loss1 : 1.239979, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2931], Loss1 : 1.219571, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2932], Loss1 : 1.241910, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2933], Loss1 : 1.210568, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2934], Loss1 : 1.208418, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2935], Loss1 : 1.236289, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2936], Loss1 : 1.211475, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2937], Loss1 : 1.240761, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2938], Loss1 : 1.234026, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2939], Loss1 : 1.204495, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2940], Loss1 : 1.223453, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2941], Loss1 : 1.233259, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2942], Loss1 : 1.234636, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2943], Loss1 : 1.229062, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2944], Loss1 : 1.258120, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2945], Loss1 : 1.217551, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2946], Loss1 : 1.205354, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2947], Loss1 : 1.204600, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2948], Loss1 : 1.237755, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2949], Loss1 : 1.229666, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2950], Loss1 : 1.241326, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2951], Loss1 : 1.219078, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2952], Loss1 : 1.224104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2953], Loss1 : 1.227096, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2954], Loss1 : 1.217904, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2955], Loss1 : 1.221318, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2956], Loss1 : 1.207254, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2957], Loss1 : 1.216219, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2958], Loss1 : 1.238286, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2959], Loss1 : 1.225677, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2960], Loss1 : 1.189209, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2961], Loss1 : 1.240458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2962], Loss1 : 1.219178, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2963], Loss1 : 1.227687, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2964], Loss1 : 1.206161, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2965], Loss1 : 1.249427, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2966], Loss1 : 1.213974, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2967], Loss1 : 1.213550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2968], Loss1 : 1.211102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2969], Loss1 : 1.228326, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2970], Loss1 : 1.208400, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2971], Loss1 : 1.220164, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2972], Loss1 : 1.196405, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2973], Loss1 : 1.224626, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2974], Loss1 : 1.234895, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2975], Loss1 : 1.203889, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2976], Loss1 : 1.206759, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2977], Loss1 : 1.204664, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2978], Loss1 : 1.244594, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2979], Loss1 : 1.219847, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2980], Loss1 : 1.221075, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2981], Loss1 : 1.223530, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2982], Loss1 : 1.211400, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2983], Loss1 : 1.209964, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2984], Loss1 : 1.203325, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2985], Loss1 : 1.210125, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2986], Loss1 : 1.225749, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2987], Loss1 : 1.192874, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2988], Loss1 : 1.215492, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2989], Loss1 : 1.218066, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2990], Loss1 : 1.235893, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2991], Loss1 : 1.219434, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2992], Loss1 : 1.195971, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2993], Loss1 : 1.194947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2994], Loss1 : 1.245412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2995], Loss1 : 1.189709, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2996], Loss1 : 1.222495, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2997], Loss1 : 1.229855, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2998], Loss1 : 1.211471, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [2999], Loss1 : 1.208503, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3000], Loss1 : 1.223578, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3001], Loss1 : 1.235831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3002], Loss1 : 1.191484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3003], Loss1 : 1.222766, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3004], Loss1 : 1.242237, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3005], Loss1 : 1.233966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3006], Loss1 : 1.247340, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3007], Loss1 : 1.247358, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3008], Loss1 : 1.262515, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3009], Loss1 : 1.230182, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3010], Loss1 : 1.216323, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3011], Loss1 : 1.240389, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3012], Loss1 : 1.190988, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3013], Loss1 : 1.232293, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3014], Loss1 : 1.237034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3015], Loss1 : 1.241847, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3016], Loss1 : 1.246940, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3017], Loss1 : 1.238210, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3018], Loss1 : 1.196856, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3019], Loss1 : 1.205956, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3020], Loss1 : 1.219575, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3021], Loss1 : 1.224768, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3022], Loss1 : 1.214831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3023], Loss1 : 1.194777, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3024], Loss1 : 1.263821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3025], Loss1 : 1.221066, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3026], Loss1 : 1.218347, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3027], Loss1 : 1.188826, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3028], Loss1 : 1.220969, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3029], Loss1 : 1.232743, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3030], Loss1 : 1.245528, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3031], Loss1 : 1.226204, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3032], Loss1 : 1.208794, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3033], Loss1 : 1.227647, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3034], Loss1 : 1.213485, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3035], Loss1 : 1.197819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3036], Loss1 : 1.259847, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3037], Loss1 : 1.191458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3038], Loss1 : 1.229886, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3039], Loss1 : 1.253705, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3040], Loss1 : 1.214687, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3041], Loss1 : 1.192048, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3042], Loss1 : 1.223037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3043], Loss1 : 1.192291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3044], Loss1 : 1.240720, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3045], Loss1 : 1.183506, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3046], Loss1 : 1.240873, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3047], Loss1 : 1.194301, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3048], Loss1 : 1.214726, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3049], Loss1 : 1.215477, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3050], Loss1 : 1.248027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3051], Loss1 : 1.201851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3052], Loss1 : 1.219541, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3053], Loss1 : 1.197677, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3054], Loss1 : 1.233278, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3055], Loss1 : 1.225165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3056], Loss1 : 1.217797, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3057], Loss1 : 1.238502, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3058], Loss1 : 1.250147, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3059], Loss1 : 1.215899, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3060], Loss1 : 1.229236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3061], Loss1 : 1.229853, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3062], Loss1 : 1.240741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3063], Loss1 : 1.210901, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3064], Loss1 : 1.247165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3065], Loss1 : 1.216867, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3066], Loss1 : 1.220585, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3067], Loss1 : 1.208224, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3068], Loss1 : 1.240416, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3069], Loss1 : 1.223704, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3070], Loss1 : 1.223805, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3071], Loss1 : 1.226102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3072], Loss1 : 1.214334, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3073], Loss1 : 1.230306, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3074], Loss1 : 1.207304, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3075], Loss1 : 1.239554, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3076], Loss1 : 1.219340, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3077], Loss1 : 1.215339, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3078], Loss1 : 1.217584, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3079], Loss1 : 1.219574, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3080], Loss1 : 1.195244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3081], Loss1 : 1.225167, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3082], Loss1 : 1.218847, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3083], Loss1 : 1.232575, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3084], Loss1 : 1.225451, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3085], Loss1 : 1.238966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3086], Loss1 : 1.219731, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3087], Loss1 : 1.223122, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3088], Loss1 : 1.226631, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3089], Loss1 : 1.223377, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3090], Loss1 : 1.239897, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3091], Loss1 : 1.221171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3092], Loss1 : 1.206268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3093], Loss1 : 1.176504, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3094], Loss1 : 1.204399, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3095], Loss1 : 1.225848, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3096], Loss1 : 1.240717, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3097], Loss1 : 1.243265, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3098], Loss1 : 1.232394, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3099], Loss1 : 1.206630, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3100], Loss1 : 1.216183, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3101], Loss1 : 1.245171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3102], Loss1 : 1.246734, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3103], Loss1 : 1.231298, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3104], Loss1 : 1.246830, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3105], Loss1 : 1.241526, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3106], Loss1 : 1.185815, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3107], Loss1 : 1.224713, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3108], Loss1 : 1.229604, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3109], Loss1 : 1.251815, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3110], Loss1 : 1.203881, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3111], Loss1 : 1.218898, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3112], Loss1 : 1.223489, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3113], Loss1 : 1.236406, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3114], Loss1 : 1.222488, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3115], Loss1 : 1.200453, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3116], Loss1 : 1.222977, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3117], Loss1 : 1.227188, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3118], Loss1 : 1.222744, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3119], Loss1 : 1.232941, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3120], Loss1 : 1.210643, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3121], Loss1 : 1.223184, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3122], Loss1 : 1.258217, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3123], Loss1 : 1.214823, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3124], Loss1 : 1.233005, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3125], Loss1 : 1.211718, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3126], Loss1 : 1.204142, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3127], Loss1 : 1.231169, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3128], Loss1 : 1.229747, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3129], Loss1 : 1.218833, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3130], Loss1 : 1.235855, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3131], Loss1 : 1.226144, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3132], Loss1 : 1.252975, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3133], Loss1 : 1.246094, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3134], Loss1 : 1.175747, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3135], Loss1 : 1.199646, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3136], Loss1 : 1.221775, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3137], Loss1 : 1.226633, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3138], Loss1 : 1.206187, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3139], Loss1 : 1.230417, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3140], Loss1 : 1.234468, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3141], Loss1 : 1.192600, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3142], Loss1 : 1.234832, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3143], Loss1 : 1.214607, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3144], Loss1 : 1.239835, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3145], Loss1 : 1.244170, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3146], Loss1 : 1.210703, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3147], Loss1 : 1.225249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3148], Loss1 : 1.205270, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3149], Loss1 : 1.207194, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3150], Loss1 : 1.180547, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3151], Loss1 : 1.215026, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3152], Loss1 : 1.205031, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3153], Loss1 : 1.235469, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3154], Loss1 : 1.220010, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3155], Loss1 : 1.240231, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3156], Loss1 : 1.218666, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3157], Loss1 : 1.219205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3158], Loss1 : 1.241134, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3159], Loss1 : 1.226828, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3160], Loss1 : 1.247205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3161], Loss1 : 1.190348, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3162], Loss1 : 1.237961, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3163], Loss1 : 1.218206, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3164], Loss1 : 1.224381, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3165], Loss1 : 1.200836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3166], Loss1 : 1.186929, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3167], Loss1 : 1.219087, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3168], Loss1 : 1.190142, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3169], Loss1 : 1.212210, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3170], Loss1 : 1.239359, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3171], Loss1 : 1.239559, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3172], Loss1 : 1.240995, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3173], Loss1 : 1.214522, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3174], Loss1 : 1.201034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3175], Loss1 : 1.254962, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3176], Loss1 : 1.216554, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3177], Loss1 : 1.229392, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3178], Loss1 : 1.226992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3179], Loss1 : 1.209973, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3180], Loss1 : 1.206336, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3181], Loss1 : 1.216510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3182], Loss1 : 1.215282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3183], Loss1 : 1.184493, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3184], Loss1 : 1.188158, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3185], Loss1 : 1.186057, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3186], Loss1 : 1.213412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3187], Loss1 : 1.226992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3188], Loss1 : 1.184728, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3189], Loss1 : 1.230568, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3190], Loss1 : 1.218586, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3191], Loss1 : 1.239631, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3192], Loss1 : 1.221895, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3193], Loss1 : 1.224609, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3194], Loss1 : 1.247304, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3195], Loss1 : 1.208269, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3196], Loss1 : 1.246890, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3197], Loss1 : 1.222217, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3198], Loss1 : 1.226009, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3199], Loss1 : 1.224819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3200], Loss1 : 1.221361, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3201], Loss1 : 1.237731, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3202], Loss1 : 1.220416, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3203], Loss1 : 1.246714, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3204], Loss1 : 1.242920, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3205], Loss1 : 1.229856, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3206], Loss1 : 1.237933, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3207], Loss1 : 1.242864, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3208], Loss1 : 1.194975, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3209], Loss1 : 1.230997, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3210], Loss1 : 1.246294, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3211], Loss1 : 1.232103, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3212], Loss1 : 1.230916, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3213], Loss1 : 1.208102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3214], Loss1 : 1.240131, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3215], Loss1 : 1.237026, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3216], Loss1 : 1.216207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3217], Loss1 : 1.200753, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3218], Loss1 : 1.208769, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3219], Loss1 : 1.229223, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3220], Loss1 : 1.242699, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3221], Loss1 : 1.220200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3222], Loss1 : 1.235010, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3223], Loss1 : 1.205687, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3224], Loss1 : 1.218869, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3225], Loss1 : 1.219891, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3226], Loss1 : 1.230349, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3227], Loss1 : 1.216370, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3228], Loss1 : 1.213931, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3229], Loss1 : 1.210130, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3230], Loss1 : 1.225287, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3231], Loss1 : 1.202933, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3232], Loss1 : 1.230311, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3233], Loss1 : 1.230222, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3234], Loss1 : 1.247923, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3235], Loss1 : 1.196037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3236], Loss1 : 1.221303, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3237], Loss1 : 1.250159, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3238], Loss1 : 1.209011, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3239], Loss1 : 1.237000, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3240], Loss1 : 1.218309, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3241], Loss1 : 1.248565, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3242], Loss1 : 1.205271, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3243], Loss1 : 1.186192, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3244], Loss1 : 1.213693, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3245], Loss1 : 1.222512, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3246], Loss1 : 1.234937, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3247], Loss1 : 1.215570, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3248], Loss1 : 1.200947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3249], Loss1 : 1.223702, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3250], Loss1 : 1.240820, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3251], Loss1 : 1.212939, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3252], Loss1 : 1.254872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3253], Loss1 : 1.232180, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3254], Loss1 : 1.224070, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3255], Loss1 : 1.236117, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3256], Loss1 : 1.213966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3257], Loss1 : 1.209836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3258], Loss1 : 1.213465, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3259], Loss1 : 1.227003, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3260], Loss1 : 1.233998, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3261], Loss1 : 1.213689, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3262], Loss1 : 1.219135, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3263], Loss1 : 1.210793, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3264], Loss1 : 1.251435, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3265], Loss1 : 1.236225, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3266], Loss1 : 1.232199, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3267], Loss1 : 1.228394, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3268], Loss1 : 1.198841, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3269], Loss1 : 1.219034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3270], Loss1 : 1.221510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3271], Loss1 : 1.202629, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3272], Loss1 : 1.218747, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3273], Loss1 : 1.195407, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3274], Loss1 : 1.244236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3275], Loss1 : 1.204071, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3276], Loss1 : 1.242427, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3277], Loss1 : 1.241861, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3278], Loss1 : 1.217579, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3279], Loss1 : 1.218963, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3280], Loss1 : 1.240020, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3281], Loss1 : 1.245605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3282], Loss1 : 1.228727, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3283], Loss1 : 1.204605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3284], Loss1 : 1.240831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3285], Loss1 : 1.242449, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3286], Loss1 : 1.165423, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3287], Loss1 : 1.238195, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3288], Loss1 : 1.233198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3289], Loss1 : 1.216029, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3290], Loss1 : 1.230227, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3291], Loss1 : 1.222126, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3292], Loss1 : 1.224135, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3293], Loss1 : 1.218962, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3294], Loss1 : 1.237069, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3295], Loss1 : 1.228434, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3296], Loss1 : 1.195264, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3297], Loss1 : 1.231737, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3298], Loss1 : 1.212520, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3299], Loss1 : 1.211367, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3300], Loss1 : 1.217552, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3301], Loss1 : 1.225418, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3302], Loss1 : 1.190250, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3303], Loss1 : 1.221154, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3304], Loss1 : 1.242839, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3305], Loss1 : 1.245558, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3306], Loss1 : 1.220340, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3307], Loss1 : 1.178703, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3308], Loss1 : 1.271556, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3309], Loss1 : 1.234278, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3310], Loss1 : 1.209266, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3311], Loss1 : 1.246745, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3312], Loss1 : 1.225476, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3313], Loss1 : 1.235684, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3314], Loss1 : 1.226826, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3315], Loss1 : 1.257311, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3316], Loss1 : 1.169060, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3317], Loss1 : 1.242177, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3318], Loss1 : 1.204894, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3319], Loss1 : 1.249424, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3320], Loss1 : 1.201104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3321], Loss1 : 1.197579, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3322], Loss1 : 1.189145, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3323], Loss1 : 1.234576, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3324], Loss1 : 1.242114, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3325], Loss1 : 1.225932, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3326], Loss1 : 1.264447, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3327], Loss1 : 1.213315, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3328], Loss1 : 1.215509, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3329], Loss1 : 1.233897, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3330], Loss1 : 1.215386, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3331], Loss1 : 1.217768, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3332], Loss1 : 1.192391, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3333], Loss1 : 1.200980, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3334], Loss1 : 1.214497, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3335], Loss1 : 1.222903, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3336], Loss1 : 1.226478, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3337], Loss1 : 1.214327, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3338], Loss1 : 1.219249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3339], Loss1 : 1.210423, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3340], Loss1 : 1.210543, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3341], Loss1 : 1.253809, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3342], Loss1 : 1.210837, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3343], Loss1 : 1.208560, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3344], Loss1 : 1.191691, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3345], Loss1 : 1.255981, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3346], Loss1 : 1.238399, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3347], Loss1 : 1.233692, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3348], Loss1 : 1.239729, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3349], Loss1 : 1.211550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3350], Loss1 : 1.236653, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3351], Loss1 : 1.252685, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3352], Loss1 : 1.244223, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3353], Loss1 : 1.226023, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3354], Loss1 : 1.243457, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3355], Loss1 : 1.183689, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3356], Loss1 : 1.230152, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3357], Loss1 : 1.202557, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3358], Loss1 : 1.234926, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3359], Loss1 : 1.229961, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3360], Loss1 : 1.209004, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3361], Loss1 : 1.236781, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3362], Loss1 : 1.206004, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3363], Loss1 : 1.206490, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3364], Loss1 : 1.200024, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3365], Loss1 : 1.189916, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3366], Loss1 : 1.256539, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3367], Loss1 : 1.214446, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3368], Loss1 : 1.240793, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3369], Loss1 : 1.232987, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3370], Loss1 : 1.177985, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3371], Loss1 : 1.222905, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3372], Loss1 : 1.209026, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3373], Loss1 : 1.222237, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3374], Loss1 : 1.224207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3375], Loss1 : 1.227357, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3376], Loss1 : 1.216807, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3377], Loss1 : 1.211596, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3378], Loss1 : 1.236968, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3379], Loss1 : 1.254112, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3380], Loss1 : 1.210322, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3381], Loss1 : 1.216249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3382], Loss1 : 1.231746, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3383], Loss1 : 1.222510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3384], Loss1 : 1.207978, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3385], Loss1 : 1.191842, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3386], Loss1 : 1.221933, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3387], Loss1 : 1.228968, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3388], Loss1 : 1.209350, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3389], Loss1 : 1.214872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3390], Loss1 : 1.229896, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3391], Loss1 : 1.192121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3392], Loss1 : 1.218379, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3393], Loss1 : 1.229144, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3394], Loss1 : 1.217982, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3395], Loss1 : 1.233098, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3396], Loss1 : 1.225604, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3397], Loss1 : 1.246915, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3398], Loss1 : 1.242119, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3399], Loss1 : 1.225298, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3400], Loss1 : 1.220529, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3401], Loss1 : 1.219852, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3402], Loss1 : 1.215877, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3403], Loss1 : 1.233779, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3404], Loss1 : 1.192214, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3405], Loss1 : 1.249698, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3406], Loss1 : 1.216865, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3407], Loss1 : 1.222559, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3408], Loss1 : 1.224027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3409], Loss1 : 1.253792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3410], Loss1 : 1.245009, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3411], Loss1 : 1.230512, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3412], Loss1 : 1.223828, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3413], Loss1 : 1.207146, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3414], Loss1 : 1.251059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3415], Loss1 : 1.213947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3416], Loss1 : 1.163717, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3417], Loss1 : 1.215590, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3418], Loss1 : 1.222143, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3419], Loss1 : 1.243536, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3420], Loss1 : 1.189912, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3421], Loss1 : 1.224735, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3422], Loss1 : 1.251121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3423], Loss1 : 1.237851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3424], Loss1 : 1.211875, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3425], Loss1 : 1.224450, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3426], Loss1 : 1.238542, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3427], Loss1 : 1.243625, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3428], Loss1 : 1.217964, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3429], Loss1 : 1.206981, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3430], Loss1 : 1.189039, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3431], Loss1 : 1.236297, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3432], Loss1 : 1.233880, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3433], Loss1 : 1.225727, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3434], Loss1 : 1.202156, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3435], Loss1 : 1.210225, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3436], Loss1 : 1.221838, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3437], Loss1 : 1.206412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3438], Loss1 : 1.234454, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3439], Loss1 : 1.215809, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3440], Loss1 : 1.241100, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3441], Loss1 : 1.252043, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3442], Loss1 : 1.184990, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3443], Loss1 : 1.226420, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3444], Loss1 : 1.188034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3445], Loss1 : 1.229263, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3446], Loss1 : 1.226925, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3447], Loss1 : 1.209459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3448], Loss1 : 1.200908, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3449], Loss1 : 1.199181, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3450], Loss1 : 1.205899, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3451], Loss1 : 1.217639, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3452], Loss1 : 1.201289, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3453], Loss1 : 1.248591, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3454], Loss1 : 1.227075, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3455], Loss1 : 1.206882, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3456], Loss1 : 1.226301, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3457], Loss1 : 1.256205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3458], Loss1 : 1.227991, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3459], Loss1 : 1.191830, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3460], Loss1 : 1.225926, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3461], Loss1 : 1.241244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3462], Loss1 : 1.196146, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3463], Loss1 : 1.221814, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3464], Loss1 : 1.240634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3465], Loss1 : 1.214379, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3466], Loss1 : 1.207776, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3467], Loss1 : 1.202716, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3468], Loss1 : 1.210732, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3469], Loss1 : 1.207445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3470], Loss1 : 1.227592, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3471], Loss1 : 1.216234, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3472], Loss1 : 1.220948, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3473], Loss1 : 1.225366, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3474], Loss1 : 1.250573, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3475], Loss1 : 1.207639, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3476], Loss1 : 1.239702, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3477], Loss1 : 1.243983, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3478], Loss1 : 1.250108, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3479], Loss1 : 1.241199, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3480], Loss1 : 1.223960, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3481], Loss1 : 1.240425, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3482], Loss1 : 1.260720, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3483], Loss1 : 1.214631, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3484], Loss1 : 1.229662, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3485], Loss1 : 1.199772, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3486], Loss1 : 1.222923, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3487], Loss1 : 1.225241, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3488], Loss1 : 1.219894, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3489], Loss1 : 1.213902, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3490], Loss1 : 1.229257, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3491], Loss1 : 1.224074, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3492], Loss1 : 1.213544, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3493], Loss1 : 1.239178, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3494], Loss1 : 1.238033, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3495], Loss1 : 1.221376, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3496], Loss1 : 1.240360, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3497], Loss1 : 1.218979, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3498], Loss1 : 1.221822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3499], Loss1 : 1.225938, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3500], Loss1 : 1.229440, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3501], Loss1 : 1.242569, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3502], Loss1 : 1.223702, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3503], Loss1 : 1.243200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3504], Loss1 : 1.209893, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3505], Loss1 : 1.224104, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3506], Loss1 : 1.205835, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3507], Loss1 : 1.247402, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3508], Loss1 : 1.215522, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3509], Loss1 : 1.236763, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3510], Loss1 : 1.210523, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3511], Loss1 : 1.213432, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3512], Loss1 : 1.208278, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3513], Loss1 : 1.216335, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3514], Loss1 : 1.200917, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3515], Loss1 : 1.249140, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3516], Loss1 : 1.233685, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3517], Loss1 : 1.253260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3518], Loss1 : 1.226009, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3519], Loss1 : 1.231694, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3520], Loss1 : 1.227261, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3521], Loss1 : 1.235829, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3522], Loss1 : 1.232907, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3523], Loss1 : 1.234066, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3524], Loss1 : 1.225690, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3525], Loss1 : 1.229054, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3526], Loss1 : 1.255120, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3527], Loss1 : 1.216014, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3528], Loss1 : 1.236227, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3529], Loss1 : 1.229391, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3530], Loss1 : 1.204621, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3531], Loss1 : 1.228710, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3532], Loss1 : 1.190990, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3533], Loss1 : 1.269031, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3534], Loss1 : 1.253694, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3535], Loss1 : 1.243634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3536], Loss1 : 1.208581, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3537], Loss1 : 1.232963, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3538], Loss1 : 1.217260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3539], Loss1 : 1.242785, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3540], Loss1 : 1.221515, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3541], Loss1 : 1.174624, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3542], Loss1 : 1.211998, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3543], Loss1 : 1.207444, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3544], Loss1 : 1.208168, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3545], Loss1 : 1.271939, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3546], Loss1 : 1.191647, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3547], Loss1 : 1.208137, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3548], Loss1 : 1.216823, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3549], Loss1 : 1.239812, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3550], Loss1 : 1.210267, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3551], Loss1 : 1.243582, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3552], Loss1 : 1.187785, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3553], Loss1 : 1.234902, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3554], Loss1 : 1.247633, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3555], Loss1 : 1.237038, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3556], Loss1 : 1.232499, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3557], Loss1 : 1.224048, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3558], Loss1 : 1.224775, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3559], Loss1 : 1.197507, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3560], Loss1 : 1.204616, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3561], Loss1 : 1.192241, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3562], Loss1 : 1.261568, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3563], Loss1 : 1.233485, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3564], Loss1 : 1.219664, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3565], Loss1 : 1.197459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3566], Loss1 : 1.212061, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3567], Loss1 : 1.220077, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3568], Loss1 : 1.241739, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3569], Loss1 : 1.197056, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3570], Loss1 : 1.208123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3571], Loss1 : 1.231690, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3572], Loss1 : 1.245445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3573], Loss1 : 1.235890, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3574], Loss1 : 1.229072, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3575], Loss1 : 1.211295, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3576], Loss1 : 1.221733, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3577], Loss1 : 1.234952, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3578], Loss1 : 1.220889, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3579], Loss1 : 1.256444, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3580], Loss1 : 1.185068, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3581], Loss1 : 1.235950, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3582], Loss1 : 1.224304, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3583], Loss1 : 1.229447, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3584], Loss1 : 1.229118, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3585], Loss1 : 1.228702, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3586], Loss1 : 1.250747, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3587], Loss1 : 1.214705, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3588], Loss1 : 1.192620, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3589], Loss1 : 1.216142, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3590], Loss1 : 1.235105, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3591], Loss1 : 1.207197, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3592], Loss1 : 1.191493, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3593], Loss1 : 1.202495, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3594], Loss1 : 1.221394, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3595], Loss1 : 1.221025, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3596], Loss1 : 1.237110, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3597], Loss1 : 1.225973, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3598], Loss1 : 1.193059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3599], Loss1 : 1.179304, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3600], Loss1 : 1.199540, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3601], Loss1 : 1.212838, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3602], Loss1 : 1.242013, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3603], Loss1 : 1.211234, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3604], Loss1 : 1.235412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3605], Loss1 : 1.254657, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3606], Loss1 : 1.228298, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3607], Loss1 : 1.265733, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3608], Loss1 : 1.224397, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3609], Loss1 : 1.221452, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3610], Loss1 : 1.221439, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3611], Loss1 : 1.207650, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3612], Loss1 : 1.200280, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3613], Loss1 : 1.225508, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3614], Loss1 : 1.221600, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3615], Loss1 : 1.207458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3616], Loss1 : 1.226180, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3617], Loss1 : 1.254480, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3618], Loss1 : 1.243263, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3619], Loss1 : 1.234102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3620], Loss1 : 1.241300, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3621], Loss1 : 1.227226, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3622], Loss1 : 1.226123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3623], Loss1 : 1.240854, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3624], Loss1 : 1.217603, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3625], Loss1 : 1.216569, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3626], Loss1 : 1.205879, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3627], Loss1 : 1.228685, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3628], Loss1 : 1.241365, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3629], Loss1 : 1.228441, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3630], Loss1 : 1.256661, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3631], Loss1 : 1.213324, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3632], Loss1 : 1.221190, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3633], Loss1 : 1.242635, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3634], Loss1 : 1.215668, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3635], Loss1 : 1.201121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3636], Loss1 : 1.228520, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3637], Loss1 : 1.215983, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3638], Loss1 : 1.219044, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3639], Loss1 : 1.244174, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3640], Loss1 : 1.236810, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3641], Loss1 : 1.245751, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3642], Loss1 : 1.210334, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3643], Loss1 : 1.235812, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3644], Loss1 : 1.220550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3645], Loss1 : 1.231327, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3646], Loss1 : 1.235241, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3647], Loss1 : 1.201273, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3648], Loss1 : 1.224501, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3649], Loss1 : 1.236848, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3650], Loss1 : 1.206850, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3651], Loss1 : 1.243957, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3652], Loss1 : 1.213547, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3653], Loss1 : 1.223884, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3654], Loss1 : 1.235901, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3655], Loss1 : 1.222821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3656], Loss1 : 1.226742, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3657], Loss1 : 1.219513, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3658], Loss1 : 1.193661, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3659], Loss1 : 1.221450, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3660], Loss1 : 1.207973, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3661], Loss1 : 1.227433, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3662], Loss1 : 1.204032, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3663], Loss1 : 1.220163, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3664], Loss1 : 1.244868, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3665], Loss1 : 1.217878, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3666], Loss1 : 1.219750, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3667], Loss1 : 1.232791, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3668], Loss1 : 1.243089, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3669], Loss1 : 1.255913, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3670], Loss1 : 1.192929, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3671], Loss1 : 1.222634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3672], Loss1 : 1.194747, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3673], Loss1 : 1.223727, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3674], Loss1 : 1.231586, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3675], Loss1 : 1.199090, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3676], Loss1 : 1.202586, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3677], Loss1 : 1.224037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3678], Loss1 : 1.199776, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3679], Loss1 : 1.228914, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3680], Loss1 : 1.241293, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3681], Loss1 : 1.209254, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3682], Loss1 : 1.263407, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3683], Loss1 : 1.230358, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3684], Loss1 : 1.218663, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3685], Loss1 : 1.220044, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3686], Loss1 : 1.221792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3687], Loss1 : 1.194465, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3688], Loss1 : 1.201155, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3689], Loss1 : 1.239383, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3690], Loss1 : 1.240204, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3691], Loss1 : 1.220254, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3692], Loss1 : 1.225965, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3693], Loss1 : 1.245772, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3694], Loss1 : 1.203375, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3695], Loss1 : 1.191361, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3696], Loss1 : 1.214258, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3697], Loss1 : 1.242979, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3698], Loss1 : 1.269486, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3699], Loss1 : 1.252636, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3700], Loss1 : 1.213304, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3701], Loss1 : 1.164432, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3702], Loss1 : 1.238869, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3703], Loss1 : 1.225412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3704], Loss1 : 1.222183, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3705], Loss1 : 1.201503, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3706], Loss1 : 1.249282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3707], Loss1 : 1.211140, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3708], Loss1 : 1.210428, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3709], Loss1 : 1.239954, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3710], Loss1 : 1.205348, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3711], Loss1 : 1.234672, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3712], Loss1 : 1.222131, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3713], Loss1 : 1.234291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3714], Loss1 : 1.233510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3715], Loss1 : 1.240000, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3716], Loss1 : 1.266349, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3717], Loss1 : 1.235400, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3718], Loss1 : 1.198044, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3719], Loss1 : 1.247198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3720], Loss1 : 1.229060, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3721], Loss1 : 1.244301, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3722], Loss1 : 1.240351, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3723], Loss1 : 1.224927, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3724], Loss1 : 1.176212, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3725], Loss1 : 1.217217, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3726], Loss1 : 1.224146, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3727], Loss1 : 1.192551, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3728], Loss1 : 1.263215, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3729], Loss1 : 1.227512, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3730], Loss1 : 1.201194, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3731], Loss1 : 1.179040, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3732], Loss1 : 1.230422, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3733], Loss1 : 1.228648, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3734], Loss1 : 1.211671, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3735], Loss1 : 1.241870, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3736], Loss1 : 1.235946, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3737], Loss1 : 1.196891, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3738], Loss1 : 1.211128, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3739], Loss1 : 1.227297, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3740], Loss1 : 1.203027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3741], Loss1 : 1.215792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3742], Loss1 : 1.237310, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3743], Loss1 : 1.224811, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3744], Loss1 : 1.218905, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3745], Loss1 : 1.239932, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3746], Loss1 : 1.231464, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3747], Loss1 : 1.207480, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3748], Loss1 : 1.227932, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3749], Loss1 : 1.246756, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3750], Loss1 : 1.220366, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3751], Loss1 : 1.262383, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3752], Loss1 : 1.204301, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3753], Loss1 : 1.237804, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3754], Loss1 : 1.249300, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3755], Loss1 : 1.228313, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3756], Loss1 : 1.236056, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3757], Loss1 : 1.225307, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3758], Loss1 : 1.243472, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3759], Loss1 : 1.222136, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3760], Loss1 : 1.219495, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3761], Loss1 : 1.257781, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3762], Loss1 : 1.231037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3763], Loss1 : 1.235395, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3764], Loss1 : 1.213699, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3765], Loss1 : 1.201688, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3766], Loss1 : 1.207368, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3767], Loss1 : 1.228987, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3768], Loss1 : 1.236743, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3769], Loss1 : 1.218743, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3770], Loss1 : 1.238132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3771], Loss1 : 1.198822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3772], Loss1 : 1.235200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3773], Loss1 : 1.208189, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3774], Loss1 : 1.215522, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3775], Loss1 : 1.229949, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3776], Loss1 : 1.185660, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3777], Loss1 : 1.243476, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3778], Loss1 : 1.212466, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3779], Loss1 : 1.238083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3780], Loss1 : 1.230468, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3781], Loss1 : 1.210713, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3782], Loss1 : 1.221365, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3783], Loss1 : 1.215889, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3784], Loss1 : 1.212101, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3785], Loss1 : 1.245510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3786], Loss1 : 1.223514, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3787], Loss1 : 1.216499, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3788], Loss1 : 1.245199, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3789], Loss1 : 1.217103, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3790], Loss1 : 1.242621, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3791], Loss1 : 1.205193, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3792], Loss1 : 1.241066, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3793], Loss1 : 1.229139, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3794], Loss1 : 1.217395, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3795], Loss1 : 1.231829, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3796], Loss1 : 1.205462, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3797], Loss1 : 1.218591, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3798], Loss1 : 1.195624, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3799], Loss1 : 1.211328, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3800], Loss1 : 1.221019, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3801], Loss1 : 1.212118, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3802], Loss1 : 1.229083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3803], Loss1 : 1.260284, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3804], Loss1 : 1.258093, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3805], Loss1 : 1.218364, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3806], Loss1 : 1.210757, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3807], Loss1 : 1.213966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3808], Loss1 : 1.240465, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3809], Loss1 : 1.217732, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3810], Loss1 : 1.225399, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3811], Loss1 : 1.214760, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3812], Loss1 : 1.255326, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3813], Loss1 : 1.219229, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3814], Loss1 : 1.247313, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3815], Loss1 : 1.214978, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3816], Loss1 : 1.230604, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3817], Loss1 : 1.219013, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3818], Loss1 : 1.213369, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3819], Loss1 : 1.259422, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3820], Loss1 : 1.211266, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3821], Loss1 : 1.229781, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3822], Loss1 : 1.246797, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3823], Loss1 : 1.232234, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3824], Loss1 : 1.229861, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3825], Loss1 : 1.219471, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3826], Loss1 : 1.224491, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3827], Loss1 : 1.171440, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3828], Loss1 : 1.229742, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3829], Loss1 : 1.228030, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3830], Loss1 : 1.242661, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3831], Loss1 : 1.205291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3832], Loss1 : 1.251948, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3833], Loss1 : 1.267415, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3834], Loss1 : 1.208285, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3835], Loss1 : 1.219315, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3836], Loss1 : 1.216329, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3837], Loss1 : 1.218178, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3838], Loss1 : 1.202199, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3839], Loss1 : 1.210014, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3840], Loss1 : 1.214095, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3841], Loss1 : 1.221660, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3842], Loss1 : 1.243728, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3843], Loss1 : 1.227906, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3844], Loss1 : 1.245469, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3845], Loss1 : 1.242486, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3846], Loss1 : 1.217772, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3847], Loss1 : 1.224579, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3848], Loss1 : 1.219928, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3849], Loss1 : 1.230624, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3850], Loss1 : 1.219588, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3851], Loss1 : 1.229102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3852], Loss1 : 1.223907, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3853], Loss1 : 1.224557, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3854], Loss1 : 1.203583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3855], Loss1 : 1.225347, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3856], Loss1 : 1.256755, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3857], Loss1 : 1.190493, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3858], Loss1 : 1.202345, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3859], Loss1 : 1.236795, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3860], Loss1 : 1.224634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3861], Loss1 : 1.264176, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3862], Loss1 : 1.200543, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3863], Loss1 : 1.230115, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3864], Loss1 : 1.240918, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3865], Loss1 : 1.248302, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3866], Loss1 : 1.200694, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3867], Loss1 : 1.194356, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3868], Loss1 : 1.201177, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3869], Loss1 : 1.213976, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3870], Loss1 : 1.214286, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3871], Loss1 : 1.225364, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3872], Loss1 : 1.246467, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3873], Loss1 : 1.208290, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3874], Loss1 : 1.232037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3875], Loss1 : 1.181641, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3876], Loss1 : 1.205652, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3877], Loss1 : 1.243354, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3878], Loss1 : 1.235837, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3879], Loss1 : 1.229039, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3880], Loss1 : 1.216493, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3881], Loss1 : 1.213924, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3882], Loss1 : 1.232312, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3883], Loss1 : 1.215007, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3884], Loss1 : 1.223812, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3885], Loss1 : 1.187482, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3886], Loss1 : 1.242236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3887], Loss1 : 1.205014, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3888], Loss1 : 1.222674, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3889], Loss1 : 1.216430, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3890], Loss1 : 1.212356, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3891], Loss1 : 1.245171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3892], Loss1 : 1.203556, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3893], Loss1 : 1.238483, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3894], Loss1 : 1.219214, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3895], Loss1 : 1.218647, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3896], Loss1 : 1.191911, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3897], Loss1 : 1.257565, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3898], Loss1 : 1.255080, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3899], Loss1 : 1.210655, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3900], Loss1 : 1.226207, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3901], Loss1 : 1.235869, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3902], Loss1 : 1.254670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3903], Loss1 : 1.198920, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3904], Loss1 : 1.231194, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3905], Loss1 : 1.244001, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3906], Loss1 : 1.214731, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3907], Loss1 : 1.205266, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3908], Loss1 : 1.247153, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3909], Loss1 : 1.236891, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3910], Loss1 : 1.225555, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3911], Loss1 : 1.218198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3912], Loss1 : 1.202219, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3913], Loss1 : 1.237432, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3914], Loss1 : 1.211341, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3915], Loss1 : 1.223538, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3916], Loss1 : 1.231398, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3917], Loss1 : 1.200576, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3918], Loss1 : 1.210795, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3919], Loss1 : 1.221942, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3920], Loss1 : 1.225806, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3921], Loss1 : 1.252205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3922], Loss1 : 1.227669, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3923], Loss1 : 1.205165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3924], Loss1 : 1.221999, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3925], Loss1 : 1.257831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3926], Loss1 : 1.224162, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3927], Loss1 : 1.232390, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3928], Loss1 : 1.204432, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3929], Loss1 : 1.228149, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3930], Loss1 : 1.206312, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3931], Loss1 : 1.230027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3932], Loss1 : 1.202500, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3933], Loss1 : 1.254933, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3934], Loss1 : 1.216266, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3935], Loss1 : 1.201804, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3936], Loss1 : 1.221887, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3937], Loss1 : 1.228062, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3938], Loss1 : 1.225474, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3939], Loss1 : 1.209796, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3940], Loss1 : 1.228877, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3941], Loss1 : 1.215724, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3942], Loss1 : 1.246377, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3943], Loss1 : 1.268929, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3944], Loss1 : 1.209545, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3945], Loss1 : 1.218316, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3946], Loss1 : 1.236878, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3947], Loss1 : 1.211426, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3948], Loss1 : 1.207605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3949], Loss1 : 1.236216, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3950], Loss1 : 1.197192, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3951], Loss1 : 1.193141, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3952], Loss1 : 1.228128, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3953], Loss1 : 1.239300, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3954], Loss1 : 1.229903, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3955], Loss1 : 1.221308, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3956], Loss1 : 1.236560, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3957], Loss1 : 1.192670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3958], Loss1 : 1.228688, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3959], Loss1 : 1.208535, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3960], Loss1 : 1.226601, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3961], Loss1 : 1.237884, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3962], Loss1 : 1.225390, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3963], Loss1 : 1.212481, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3964], Loss1 : 1.250448, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3965], Loss1 : 1.204839, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3966], Loss1 : 1.220961, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3967], Loss1 : 1.244993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3968], Loss1 : 1.237590, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3969], Loss1 : 1.222667, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3970], Loss1 : 1.216358, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3971], Loss1 : 1.255408, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3972], Loss1 : 1.206518, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3973], Loss1 : 1.185178, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3974], Loss1 : 1.221786, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3975], Loss1 : 1.226646, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3976], Loss1 : 1.227708, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3977], Loss1 : 1.232801, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3978], Loss1 : 1.258664, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3979], Loss1 : 1.205920, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3980], Loss1 : 1.226536, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3981], Loss1 : 1.232648, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3982], Loss1 : 1.261702, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3983], Loss1 : 1.203914, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3984], Loss1 : 1.254818, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3985], Loss1 : 1.234607, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3986], Loss1 : 1.232787, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3987], Loss1 : 1.217869, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3988], Loss1 : 1.219566, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3989], Loss1 : 1.235692, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3990], Loss1 : 1.221012, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3991], Loss1 : 1.248687, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3992], Loss1 : 1.221300, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3993], Loss1 : 1.188079, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3994], Loss1 : 1.213148, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3995], Loss1 : 1.227681, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3996], Loss1 : 1.224236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3997], Loss1 : 1.226403, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3998], Loss1 : 1.232223, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [3999], Loss1 : 1.220294, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4000], Loss1 : 1.182539, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4001], Loss1 : 1.233033, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4002], Loss1 : 1.227380, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4003], Loss1 : 1.212032, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4004], Loss1 : 1.213395, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4005], Loss1 : 1.241488, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4006], Loss1 : 1.199254, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4007], Loss1 : 1.224666, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4008], Loss1 : 1.225705, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4009], Loss1 : 1.236976, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4010], Loss1 : 1.246178, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4011], Loss1 : 1.216831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4012], Loss1 : 1.216782, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4013], Loss1 : 1.239099, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4014], Loss1 : 1.208638, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4015], Loss1 : 1.223818, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4016], Loss1 : 1.249988, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4017], Loss1 : 1.192058, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4018], Loss1 : 1.243177, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4019], Loss1 : 1.195384, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4020], Loss1 : 1.228441, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4021], Loss1 : 1.243734, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4022], Loss1 : 1.221841, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4023], Loss1 : 1.206159, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4024], Loss1 : 1.211558, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4025], Loss1 : 1.234121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4026], Loss1 : 1.230914, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4027], Loss1 : 1.240700, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4028], Loss1 : 1.268960, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4029], Loss1 : 1.213410, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4030], Loss1 : 1.243172, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4031], Loss1 : 1.238618, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4032], Loss1 : 1.219694, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4033], Loss1 : 1.221806, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4034], Loss1 : 1.226471, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4035], Loss1 : 1.213125, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4036], Loss1 : 1.218198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4037], Loss1 : 1.225287, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4038], Loss1 : 1.216772, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4039], Loss1 : 1.221966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4040], Loss1 : 1.244529, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4041], Loss1 : 1.210847, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4042], Loss1 : 1.213016, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4043], Loss1 : 1.201761, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4044], Loss1 : 1.234566, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4045], Loss1 : 1.203870, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4046], Loss1 : 1.254997, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4047], Loss1 : 1.222126, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4048], Loss1 : 1.222886, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4049], Loss1 : 1.226642, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4050], Loss1 : 1.247860, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4051], Loss1 : 1.185500, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4052], Loss1 : 1.192717, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4053], Loss1 : 1.199979, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4054], Loss1 : 1.213730, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4055], Loss1 : 1.254282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4056], Loss1 : 1.235815, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4057], Loss1 : 1.227959, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4058], Loss1 : 1.226404, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4059], Loss1 : 1.220615, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4060], Loss1 : 1.215484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4061], Loss1 : 1.206538, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4062], Loss1 : 1.247782, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4063], Loss1 : 1.209427, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4064], Loss1 : 1.230618, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4065], Loss1 : 1.216975, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4066], Loss1 : 1.216057, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4067], Loss1 : 1.209214, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4068], Loss1 : 1.232604, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4069], Loss1 : 1.219268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4070], Loss1 : 1.223173, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4071], Loss1 : 1.191729, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4072], Loss1 : 1.201015, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4073], Loss1 : 1.256572, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4074], Loss1 : 1.234673, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4075], Loss1 : 1.199255, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4076], Loss1 : 1.253316, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4077], Loss1 : 1.210234, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4078], Loss1 : 1.205687, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4079], Loss1 : 1.190428, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4080], Loss1 : 1.211445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4081], Loss1 : 1.249921, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4082], Loss1 : 1.203993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4083], Loss1 : 1.177640, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4084], Loss1 : 1.227724, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4085], Loss1 : 1.238821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4086], Loss1 : 1.213382, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4087], Loss1 : 1.240926, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4088], Loss1 : 1.222312, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4089], Loss1 : 1.225859, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4090], Loss1 : 1.238819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4091], Loss1 : 1.243268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4092], Loss1 : 1.201167, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4093], Loss1 : 1.192720, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4094], Loss1 : 1.260612, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4095], Loss1 : 1.224140, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4096], Loss1 : 1.199164, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4097], Loss1 : 1.212159, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4098], Loss1 : 1.223377, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4099], Loss1 : 1.237244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4100], Loss1 : 1.181075, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4101], Loss1 : 1.214599, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4102], Loss1 : 1.238842, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4103], Loss1 : 1.244526, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4104], Loss1 : 1.247906, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4105], Loss1 : 1.233748, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4106], Loss1 : 1.219253, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4107], Loss1 : 1.219151, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4108], Loss1 : 1.239506, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4109], Loss1 : 1.196821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4110], Loss1 : 1.219795, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4111], Loss1 : 1.211678, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4112], Loss1 : 1.230074, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4113], Loss1 : 1.216481, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4114], Loss1 : 1.246366, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4115], Loss1 : 1.230679, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4116], Loss1 : 1.229041, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4117], Loss1 : 1.212719, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4118], Loss1 : 1.237269, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4119], Loss1 : 1.223952, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4120], Loss1 : 1.222767, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4121], Loss1 : 1.254680, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4122], Loss1 : 1.264179, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4123], Loss1 : 1.254597, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4124], Loss1 : 1.195754, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4125], Loss1 : 1.222527, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4126], Loss1 : 1.199088, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4127], Loss1 : 1.224456, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4128], Loss1 : 1.207341, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4129], Loss1 : 1.269616, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4130], Loss1 : 1.239741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4131], Loss1 : 1.198680, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4132], Loss1 : 1.219160, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4133], Loss1 : 1.207095, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4134], Loss1 : 1.226653, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4135], Loss1 : 1.253261, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4136], Loss1 : 1.222286, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4137], Loss1 : 1.231364, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4138], Loss1 : 1.208505, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4139], Loss1 : 1.199327, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4140], Loss1 : 1.229424, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4141], Loss1 : 1.224566, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4142], Loss1 : 1.185056, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4143], Loss1 : 1.243132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4144], Loss1 : 1.250602, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4145], Loss1 : 1.242015, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4146], Loss1 : 1.223459, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4147], Loss1 : 1.231688, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4148], Loss1 : 1.203753, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4149], Loss1 : 1.222132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4150], Loss1 : 1.247796, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4151], Loss1 : 1.191200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4152], Loss1 : 1.219548, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4153], Loss1 : 1.202284, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4154], Loss1 : 1.215134, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4155], Loss1 : 1.216021, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4156], Loss1 : 1.214840, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4157], Loss1 : 1.242605, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4158], Loss1 : 1.224546, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4159], Loss1 : 1.228412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4160], Loss1 : 1.207347, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4161], Loss1 : 1.229905, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4162], Loss1 : 1.217809, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4163], Loss1 : 1.203653, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4164], Loss1 : 1.209494, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4165], Loss1 : 1.216626, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4166], Loss1 : 1.237208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4167], Loss1 : 1.204077, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4168], Loss1 : 1.213689, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4169], Loss1 : 1.222581, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4170], Loss1 : 1.218140, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4171], Loss1 : 1.226921, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4172], Loss1 : 1.188929, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4173], Loss1 : 1.232587, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4174], Loss1 : 1.227123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4175], Loss1 : 1.243343, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4176], Loss1 : 1.228181, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4177], Loss1 : 1.212930, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4178], Loss1 : 1.229269, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4179], Loss1 : 1.237279, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4180], Loss1 : 1.193863, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4181], Loss1 : 1.219764, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4182], Loss1 : 1.229592, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4183], Loss1 : 1.226760, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4184], Loss1 : 1.215804, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4185], Loss1 : 1.233884, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4186], Loss1 : 1.236268, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4187], Loss1 : 1.230482, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4188], Loss1 : 1.191141, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4189], Loss1 : 1.208876, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4190], Loss1 : 1.212716, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4191], Loss1 : 1.264779, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4192], Loss1 : 1.242705, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4193], Loss1 : 1.227640, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4194], Loss1 : 1.263492, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4195], Loss1 : 1.199683, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4196], Loss1 : 1.212790, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4197], Loss1 : 1.215966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4198], Loss1 : 1.196807, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4199], Loss1 : 1.228787, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4200], Loss1 : 1.231331, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4201], Loss1 : 1.199400, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4202], Loss1 : 1.241063, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4203], Loss1 : 1.265415, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4204], Loss1 : 1.220162, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4205], Loss1 : 1.228442, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4206], Loss1 : 1.183206, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4207], Loss1 : 1.199389, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4208], Loss1 : 1.233698, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4209], Loss1 : 1.243310, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4210], Loss1 : 1.231251, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4211], Loss1 : 1.211928, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4212], Loss1 : 1.221531, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4213], Loss1 : 1.230244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4214], Loss1 : 1.218845, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4215], Loss1 : 1.266988, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4216], Loss1 : 1.243122, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4217], Loss1 : 1.203488, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4218], Loss1 : 1.202522, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4219], Loss1 : 1.232513, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4220], Loss1 : 1.252029, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4221], Loss1 : 1.241861, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4222], Loss1 : 1.221151, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4223], Loss1 : 1.216333, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4224], Loss1 : 1.204282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4225], Loss1 : 1.233123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4226], Loss1 : 1.253048, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4227], Loss1 : 1.230171, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4228], Loss1 : 1.217245, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4229], Loss1 : 1.228773, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4230], Loss1 : 1.207139, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4231], Loss1 : 1.204246, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4232], Loss1 : 1.237821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4233], Loss1 : 1.184553, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4234], Loss1 : 1.198681, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4235], Loss1 : 1.214940, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4236], Loss1 : 1.235895, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4237], Loss1 : 1.241275, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4238], Loss1 : 1.221643, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4239], Loss1 : 1.274874, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4240], Loss1 : 1.259888, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4241], Loss1 : 1.219915, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4242], Loss1 : 1.213068, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4243], Loss1 : 1.256282, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4244], Loss1 : 1.207737, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4245], Loss1 : 1.214911, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4246], Loss1 : 1.231180, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4247], Loss1 : 1.256587, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4248], Loss1 : 1.207123, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4249], Loss1 : 1.217101, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4250], Loss1 : 1.240544, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4251], Loss1 : 1.225424, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4252], Loss1 : 1.193654, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4253], Loss1 : 1.204532, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4254], Loss1 : 1.236153, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4255], Loss1 : 1.229898, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4256], Loss1 : 1.230045, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4257], Loss1 : 1.234006, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4258], Loss1 : 1.197183, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4259], Loss1 : 1.241301, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4260], Loss1 : 1.240120, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4261], Loss1 : 1.199383, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4262], Loss1 : 1.196075, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4263], Loss1 : 1.224607, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4264], Loss1 : 1.219823, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4265], Loss1 : 1.248149, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4266], Loss1 : 1.224350, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4267], Loss1 : 1.204625, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4268], Loss1 : 1.225047, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4269], Loss1 : 1.255983, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4270], Loss1 : 1.227421, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4271], Loss1 : 1.220581, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4272], Loss1 : 1.243637, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4273], Loss1 : 1.218001, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4274], Loss1 : 1.232445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4275], Loss1 : 1.225930, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4276], Loss1 : 1.239412, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4277], Loss1 : 1.248749, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4278], Loss1 : 1.211237, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4279], Loss1 : 1.242246, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4280], Loss1 : 1.231059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4281], Loss1 : 1.228122, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4282], Loss1 : 1.258927, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4283], Loss1 : 1.244406, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4284], Loss1 : 1.227330, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4285], Loss1 : 1.246073, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4286], Loss1 : 1.266716, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4287], Loss1 : 1.249291, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4288], Loss1 : 1.237786, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4289], Loss1 : 1.235311, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4290], Loss1 : 1.232089, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4291], Loss1 : 1.229205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4292], Loss1 : 1.217318, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4293], Loss1 : 1.221439, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4294], Loss1 : 1.244363, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4295], Loss1 : 1.215084, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4296], Loss1 : 1.208130, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4297], Loss1 : 1.261535, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4298], Loss1 : 1.207289, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4299], Loss1 : 1.209891, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4300], Loss1 : 1.234439, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4301], Loss1 : 1.230760, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4302], Loss1 : 1.256166, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4303], Loss1 : 1.234188, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4304], Loss1 : 1.203913, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4305], Loss1 : 1.228825, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4306], Loss1 : 1.220571, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4307], Loss1 : 1.224288, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4308], Loss1 : 1.211660, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4309], Loss1 : 1.229741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4310], Loss1 : 1.247788, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4311], Loss1 : 1.214224, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4312], Loss1 : 1.216193, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4313], Loss1 : 1.244348, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4314], Loss1 : 1.238491, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4315], Loss1 : 1.236954, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4316], Loss1 : 1.206851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4317], Loss1 : 1.219455, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4318], Loss1 : 1.217673, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4319], Loss1 : 1.226723, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4320], Loss1 : 1.187861, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4321], Loss1 : 1.223279, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4322], Loss1 : 1.243337, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4323], Loss1 : 1.193398, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4324], Loss1 : 1.218508, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4325], Loss1 : 1.230435, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4326], Loss1 : 1.201111, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4327], Loss1 : 1.248338, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4328], Loss1 : 1.240052, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4329], Loss1 : 1.232285, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4330], Loss1 : 1.253255, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4331], Loss1 : 1.214854, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4332], Loss1 : 1.257352, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4333], Loss1 : 1.219575, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4334], Loss1 : 1.221905, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4335], Loss1 : 1.241089, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4336], Loss1 : 1.176014, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4337], Loss1 : 1.226707, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4338], Loss1 : 1.206031, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4339], Loss1 : 1.221687, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4340], Loss1 : 1.235540, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4341], Loss1 : 1.261760, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4342], Loss1 : 1.207310, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4343], Loss1 : 1.219970, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4344], Loss1 : 1.217418, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4345], Loss1 : 1.206331, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4346], Loss1 : 1.245349, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4347], Loss1 : 1.231015, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4348], Loss1 : 1.217017, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4349], Loss1 : 1.217021, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4350], Loss1 : 1.219145, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4351], Loss1 : 1.255336, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4352], Loss1 : 1.220175, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4353], Loss1 : 1.221501, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4354], Loss1 : 1.167790, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4355], Loss1 : 1.207962, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4356], Loss1 : 1.221371, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4357], Loss1 : 1.217613, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4358], Loss1 : 1.218460, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4359], Loss1 : 1.234353, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4360], Loss1 : 1.208130, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4361], Loss1 : 1.234451, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4362], Loss1 : 1.233761, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4363], Loss1 : 1.216354, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4364], Loss1 : 1.239013, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4365], Loss1 : 1.227181, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4366], Loss1 : 1.259224, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4367], Loss1 : 1.228375, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4368], Loss1 : 1.222617, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4369], Loss1 : 1.221149, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4370], Loss1 : 1.230198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4371], Loss1 : 1.234125, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4372], Loss1 : 1.188241, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4373], Loss1 : 1.204310, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4374], Loss1 : 1.217417, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4375], Loss1 : 1.199413, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4376], Loss1 : 1.209462, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4377], Loss1 : 1.213116, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4378], Loss1 : 1.212801, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4379], Loss1 : 1.240752, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4380], Loss1 : 1.193717, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4381], Loss1 : 1.245759, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4382], Loss1 : 1.222668, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4383], Loss1 : 1.202778, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4384], Loss1 : 1.236043, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4385], Loss1 : 1.203200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4386], Loss1 : 1.226868, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4387], Loss1 : 1.237618, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4388], Loss1 : 1.209038, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4389], Loss1 : 1.234944, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4390], Loss1 : 1.248317, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4391], Loss1 : 1.207995, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4392], Loss1 : 1.239484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4393], Loss1 : 1.182487, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4394], Loss1 : 1.224082, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4395], Loss1 : 1.223487, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4396], Loss1 : 1.238973, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4397], Loss1 : 1.227263, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4398], Loss1 : 1.227037, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4399], Loss1 : 1.226398, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4400], Loss1 : 1.225348, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4401], Loss1 : 1.227285, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4402], Loss1 : 1.228068, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4403], Loss1 : 1.213604, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4404], Loss1 : 1.242109, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4405], Loss1 : 1.224963, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4406], Loss1 : 1.184205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4407], Loss1 : 1.241717, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4408], Loss1 : 1.238135, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4409], Loss1 : 1.255898, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4410], Loss1 : 1.247818, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4411], Loss1 : 1.228541, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4412], Loss1 : 1.210230, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4413], Loss1 : 1.230344, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4414], Loss1 : 1.269670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4415], Loss1 : 1.201447, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4416], Loss1 : 1.232510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4417], Loss1 : 1.239153, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4418], Loss1 : 1.219024, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4419], Loss1 : 1.240560, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4420], Loss1 : 1.247382, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4421], Loss1 : 1.208229, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4422], Loss1 : 1.220197, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4423], Loss1 : 1.234451, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4424], Loss1 : 1.239997, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4425], Loss1 : 1.255249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4426], Loss1 : 1.232441, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4427], Loss1 : 1.237887, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4428], Loss1 : 1.223992, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4429], Loss1 : 1.233094, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4430], Loss1 : 1.237146, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4431], Loss1 : 1.241019, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4432], Loss1 : 1.231330, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4433], Loss1 : 1.194151, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4434], Loss1 : 1.215229, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4435], Loss1 : 1.251492, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4436], Loss1 : 1.186993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4437], Loss1 : 1.209177, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4438], Loss1 : 1.240019, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4439], Loss1 : 1.180349, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4440], Loss1 : 1.234936, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4441], Loss1 : 1.212618, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4442], Loss1 : 1.222489, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4443], Loss1 : 1.251023, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4444], Loss1 : 1.227613, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4445], Loss1 : 1.221855, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4446], Loss1 : 1.220532, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4447], Loss1 : 1.217002, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4448], Loss1 : 1.225205, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4449], Loss1 : 1.212955, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4450], Loss1 : 1.215614, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4451], Loss1 : 1.215583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4452], Loss1 : 1.241022, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4453], Loss1 : 1.216324, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4454], Loss1 : 1.234097, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4455], Loss1 : 1.218032, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4456], Loss1 : 1.237834, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4457], Loss1 : 1.183885, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4458], Loss1 : 1.188491, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4459], Loss1 : 1.190719, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4460], Loss1 : 1.205925, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4461], Loss1 : 1.204029, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4462], Loss1 : 1.232351, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4463], Loss1 : 1.245510, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4464], Loss1 : 1.220049, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4465], Loss1 : 1.223737, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4466], Loss1 : 1.209807, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4467], Loss1 : 1.234788, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4468], Loss1 : 1.204304, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4469], Loss1 : 1.221870, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4470], Loss1 : 1.232703, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4471], Loss1 : 1.200112, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4472], Loss1 : 1.229993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4473], Loss1 : 1.218801, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4474], Loss1 : 1.221278, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4475], Loss1 : 1.220108, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4476], Loss1 : 1.231296, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4477], Loss1 : 1.248859, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4478], Loss1 : 1.230721, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4479], Loss1 : 1.221574, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4480], Loss1 : 1.231829, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4481], Loss1 : 1.237948, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4482], Loss1 : 1.181832, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4483], Loss1 : 1.184481, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4484], Loss1 : 1.168621, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4485], Loss1 : 1.243027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4486], Loss1 : 1.193998, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4487], Loss1 : 1.237245, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4488], Loss1 : 1.245015, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4489], Loss1 : 1.209054, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4490], Loss1 : 1.248670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4491], Loss1 : 1.241784, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4492], Loss1 : 1.232214, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4493], Loss1 : 1.235808, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4494], Loss1 : 1.205822, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4495], Loss1 : 1.210121, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4496], Loss1 : 1.202527, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4497], Loss1 : 1.228564, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4498], Loss1 : 1.202056, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4499], Loss1 : 1.248539, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4500], Loss1 : 1.227328, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4501], Loss1 : 1.220858, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4502], Loss1 : 1.212034, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4503], Loss1 : 1.241068, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4504], Loss1 : 1.237004, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4505], Loss1 : 1.251095, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4506], Loss1 : 1.214049, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4507], Loss1 : 1.199705, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4508], Loss1 : 1.238670, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4509], Loss1 : 1.215079, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4510], Loss1 : 1.213354, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4511], Loss1 : 1.258511, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4512], Loss1 : 1.235946, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4513], Loss1 : 1.244273, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4514], Loss1 : 1.220784, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4515], Loss1 : 1.226938, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4516], Loss1 : 1.227872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4517], Loss1 : 1.223958, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4518], Loss1 : 1.239884, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4519], Loss1 : 1.172235, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4520], Loss1 : 1.230565, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4521], Loss1 : 1.255404, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4522], Loss1 : 1.237727, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4523], Loss1 : 1.234836, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4524], Loss1 : 1.208272, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4525], Loss1 : 1.224440, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4526], Loss1 : 1.211071, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4527], Loss1 : 1.195029, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4528], Loss1 : 1.236079, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4529], Loss1 : 1.235944, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4530], Loss1 : 1.223661, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4531], Loss1 : 1.211508, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4532], Loss1 : 1.242420, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4533], Loss1 : 1.214582, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4534], Loss1 : 1.240448, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4535], Loss1 : 1.231333, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4536], Loss1 : 1.230162, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4537], Loss1 : 1.257165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4538], Loss1 : 1.200245, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4539], Loss1 : 1.248112, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4540], Loss1 : 1.225323, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4541], Loss1 : 1.234731, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4542], Loss1 : 1.213311, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4543], Loss1 : 1.235821, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4544], Loss1 : 1.211900, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4545], Loss1 : 1.237477, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4546], Loss1 : 1.198004, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4547], Loss1 : 1.207096, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4548], Loss1 : 1.215786, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4549], Loss1 : 1.218042, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4550], Loss1 : 1.216662, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4551], Loss1 : 1.241816, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4552], Loss1 : 1.239915, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4553], Loss1 : 1.239406, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4554], Loss1 : 1.214582, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4555], Loss1 : 1.265186, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4556], Loss1 : 1.226485, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4557], Loss1 : 1.211324, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4558], Loss1 : 1.224869, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4559], Loss1 : 1.193934, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4560], Loss1 : 1.217388, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4561], Loss1 : 1.222159, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4562], Loss1 : 1.238484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4563], Loss1 : 1.217208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4564], Loss1 : 1.244150, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4565], Loss1 : 1.203611, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4566], Loss1 : 1.227946, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4567], Loss1 : 1.248666, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4568], Loss1 : 1.206737, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4569], Loss1 : 1.229286, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4570], Loss1 : 1.215011, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4571], Loss1 : 1.233053, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4572], Loss1 : 1.196091, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4573], Loss1 : 1.217929, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4574], Loss1 : 1.234231, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4575], Loss1 : 1.227843, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4576], Loss1 : 1.233713, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4577], Loss1 : 1.222259, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4578], Loss1 : 1.218501, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4579], Loss1 : 1.214952, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4580], Loss1 : 1.203158, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4581], Loss1 : 1.231760, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4582], Loss1 : 1.223435, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4583], Loss1 : 1.230544, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4584], Loss1 : 1.258918, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4585], Loss1 : 1.236944, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4586], Loss1 : 1.216338, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4587], Loss1 : 1.223413, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4588], Loss1 : 1.226638, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4589], Loss1 : 1.225444, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4590], Loss1 : 1.222236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4591], Loss1 : 1.231105, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4592], Loss1 : 1.227264, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4593], Loss1 : 1.209533, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4594], Loss1 : 1.218345, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4595], Loss1 : 1.213795, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4596], Loss1 : 1.225928, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4597], Loss1 : 1.223024, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4598], Loss1 : 1.203490, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4599], Loss1 : 1.184303, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4600], Loss1 : 1.241773, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4601], Loss1 : 1.230872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4602], Loss1 : 1.242116, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4603], Loss1 : 1.191554, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4604], Loss1 : 1.270815, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4605], Loss1 : 1.230449, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4606], Loss1 : 1.214306, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4607], Loss1 : 1.209994, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4608], Loss1 : 1.227654, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4609], Loss1 : 1.247275, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4610], Loss1 : 1.215968, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4611], Loss1 : 1.224378, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4612], Loss1 : 1.235215, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4613], Loss1 : 1.219887, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4614], Loss1 : 1.232824, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4615], Loss1 : 1.232208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4616], Loss1 : 1.210865, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4617], Loss1 : 1.248103, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4618], Loss1 : 1.225465, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4619], Loss1 : 1.248183, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4620], Loss1 : 1.218369, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4621], Loss1 : 1.194950, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4622], Loss1 : 1.209254, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4623], Loss1 : 1.199550, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4624], Loss1 : 1.236132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4625], Loss1 : 1.264651, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4626], Loss1 : 1.218874, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4627], Loss1 : 1.216351, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4628], Loss1 : 1.225165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4629], Loss1 : 1.212288, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4630], Loss1 : 1.245690, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4631], Loss1 : 1.221853, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4632], Loss1 : 1.231762, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4633], Loss1 : 1.244444, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4634], Loss1 : 1.237634, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4635], Loss1 : 1.252991, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4636], Loss1 : 1.210118, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4637], Loss1 : 1.231283, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4638], Loss1 : 1.240175, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4639], Loss1 : 1.266489, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4640], Loss1 : 1.192429, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4641], Loss1 : 1.242795, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4642], Loss1 : 1.244814, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4643], Loss1 : 1.228241, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4644], Loss1 : 1.228261, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4645], Loss1 : 1.228606, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4646], Loss1 : 1.246683, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4647], Loss1 : 1.216333, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4648], Loss1 : 1.240826, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4649], Loss1 : 1.200641, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4650], Loss1 : 1.206697, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4651], Loss1 : 1.224641, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4652], Loss1 : 1.235083, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4653], Loss1 : 1.229475, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4654], Loss1 : 1.219248, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4655], Loss1 : 1.221815, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4656], Loss1 : 1.202326, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4657], Loss1 : 1.223908, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4658], Loss1 : 1.194549, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4659], Loss1 : 1.221277, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4660], Loss1 : 1.239820, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4661], Loss1 : 1.231203, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4662], Loss1 : 1.228692, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4663], Loss1 : 1.229523, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4664], Loss1 : 1.222872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4665], Loss1 : 1.212947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4666], Loss1 : 1.222764, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4667], Loss1 : 1.260785, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4668], Loss1 : 1.232314, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4669], Loss1 : 1.224962, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4670], Loss1 : 1.237023, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4671], Loss1 : 1.256200, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4672], Loss1 : 1.215434, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4673], Loss1 : 1.224851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4674], Loss1 : 1.242111, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4675], Loss1 : 1.222405, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4676], Loss1 : 1.213311, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4677], Loss1 : 1.238716, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4678], Loss1 : 1.231749, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4679], Loss1 : 1.208060, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4680], Loss1 : 1.225080, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4681], Loss1 : 1.207570, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4682], Loss1 : 1.241321, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4683], Loss1 : 1.191446, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4684], Loss1 : 1.229953, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4685], Loss1 : 1.217221, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4686], Loss1 : 1.236042, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4687], Loss1 : 1.212315, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4688], Loss1 : 1.226997, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4689], Loss1 : 1.227348, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4690], Loss1 : 1.216319, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4691], Loss1 : 1.219558, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4692], Loss1 : 1.223442, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4693], Loss1 : 1.221641, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4694], Loss1 : 1.222120, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4695], Loss1 : 1.219977, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4696], Loss1 : 1.244642, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4697], Loss1 : 1.210678, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4698], Loss1 : 1.225931, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4699], Loss1 : 1.232946, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4700], Loss1 : 1.202208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4701], Loss1 : 1.236391, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4702], Loss1 : 1.237969, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4703], Loss1 : 1.200575, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4704], Loss1 : 1.217937, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4705], Loss1 : 1.239906, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4706], Loss1 : 1.204216, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4707], Loss1 : 1.233284, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4708], Loss1 : 1.219769, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4709], Loss1 : 1.213196, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4710], Loss1 : 1.227778, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4711], Loss1 : 1.216453, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4712], Loss1 : 1.254402, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4713], Loss1 : 1.162059, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4714], Loss1 : 1.224502, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4715], Loss1 : 1.221338, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4716], Loss1 : 1.237769, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4717], Loss1 : 1.225712, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4718], Loss1 : 1.232831, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4719], Loss1 : 1.244807, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4720], Loss1 : 1.220644, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4721], Loss1 : 1.203190, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4722], Loss1 : 1.245812, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4723], Loss1 : 1.236102, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4724], Loss1 : 1.225182, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4725], Loss1 : 1.238311, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4726], Loss1 : 1.174429, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4727], Loss1 : 1.227878, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4728], Loss1 : 1.233798, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4729], Loss1 : 1.225396, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4730], Loss1 : 1.252198, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4731], Loss1 : 1.214048, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4732], Loss1 : 1.250861, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4733], Loss1 : 1.234970, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4734], Loss1 : 1.227647, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4735], Loss1 : 1.248716, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4736], Loss1 : 1.215825, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4737], Loss1 : 1.236097, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4738], Loss1 : 1.255432, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4739], Loss1 : 1.214492, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4740], Loss1 : 1.242470, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4741], Loss1 : 1.209191, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4742], Loss1 : 1.216934, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4743], Loss1 : 1.224017, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4744], Loss1 : 1.208142, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4745], Loss1 : 1.218908, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4746], Loss1 : 1.219435, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4747], Loss1 : 1.245132, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4748], Loss1 : 1.229654, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4749], Loss1 : 1.217978, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4750], Loss1 : 1.201834, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4751], Loss1 : 1.233246, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4752], Loss1 : 1.232943, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4753], Loss1 : 1.187490, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4754], Loss1 : 1.219745, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4755], Loss1 : 1.211269, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4756], Loss1 : 1.213690, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4757], Loss1 : 1.220586, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4758], Loss1 : 1.212863, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4759], Loss1 : 1.224664, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4760], Loss1 : 1.236966, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4761], Loss1 : 1.237248, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4762], Loss1 : 1.209155, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4763], Loss1 : 1.221445, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4764], Loss1 : 1.234009, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4765], Loss1 : 1.217240, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4766], Loss1 : 1.261591, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4767], Loss1 : 1.229953, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4768], Loss1 : 1.228027, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4769], Loss1 : 1.245520, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4770], Loss1 : 1.234758, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4771], Loss1 : 1.234729, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4772], Loss1 : 1.215666, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4773], Loss1 : 1.222458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4774], Loss1 : 1.198129, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4775], Loss1 : 1.204235, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4776], Loss1 : 1.257731, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4777], Loss1 : 1.209007, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4778], Loss1 : 1.229852, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4779], Loss1 : 1.213710, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4780], Loss1 : 1.238661, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4781], Loss1 : 1.243849, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4782], Loss1 : 1.215893, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4783], Loss1 : 1.226127, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4784], Loss1 : 1.218179, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4785], Loss1 : 1.245177, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4786], Loss1 : 1.248289, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4787], Loss1 : 1.241819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4788], Loss1 : 1.165578, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4789], Loss1 : 1.198192, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4790], Loss1 : 1.254838, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4791], Loss1 : 1.218711, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4792], Loss1 : 1.206165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4793], Loss1 : 1.207363, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4794], Loss1 : 1.238988, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4795], Loss1 : 1.245274, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4796], Loss1 : 1.230089, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4797], Loss1 : 1.233453, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4798], Loss1 : 1.201943, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4799], Loss1 : 1.223891, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4800], Loss1 : 1.259696, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4801], Loss1 : 1.211986, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4802], Loss1 : 1.201526, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4803], Loss1 : 1.224424, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4804], Loss1 : 1.216526, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4805], Loss1 : 1.257996, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4806], Loss1 : 1.225971, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4807], Loss1 : 1.243542, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4808], Loss1 : 1.223386, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4809], Loss1 : 1.201350, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4810], Loss1 : 1.183909, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4811], Loss1 : 1.227811, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4812], Loss1 : 1.213526, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4813], Loss1 : 1.214135, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4814], Loss1 : 1.251057, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4815], Loss1 : 1.207792, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4816], Loss1 : 1.250947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4817], Loss1 : 1.219532, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4818], Loss1 : 1.248210, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4819], Loss1 : 1.243872, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4820], Loss1 : 1.247181, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4821], Loss1 : 1.241621, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4822], Loss1 : 1.247314, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4823], Loss1 : 1.207923, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4824], Loss1 : 1.217249, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4825], Loss1 : 1.232408, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4826], Loss1 : 1.233473, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4827], Loss1 : 1.233898, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4828], Loss1 : 1.246919, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4829], Loss1 : 1.245993, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4830], Loss1 : 1.216309, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4831], Loss1 : 1.204438, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4832], Loss1 : 1.197969, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4833], Loss1 : 1.233818, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4834], Loss1 : 1.226967, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4835], Loss1 : 1.234675, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4836], Loss1 : 1.234248, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4837], Loss1 : 1.201829, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4838], Loss1 : 1.242138, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4839], Loss1 : 1.213741, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4840], Loss1 : 1.223054, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4841], Loss1 : 1.210239, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4842], Loss1 : 1.208357, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4843], Loss1 : 1.251458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4844], Loss1 : 1.237260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4845], Loss1 : 1.205001, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4846], Loss1 : 1.209377, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4847], Loss1 : 1.224362, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4848], Loss1 : 1.196260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4849], Loss1 : 1.242920, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4850], Loss1 : 1.213856, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4851], Loss1 : 1.198923, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4852], Loss1 : 1.244260, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4853], Loss1 : 1.211635, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4854], Loss1 : 1.206324, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4855], Loss1 : 1.225541, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4856], Loss1 : 1.240447, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4857], Loss1 : 1.213190, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4858], Loss1 : 1.226578, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4859], Loss1 : 1.205548, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4860], Loss1 : 1.215729, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4861], Loss1 : 1.187906, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4862], Loss1 : 1.225897, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4863], Loss1 : 1.267573, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4864], Loss1 : 1.187819, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4865], Loss1 : 1.221491, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4866], Loss1 : 1.214604, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4867], Loss1 : 1.183362, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4868], Loss1 : 1.224115, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4869], Loss1 : 1.218851, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4870], Loss1 : 1.233208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4871], Loss1 : 1.234779, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4872], Loss1 : 1.237252, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4873], Loss1 : 1.220767, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4874], Loss1 : 1.237632, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4875], Loss1 : 1.235001, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4876], Loss1 : 1.214212, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4877], Loss1 : 1.257278, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4878], Loss1 : 1.208664, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4879], Loss1 : 1.181870, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4880], Loss1 : 1.202679, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4881], Loss1 : 1.225680, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4882], Loss1 : 1.228394, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4883], Loss1 : 1.240520, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4884], Loss1 : 1.210846, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4885], Loss1 : 1.218437, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4886], Loss1 : 1.224148, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4887], Loss1 : 1.213321, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4888], Loss1 : 1.182490, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4889], Loss1 : 1.268130, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4890], Loss1 : 1.221379, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4891], Loss1 : 1.226043, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4892], Loss1 : 1.220154, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4893], Loss1 : 1.247772, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4894], Loss1 : 1.214256, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4895], Loss1 : 1.223292, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4896], Loss1 : 1.258406, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4897], Loss1 : 1.229681, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4898], Loss1 : 1.221484, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4899], Loss1 : 1.226746, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4900], Loss1 : 1.238557, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4901], Loss1 : 1.228269, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4902], Loss1 : 1.235496, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4903], Loss1 : 1.209241, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4904], Loss1 : 1.206165, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4905], Loss1 : 1.218873, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4906], Loss1 : 1.189854, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4907], Loss1 : 1.214629, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4908], Loss1 : 1.239926, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4909], Loss1 : 1.226968, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4910], Loss1 : 1.240558, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4911], Loss1 : 1.216540, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4912], Loss1 : 1.222008, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4913], Loss1 : 1.239079, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4914], Loss1 : 1.229170, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4915], Loss1 : 1.246292, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4916], Loss1 : 1.230791, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4917], Loss1 : 1.196930, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4918], Loss1 : 1.200322, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4919], Loss1 : 1.246942, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4920], Loss1 : 1.224946, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4921], Loss1 : 1.214053, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4922], Loss1 : 1.218669, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4923], Loss1 : 1.215659, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4924], Loss1 : 1.234240, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4925], Loss1 : 1.212213, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4926], Loss1 : 1.258845, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4927], Loss1 : 1.208251, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4928], Loss1 : 1.211691, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4929], Loss1 : 1.222902, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4930], Loss1 : 1.196709, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4931], Loss1 : 1.223444, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4932], Loss1 : 1.234441, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4933], Loss1 : 1.220640, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4934], Loss1 : 1.225350, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4935], Loss1 : 1.225850, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4936], Loss1 : 1.242674, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4937], Loss1 : 1.232935, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4938], Loss1 : 1.230400, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4939], Loss1 : 1.207063, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4940], Loss1 : 1.243004, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4941], Loss1 : 1.196947, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4942], Loss1 : 1.223437, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4943], Loss1 : 1.217781, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4944], Loss1 : 1.232069, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4945], Loss1 : 1.226116, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4946], Loss1 : 1.197544, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4947], Loss1 : 1.250874, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4948], Loss1 : 1.217187, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4949], Loss1 : 1.206114, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4950], Loss1 : 1.239575, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4951], Loss1 : 1.220568, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4952], Loss1 : 1.216267, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4953], Loss1 : 1.206172, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4954], Loss1 : 1.214103, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4955], Loss1 : 1.202030, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4956], Loss1 : 1.247932, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4957], Loss1 : 1.221882, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4958], Loss1 : 1.198315, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4959], Loss1 : 1.215962, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4960], Loss1 : 1.213839, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4961], Loss1 : 1.235482, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4962], Loss1 : 1.227583, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4963], Loss1 : 1.237013, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4964], Loss1 : 1.218443, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4965], Loss1 : 1.211267, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4966], Loss1 : 1.229278, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4967], Loss1 : 1.222458, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4968], Loss1 : 1.231003, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4969], Loss1 : 1.251630, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4970], Loss1 : 1.242107, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4971], Loss1 : 1.235247, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4972], Loss1 : 1.198790, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4973], Loss1 : 1.231549, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4974], Loss1 : 1.258208, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4975], Loss1 : 1.246147, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4976], Loss1 : 1.259236, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4977], Loss1 : 1.223087, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4978], Loss1 : 1.212791, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4979], Loss1 : 1.173466, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4980], Loss1 : 1.275107, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4981], Loss1 : 1.237848, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4982], Loss1 : 1.200808, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4983], Loss1 : 1.245962, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4984], Loss1 : 1.226166, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4985], Loss1 : 1.217170, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4986], Loss1 : 1.245964, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4987], Loss1 : 1.199140, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4988], Loss1 : 1.221497, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4989], Loss1 : 1.219276, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4990], Loss1 : 1.247904, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4991], Loss1 : 1.246957, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4992], Loss1 : 1.231199, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4993], Loss1 : 1.195324, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4994], Loss1 : 1.202360, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4995], Loss1 : 1.196244, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4996], Loss1 : 1.205843, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4997], Loss1 : 1.208531, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4998], Loss1 : 1.222046, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [4999], Loss1 : 1.235830, Loss2 : 0.022539, Train Loss : [0.02254] \n",
      "Epoch [5000], Loss1 : 1.244645, Loss2 : 0.022539, Train Loss : [0.02254] "
     ]
    }
   ],
   "source": [
    "# DataLoader 정의\n",
    "train_dataset = TensorDataset(torch.from_numpy(total).type(torch.float), torch.from_numpy(total).type(torch.float))\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=2, worker_init_fn=seed_worker)\n",
    "\n",
    "# 학습 모델 설정\n",
    "model = AutoEncoder().to(device)\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss().to(device)\n",
    "criterion2 = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])  # Adam\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=len(train_loader) * int(CFG['EPOCHS']*0.5),\n",
    "    num_training_steps=len(train_loader) * CFG['EPOCHS']\n",
    ")\n",
    "\n",
    "\n",
    "best_score = 100\n",
    "\n",
    "# train\n",
    "torch.backends.cudnn.benchmark = True\n",
    "for epoch in range(1,CFG['EPOCHS']+1):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for x, label in iter(train_loader):            \n",
    "        x, label = x.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_label, pred_vector = model(x)\n",
    "        target = pred_label[:len(y2), :3] # 앞의 세 개를 label로 유도\n",
    "        target2 = torch.softmax(target, axis=1)    \n",
    "\n",
    "        loss1 = criterion1(y2.float(), target2)\n",
    "        loss2 = criterion2(label, pred_vector)\n",
    "        \n",
    "        loss = loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    tr_loss = np.mean(train_loss)\n",
    "    print()\n",
    "    print(f'Epoch [{epoch}], Loss1 : {loss1:.6f}, Loss2 : {loss2:.6f}, Train Loss : [{tr_loss:.5f}]', end=\" \")\n",
    "    # print(f'Epoch [{epoch}], Train Loss : [{tr_loss:.5f}]')\n",
    "\n",
    "    if best_score > tr_loss:\n",
    "        print(\"- Model Saved!\")\n",
    "        torch.save(model.state_dict(), f'./models/AutoEncoder_total.pt')\n",
    "        best_score = tr_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
