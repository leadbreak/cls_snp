{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, sampler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN, RandomOverSampler, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours, RepeatedEditedNearestNeighbours, AllKNN, CondensedNearestNeighbour, OneSidedSelection, NeighbourhoodCleaningRule\n",
    "\n",
    "import shap\n",
    "import catboost\n",
    "from catboost import Pool, cv\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   id      248 non-null    object  \n",
      " 1   trait   248 non-null    category\n",
      " 2   SNP_01  248 non-null    category\n",
      " 3   SNP_02  248 non-null    category\n",
      " 4   SNP_03  248 non-null    category\n",
      " 5   SNP_04  248 non-null    category\n",
      " 6   SNP_05  248 non-null    category\n",
      " 7   SNP_06  248 non-null    category\n",
      " 8   SNP_07  248 non-null    category\n",
      " 9   SNP_08  248 non-null    category\n",
      " 10  SNP_09  248 non-null    category\n",
      " 11  SNP_10  248 non-null    category\n",
      " 12  SNP_11  248 non-null    category\n",
      " 13  SNP_12  248 non-null    category\n",
      " 14  SNP_13  248 non-null    category\n",
      " 15  SNP_14  248 non-null    category\n",
      " 16  SNP_15  248 non-null    category\n",
      " 17  class   248 non-null    object  \n",
      "dtypes: category(16), object(2)\n",
      "memory usage: 9.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   id      175 non-null    object  \n",
      " 1   trait   175 non-null    category\n",
      " 2   SNP_01  175 non-null    category\n",
      " 3   SNP_02  175 non-null    category\n",
      " 4   SNP_03  175 non-null    category\n",
      " 5   SNP_04  175 non-null    category\n",
      " 6   SNP_05  175 non-null    category\n",
      " 7   SNP_06  175 non-null    category\n",
      " 8   SNP_07  175 non-null    category\n",
      " 9   SNP_08  175 non-null    category\n",
      " 10  SNP_09  175 non-null    category\n",
      " 11  SNP_10  175 non-null    category\n",
      " 12  SNP_11  175 non-null    category\n",
      " 13  SNP_12  175 non-null    category\n",
      " 14  SNP_13  175 non-null    category\n",
      " 15  SNP_14  175 non-null    category\n",
      " 16  SNP_15  175 non-null    category\n",
      "dtypes: category(16), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\").drop(columns=['father', 'mother', 'gender'])\n",
    "train.drop_duplicates(subset=train.columns.tolist()[5:20], inplace=True, ignore_index=True)\n",
    "test = pd.read_csv(\"./data/test.csv\").drop(columns=['father', 'mother', 'gender'])\n",
    "\n",
    "train.iloc[:, 1:-1] = train.iloc[:, 1:-1].astype('category')\n",
    "test.iloc[:, 1:] = test.iloc[:, 1:].astype('category')\n",
    "\n",
    "answer = np.zeros(len(test)) - 1\n",
    "\n",
    "train.info(), test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 1871.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248 entries, 0 to 247\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   id      248 non-null    object  \n",
      " 1   trait   248 non-null    category\n",
      " 2   SNP_01  248 non-null    category\n",
      " 3   SNP_02  248 non-null    category\n",
      " 4   SNP_03  248 non-null    category\n",
      " 5   SNP_04  248 non-null    category\n",
      " 6   SNP_05  248 non-null    category\n",
      " 7   SNP_06  248 non-null    category\n",
      " 8   SNP_07  248 non-null    category\n",
      " 9   SNP_08  248 non-null    category\n",
      " 10  SNP_09  248 non-null    category\n",
      " 11  SNP_10  248 non-null    category\n",
      " 12  SNP_11  248 non-null    category\n",
      " 13  SNP_12  248 non-null    category\n",
      " 14  SNP_13  248 non-null    category\n",
      " 15  SNP_14  248 non-null    category\n",
      " 16  SNP_15  248 non-null    category\n",
      " 17  class   248 non-null    object  \n",
      "dtypes: category(16), object(2)\n",
      "memory usage: 9.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   id      175 non-null    object  \n",
      " 1   trait   175 non-null    category\n",
      " 2   SNP_01  175 non-null    category\n",
      " 3   SNP_02  175 non-null    category\n",
      " 4   SNP_03  175 non-null    category\n",
      " 5   SNP_04  175 non-null    category\n",
      " 6   SNP_05  175 non-null    category\n",
      " 7   SNP_06  175 non-null    category\n",
      " 8   SNP_07  175 non-null    category\n",
      " 9   SNP_08  175 non-null    category\n",
      " 10  SNP_09  175 non-null    category\n",
      " 11  SNP_10  175 non-null    category\n",
      " 12  SNP_11  175 non-null    category\n",
      " 13  SNP_12  175 non-null    category\n",
      " 14  SNP_13  175 non-null    category\n",
      " 15  SNP_14  175 non-null    category\n",
      " 16  SNP_15  175 non-null    category\n",
      "dtypes: category(16), object(1)\n",
      "memory usage: 6.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text 형태의 categorical 변수들을 숫자형태로 변경\n",
    "\n",
    "for i in tqdm(range(1, 15+1)) :\n",
    "    target = str(i) if i >= 10 else \"0\"+str(i)\n",
    "    try :   \n",
    "        cols = sorted(train[f\"SNP_{target}\"].unique().tolist())  \n",
    "        train[f\"SNP_{target}\"] = train[f\"SNP_{target}\"].map(lambda x : 0 if x==cols[0] else (1 if x==cols[1] else 2))\n",
    "        test[f\"SNP_{target}\"] = test[f\"SNP_{target}\"].map(lambda x : 0 if x==cols[0] else (1 if x==cols[1] else 2))\n",
    "    except :\n",
    "        continue\n",
    "\n",
    "train.info(), test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([248, 47]), torch.Size([175, 47]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = train.iloc[:, 1:-1].to_numpy(), train['class'].map(lambda x : 0 if x=='A' else(1 if x=='B' else 2)).values\n",
    "X_test = test.iloc[:,1:].to_numpy()\n",
    "\n",
    "# Load the data\n",
    "train_data = torch.from_numpy(X)\n",
    "test_data = torch.from_numpy(X_test)\n",
    "\n",
    "# Preprocess the data by one-hot encoding the categories\n",
    "one_hot_data_01 = F.one_hot(train_data[:,:1]-1, num_classes=2).view(len(X), 2).float()\n",
    "one_hot_data_02 = F.one_hot(train_data[:,1:], num_classes=3).view(len(X), 3*train_data[:,1:].size(1)).float()\n",
    "\n",
    "one_hot_train = torch.concat([one_hot_data_01, one_hot_data_02], axis=1)\n",
    "\n",
    "one_hot_data_01 = F.one_hot(test_data[:,:1]-1, num_classes=2).view(len(X_test), 2).float()\n",
    "one_hot_data_02 = F.one_hot(test_data[:,1:], num_classes=3).view(len(X_test), 3*test_data[:,1:].size(1)).float()\n",
    "\n",
    "one_hot_test = torch.concat([one_hot_data_01, one_hot_data_02], axis=1)\n",
    "\n",
    "one_hot_train.shape, one_hot_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2360, 47), (2360,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed=333\n",
    "strategy1 = {0 : 40, 1 : 70, 2 : 60}\n",
    "\n",
    "under1 = RandomUnderSampler(sampling_strategy=strategy1, random_state=random_seed)\n",
    "under2 = EditedNearestNeighbours()\n",
    "under3 = RepeatedEditedNearestNeighbours()\n",
    "under4 = AllKNN()\n",
    "under5 = CondensedNearestNeighbour(random_state=random_seed)\n",
    "under6 = OneSidedSelection(random_state=random_seed)\n",
    "under7 = NeighbourhoodCleaningRule()\n",
    "\n",
    "X, y = one_hot_train, train['class'].map(lambda x : 0 if x=='A' else (1 if x=='B' else 2)).values\n",
    "\n",
    "X1, y1 = under1.fit_resample(X, y)\n",
    "X2, y2 = under2.fit_resample(X, y)\n",
    "X3, y3 = under3.fit_resample(X, y)\n",
    "X4, y4 = under4.fit_resample(X, y)\n",
    "X5, y5 = under5.fit_resample(X, y)\n",
    "X6, y6 = under6.fit_resample(X, y)\n",
    "X7, y7 = under7.fit_resample(X, y)\n",
    "\n",
    "strategy2 = {0 : 100, 1 : 120, 2 : 110}\n",
    "\n",
    "over1 = SMOTEN(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over2 = SMOTE(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over3 = RandomOverSampler(sampling_strategy=strategy2, random_state=random_seed)\n",
    "\n",
    "X8, y8 = over1.fit_resample(X, y)\n",
    "X9, y9 = over2.fit_resample(X, y)\n",
    "X10, y10 = over3.fit_resample(X, y)\n",
    "\n",
    "data = np.concatenate([one_hot_train, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10])\n",
    "label = np.concatenate([y, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10])\n",
    "\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12482, 47), (12482,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 3833\n",
    "strategy1 = {0 : 40, 1 : 70, 2 : 50}\n",
    "\n",
    "under1 = RandomUnderSampler(sampling_strategy=strategy1, random_state=random_seed)\n",
    "under2 = EditedNearestNeighbours()\n",
    "under3 = RepeatedEditedNearestNeighbours()\n",
    "under4 = AllKNN()\n",
    "under5 = CondensedNearestNeighbour(random_state=random_seed)\n",
    "under6 = OneSidedSelection(random_state=random_seed)\n",
    "under7 = NeighbourhoodCleaningRule()\n",
    "\n",
    "X, y = one_hot_train, train['class'].map(lambda x : 0 if x=='A' else (1 if x=='B' else 2)).values\n",
    "\n",
    "X1, y1 = under1.fit_resample(X, y)\n",
    "X2, y2 = under2.fit_resample(X, y)\n",
    "X3, y3 = under3.fit_resample(X, y)\n",
    "X4, y4 = under4.fit_resample(X, y)\n",
    "X5, y5 = under5.fit_resample(X, y)\n",
    "X6, y6 = under6.fit_resample(X, y)\n",
    "X7, y7 = under7.fit_resample(X, y)\n",
    "\n",
    "strategy2 = {0 : 1000, 1 : 1000, 2 : 1000}\n",
    "\n",
    "over1 = SMOTEN(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over2 = SMOTE(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over3 = RandomOverSampler(sampling_strategy=strategy2, random_state=random_seed)\n",
    "\n",
    "X8, y8 = over1.fit_resample(X, y)\n",
    "X9, y9 = over2.fit_resample(X, y)\n",
    "X10, y10 = over3.fit_resample(X, y)\n",
    "\n",
    "data = np.concatenate([data, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10])\n",
    "label = np.concatenate([label, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10])\n",
    "\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23205, 47), (23205,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 3587\n",
    "strategy1 = {0 : 40, 1 : 70, 2 : 50}\n",
    "\n",
    "under1 = RandomUnderSampler(sampling_strategy=strategy1, random_state=random_seed)\n",
    "under2 = EditedNearestNeighbours()\n",
    "under3 = RepeatedEditedNearestNeighbours()\n",
    "under4 = AllKNN()\n",
    "under5 = CondensedNearestNeighbour(random_state=random_seed)\n",
    "under6 = OneSidedSelection(random_state=random_seed)\n",
    "under7 = NeighbourhoodCleaningRule()\n",
    "\n",
    "X, y = one_hot_train, train['class'].map(lambda x : 0 if x=='A' else (1 if x=='B' else 2)).values\n",
    "\n",
    "X1, y1 = under1.fit_resample(X, y)\n",
    "X2, y2 = under2.fit_resample(X, y)\n",
    "X3, y3 = under3.fit_resample(X, y)\n",
    "X4, y4 = under4.fit_resample(X, y)\n",
    "X5, y5 = under5.fit_resample(X, y)\n",
    "X6, y6 = under6.fit_resample(X, y)\n",
    "X7, y7 = under7.fit_resample(X, y)\n",
    "\n",
    "strategy2 = {0 : 1000, 1 : 1200, 2 : 1000}\n",
    "\n",
    "over1 = SMOTEN(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over2 = SMOTE(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over3 = RandomOverSampler(sampling_strategy=strategy2, random_state=random_seed)\n",
    "\n",
    "X8, y8 = over1.fit_resample(X, y)\n",
    "X9, y9 = over2.fit_resample(X, y)\n",
    "X10, y10 = over3.fit_resample(X, y)\n",
    "\n",
    "data = np.concatenate([data, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10])\n",
    "label = np.concatenate([label, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10])\n",
    "\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25327, 47), (25327,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 313\n",
    "strategy1 = {0 : 40, 1 : 70, 2 : 50}\n",
    "\n",
    "under1 = RandomUnderSampler(sampling_strategy=strategy1, random_state=random_seed)\n",
    "under2 = EditedNearestNeighbours()\n",
    "under3 = RepeatedEditedNearestNeighbours()\n",
    "under4 = AllKNN()\n",
    "under5 = CondensedNearestNeighbour(random_state=random_seed)\n",
    "under6 = OneSidedSelection(random_state=random_seed)\n",
    "under7 = NeighbourhoodCleaningRule()\n",
    "\n",
    "X, y = one_hot_train, train['class'].map(lambda x : 0 if x=='A' else (1 if x=='B' else 2)).values\n",
    "\n",
    "X1, y1 = under1.fit_resample(X, y)\n",
    "X2, y2 = under2.fit_resample(X, y)\n",
    "X3, y3 = under3.fit_resample(X, y)\n",
    "X4, y4 = under4.fit_resample(X, y)\n",
    "X5, y5 = under5.fit_resample(X, y)\n",
    "X6, y6 = under6.fit_resample(X, y)\n",
    "X7, y7 = under7.fit_resample(X, y)\n",
    "\n",
    "strategy2 = {0 : 100, 1 : 120, 2 : 110}\n",
    "\n",
    "over1 = SMOTEN(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over2 = SMOTE(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over3 = RandomOverSampler(sampling_strategy=strategy2, random_state=random_seed)\n",
    "\n",
    "X8, y8 = over1.fit_resample(X, y)\n",
    "X9, y9 = over2.fit_resample(X, y)\n",
    "X10, y10 = over3.fit_resample(X, y)\n",
    "\n",
    "data = np.concatenate([data, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10])\n",
    "label = np.concatenate([label, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10])\n",
    "\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27431, 47), (27431,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 10000\n",
    "strategy1 = {0 : 40, 1 : 70, 2 : 50}\n",
    "\n",
    "under1 = RandomUnderSampler(sampling_strategy=strategy1, random_state=random_seed)\n",
    "under2 = EditedNearestNeighbours()\n",
    "under3 = RepeatedEditedNearestNeighbours()\n",
    "under4 = AllKNN()\n",
    "under5 = CondensedNearestNeighbour(random_state=random_seed)\n",
    "under6 = OneSidedSelection(random_state=random_seed)\n",
    "under7 = NeighbourhoodCleaningRule()\n",
    "\n",
    "X, y = one_hot_train, train['class'].map(lambda x : 0 if x=='A' else (1 if x=='B' else 2)).values\n",
    "\n",
    "X1, y1 = under1.fit_resample(X, y)\n",
    "X2, y2 = under2.fit_resample(X, y)\n",
    "X3, y3 = under3.fit_resample(X, y)\n",
    "X4, y4 = under4.fit_resample(X, y)\n",
    "X5, y5 = under5.fit_resample(X, y)\n",
    "X6, y6 = under6.fit_resample(X, y)\n",
    "X7, y7 = under7.fit_resample(X, y)\n",
    "\n",
    "strategy2 = {0 : 100, 1 : 120, 2 : 110}\n",
    "\n",
    "over1 = SMOTEN(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over2 = SMOTE(sampling_strategy=strategy2, random_state=random_seed)\n",
    "over3 = RandomOverSampler(sampling_strategy=strategy2, random_state=random_seed)\n",
    "\n",
    "X8, y8 = over1.fit_resample(X, y)\n",
    "X9, y9 = over2.fit_resample(X, y)\n",
    "X10, y10 = over3.fit_resample(X, y)\n",
    "\n",
    "data = np.concatenate([data, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10])\n",
    "label = np.concatenate([label, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10])\n",
    "\n",
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>var_21</th>\n",
       "      <th>var_22</th>\n",
       "      <th>var_23</th>\n",
       "      <th>var_24</th>\n",
       "      <th>var_25</th>\n",
       "      <th>var_26</th>\n",
       "      <th>var_27</th>\n",
       "      <th>var_28</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_30</th>\n",
       "      <th>var_31</th>\n",
       "      <th>var_32</th>\n",
       "      <th>var_33</th>\n",
       "      <th>var_34</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>var_38</th>\n",
       "      <th>var_39</th>\n",
       "      <th>var_40</th>\n",
       "      <th>var_41</th>\n",
       "      <th>var_42</th>\n",
       "      <th>var_43</th>\n",
       "      <th>var_44</th>\n",
       "      <th>var_45</th>\n",
       "      <th>var_46</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0  var_1  var_2  var_3  var_4  var_5  var_6  var_7  var_8  var_9  \\\n",
       "0      0.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0    1.0    0.0   \n",
       "1      0.0    1.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0   \n",
       "2      0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    1.0    0.0   \n",
       "3      1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    0.0   \n",
       "4      0.0    1.0    0.0    0.0    1.0    0.0    0.0    1.0    0.0    0.0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "470    0.0    1.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0   \n",
       "471    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0   \n",
       "472    0.0    1.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    1.0   \n",
       "473    0.0    1.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "474    0.0    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "     var_10  var_11  var_12  var_13  var_14  var_15  var_16  var_17  var_18  \\\n",
       "0       0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "1       0.0     1.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "2       0.0     0.0     1.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "3       0.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "4       1.0     1.0     0.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "470     0.0     1.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "471     0.0     1.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "472     0.0     1.0     0.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "473     1.0     1.0     0.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "474     0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "     var_19  var_20  var_21  var_22  var_23  var_24  var_25  var_26  var_27  \\\n",
       "0       0.0     1.0     0.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
       "1       0.0     1.0     0.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "2       1.0     1.0     0.0     0.0     0.0     1.0     0.0     0.0     1.0   \n",
       "3       1.0     0.0     0.0     1.0     1.0     0.0     0.0     0.0     0.0   \n",
       "4       0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "470     0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "471     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "472     0.0     0.0     1.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "473     0.0     1.0     0.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "474     0.0     1.0     0.0     0.0     0.0     0.0     1.0     1.0     0.0   \n",
       "\n",
       "     var_28  var_29  var_30  var_31  var_32  var_33  var_34  var_35  var_36  \\\n",
       "0       0.0     0.0     0.0     1.0     0.0     1.0     0.0     1.0     0.0   \n",
       "1       0.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "2       0.0     0.0     1.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "3       1.0     0.0     1.0     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "4       0.0     0.0     0.0     1.0     1.0     0.0     0.0     1.0     0.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "470     0.0     1.0     0.0     0.0     0.0     1.0     0.0     1.0     0.0   \n",
       "471     0.0     0.0     0.0     1.0     0.0     1.0     0.0     1.0     0.0   \n",
       "472     0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0   \n",
       "473     0.0     0.0     0.0     1.0     1.0     0.0     0.0     0.0     0.0   \n",
       "474     0.0     0.0     0.0     1.0     1.0     0.0     0.0     0.0     1.0   \n",
       "\n",
       "     var_37  var_38  var_39  var_40  var_41  var_42  var_43  var_44  var_45  \\\n",
       "0       0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "1       0.0     0.0     0.0     1.0     1.0     0.0     0.0     1.0     0.0   \n",
       "2       0.0     1.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "3       1.0     0.0     0.0     1.0     1.0     0.0     0.0     0.0     0.0   \n",
       "4       0.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "470     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0   \n",
       "471     0.0     0.0     0.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "472     0.0     0.0     1.0     0.0     1.0     0.0     0.0     1.0     0.0   \n",
       "473     0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "474     0.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0     1.0   \n",
       "\n",
       "     var_46  class  \n",
       "0       0.0      1  \n",
       "1       0.0      2  \n",
       "2       0.0      1  \n",
       "3       1.0      0  \n",
       "4       0.0      2  \n",
       "..      ...    ...  \n",
       "470     0.0      2  \n",
       "471     0.0      2  \n",
       "472     0.0      2  \n",
       "473     0.0      2  \n",
       "474     0.0      2  \n",
       "\n",
       "[475 rows x 48 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data, columns=[f\"var_{x}\" for x in range(data.shape[1])])\n",
    "df[df >= 0.5] = 1.0\n",
    "df[df < 0.5] = 0.0\n",
    "df['class'] = label\n",
    "df['var_2'] = 0.0\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>var_16</th>\n",
       "      <th>var_17</th>\n",
       "      <th>var_18</th>\n",
       "      <th>var_19</th>\n",
       "      <th>var_20</th>\n",
       "      <th>var_21</th>\n",
       "      <th>var_22</th>\n",
       "      <th>var_23</th>\n",
       "      <th>var_24</th>\n",
       "      <th>var_25</th>\n",
       "      <th>var_26</th>\n",
       "      <th>var_27</th>\n",
       "      <th>var_28</th>\n",
       "      <th>var_29</th>\n",
       "      <th>var_30</th>\n",
       "      <th>var_31</th>\n",
       "      <th>var_32</th>\n",
       "      <th>var_33</th>\n",
       "      <th>var_34</th>\n",
       "      <th>var_35</th>\n",
       "      <th>var_36</th>\n",
       "      <th>var_37</th>\n",
       "      <th>var_38</th>\n",
       "      <th>var_39</th>\n",
       "      <th>var_40</th>\n",
       "      <th>var_41</th>\n",
       "      <th>var_42</th>\n",
       "      <th>var_43</th>\n",
       "      <th>var_44</th>\n",
       "      <th>var_45</th>\n",
       "      <th>var_46</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.0</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "      <td>475.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.229474</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202105</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.183158</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.404211</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.338947</td>\n",
       "      <td>0.124211</td>\n",
       "      <td>0.298947</td>\n",
       "      <td>0.338947</td>\n",
       "      <td>0.307368</td>\n",
       "      <td>0.189474</td>\n",
       "      <td>0.446316</td>\n",
       "      <td>0.223158</td>\n",
       "      <td>0.658947</td>\n",
       "      <td>0.181053</td>\n",
       "      <td>0.155789</td>\n",
       "      <td>0.286316</td>\n",
       "      <td>0.374737</td>\n",
       "      <td>0.294737</td>\n",
       "      <td>0.717895</td>\n",
       "      <td>0.187368</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.143158</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>0.602105</td>\n",
       "      <td>0.290526</td>\n",
       "      <td>0.330526</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.541053</td>\n",
       "      <td>0.214737</td>\n",
       "      <td>0.162105</td>\n",
       "      <td>0.166316</td>\n",
       "      <td>0.349474</td>\n",
       "      <td>0.381053</td>\n",
       "      <td>0.722105</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.425263</td>\n",
       "      <td>0.298947</td>\n",
       "      <td>0.172632</td>\n",
       "      <td>1.090526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.420938</td>\n",
       "      <td>0.420938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401994</td>\n",
       "      <td>0.495819</td>\n",
       "      <td>0.387204</td>\n",
       "      <td>0.482885</td>\n",
       "      <td>0.479886</td>\n",
       "      <td>0.491256</td>\n",
       "      <td>0.473129</td>\n",
       "      <td>0.350603</td>\n",
       "      <td>0.500127</td>\n",
       "      <td>0.473851</td>\n",
       "      <td>0.330169</td>\n",
       "      <td>0.458279</td>\n",
       "      <td>0.473851</td>\n",
       "      <td>0.461890</td>\n",
       "      <td>0.392298</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.416802</td>\n",
       "      <td>0.474563</td>\n",
       "      <td>0.385468</td>\n",
       "      <td>0.363038</td>\n",
       "      <td>0.452515</td>\n",
       "      <td>0.484565</td>\n",
       "      <td>0.456405</td>\n",
       "      <td>0.450499</td>\n",
       "      <td>0.390618</td>\n",
       "      <td>0.250923</td>\n",
       "      <td>0.350603</td>\n",
       "      <td>0.420938</td>\n",
       "      <td>0.489980</td>\n",
       "      <td>0.454484</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.449472</td>\n",
       "      <td>0.498837</td>\n",
       "      <td>0.411073</td>\n",
       "      <td>0.368936</td>\n",
       "      <td>0.372756</td>\n",
       "      <td>0.477306</td>\n",
       "      <td>0.486157</td>\n",
       "      <td>0.448434</td>\n",
       "      <td>0.383712</td>\n",
       "      <td>0.250923</td>\n",
       "      <td>0.494904</td>\n",
       "      <td>0.458279</td>\n",
       "      <td>0.378327</td>\n",
       "      <td>0.736492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            var_0       var_1  var_2       var_3       var_4       var_5  \\\n",
       "count  475.000000  475.000000  475.0  475.000000  475.000000  475.000000   \n",
       "mean     0.229474    0.770526    0.0    0.202105    0.568421    0.183158   \n",
       "std      0.420938    0.420938    0.0    0.401994    0.495819    0.387204   \n",
       "min      0.000000    0.000000    0.0    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    0.0    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    1.000000    0.0    0.000000    1.000000    0.000000   \n",
       "75%      0.000000    1.000000    0.0    0.000000    1.000000    0.000000   \n",
       "max      1.000000    1.000000    0.0    1.000000    1.000000    1.000000   \n",
       "\n",
       "            var_6       var_7       var_8       var_9      var_10      var_11  \\\n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000   \n",
       "mean     0.368421    0.357895    0.404211    0.336842    0.143158    0.480000   \n",
       "std      0.482885    0.479886    0.491256    0.473129    0.350603    0.500127   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           var_12      var_13      var_14      var_15      var_16      var_17  \\\n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000   \n",
       "mean     0.338947    0.124211    0.298947    0.338947    0.307368    0.189474   \n",
       "std      0.473851    0.330169    0.458279    0.473851    0.461890    0.392298   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    0.000000    1.000000    1.000000    1.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           var_18      var_19      var_20      var_21      var_22      var_23  \\\n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000   \n",
       "mean     0.446316    0.223158    0.658947    0.181053    0.155789    0.286316   \n",
       "std      0.497634    0.416802    0.474563    0.385468    0.363038    0.452515   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    0.000000    1.000000    0.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           var_24      var_25      var_26      var_27      var_28      var_29  \\\n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000   \n",
       "mean     0.374737    0.294737    0.717895    0.187368    0.067368    0.143158   \n",
       "std      0.484565    0.456405    0.450499    0.390618    0.250923    0.350603   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           var_30      var_31      var_32      var_33      var_34      var_35  \\\n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000   \n",
       "mean     0.229474    0.602105    0.290526    0.330526    0.280000    0.541053   \n",
       "std      0.420938    0.489980    0.454484    0.470899    0.449472    0.498837   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    1.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           var_36      var_37      var_38      var_39      var_40      var_41  \\\n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000   \n",
       "mean     0.214737    0.162105    0.166316    0.349474    0.381053    0.722105   \n",
       "std      0.411073    0.368936    0.372756    0.477306    0.486157    0.448434   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      0.000000    0.000000    0.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "           var_42      var_43      var_44      var_45      var_46       class  \n",
       "count  475.000000  475.000000  475.000000  475.000000  475.000000  475.000000  \n",
       "mean     0.178947    0.067368    0.425263    0.298947    0.172632    1.090526  \n",
       "std      0.383712    0.250923    0.494904    0.458279    0.378327    0.736492  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000  \n",
       "75%      0.000000    0.000000    1.000000    1.000000    0.000000    2.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    2.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_classes):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads, dropout=0.5)\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.attention(x, x, x)[0]\n",
    "        x = self.output_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, num_epochs, batch_size, learning_rate):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    step_size = 5\n",
    "    gamma=0.9\n",
    "\n",
    "    # define the scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    train_data, val_data = data, data\n",
    "\n",
    "    # Create DataLoaders for the training and validation sets\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Loop over the number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Loop over the training data\n",
    "        for x, y in train_loader:\n",
    "            # Move the data to the correct device\n",
    "            x, y = x.to(device), torch.Tensor(y).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Initialize the validation loss and accuracy\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "\n",
    "        # Loop over the validation data\n",
    "        for x, y in val_loader:\n",
    "            # Move the data to the correct device\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "            # Update the validation loss and accuracy\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (logits.argmax(1) == y).float().mean().item()\n",
    "\n",
    "        # Calculate the average validation loss and accuracy\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "\n",
    "        # Print the epoch, loss, and accuracy\n",
    "        print(f\"Epoch {epoch+1}: loss = {loss:.4f}, val_loss = {val_loss:.4f}, val_accuracy = {val_acc:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m dataset_BC \u001b[39m=\u001b[39m SparseDataset(df[df[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues, (df[df[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m), transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model_A \u001b[39m=\u001b[39m train(modelA, dataset_A, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [33], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     29\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), torch\u001b[39m.\u001b[39mTensor(y)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     33\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, y)\n\u001b[1;32m     35\u001b[0m \u001b[39m# Backward pass and optimization step\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [31], line 14\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layer(x)\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(x, x, x)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "modelA = Transformer(input_dim=47, hidden_dim=256, num_heads=4, num_classes=2)\n",
    "modelB = Transformer(input_dim=47, hidden_dim=256, num_heads=8, num_classes=2)\n",
    "modelC = Transformer(input_dim=47, hidden_dim=256, num_heads=8, num_classes=2)\n",
    "modelBC = Transformer(input_dim=47, hidden_dim=128, num_heads=4, num_classes=2)\n",
    "\n",
    "# Create the dataset and data loader\n",
    "dataset_A = SparseDataset(df.iloc[:,:-1].values, (df['class']==0).values.astype(int), transform=None)\n",
    "dataset_B = SparseDataset(df.iloc[:,:-1].values, (df['class']==1).values.astype(int), transform=None)\n",
    "dataset_C = SparseDataset(df.iloc[:,:-1].values, (df['class']==2).values.astype(int), transform=None)\n",
    "dataset_BC = SparseDataset(df[df['class']!=0].iloc[:,:-1].values, (df[df['class']!=0]['class']==2).values.astype(int), transform=None)\n",
    "\n",
    "# Train the model\n",
    "model_A = train(modelA, dataset_A, num_epochs=5, batch_size=64, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_B \u001b[39m=\u001b[39m train(modelB, dataset_B, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [26], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     29\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), torch\u001b[39m.\u001b[39mTensor(y)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m logits \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     33\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, y)\n\u001b[1;32m     35\u001b[0m \u001b[39m# Backward pass and optimization step\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [24], line 14\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_layer(x)\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(x, x, x)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_B = train(modelB, dataset_B, num_epochs=100, batch_size=512, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.3523, val_loss = 0.1780, val_accuracy = 0.9433\n",
      "Epoch 2: loss = 0.0307, val_loss = 0.1176, val_accuracy = 0.9643\n",
      "Epoch 3: loss = 0.0657, val_loss = 0.1051, val_accuracy = 0.9748\n",
      "Epoch 4: loss = 0.2326, val_loss = 0.1542, val_accuracy = 0.9349\n",
      "Epoch 5: loss = 0.0683, val_loss = 0.0867, val_accuracy = 0.9811\n",
      "Epoch 6: loss = 0.0358, val_loss = 0.1124, val_accuracy = 0.9769\n",
      "Epoch 7: loss = 0.0890, val_loss = 0.0951, val_accuracy = 0.9769\n",
      "Epoch 8: loss = 0.0779, val_loss = 0.0725, val_accuracy = 0.9811\n",
      "Epoch 9: loss = 0.1351, val_loss = 0.0927, val_accuracy = 0.9811\n",
      "Epoch 10: loss = 0.2642, val_loss = 0.1237, val_accuracy = 0.9706\n",
      "Epoch 11: loss = 0.1464, val_loss = 0.1029, val_accuracy = 0.9706\n",
      "Epoch 12: loss = 0.3545, val_loss = 0.1806, val_accuracy = 0.9811\n",
      "Epoch 13: loss = 0.0965, val_loss = 0.0464, val_accuracy = 0.9853\n",
      "Epoch 14: loss = 0.0518, val_loss = 0.0486, val_accuracy = 0.9790\n",
      "Epoch 15: loss = 0.1621, val_loss = 0.0466, val_accuracy = 0.9832\n",
      "Epoch 16: loss = 0.1244, val_loss = 0.0670, val_accuracy = 0.9832\n",
      "Epoch 17: loss = 0.0563, val_loss = 0.0820, val_accuracy = 0.9790\n",
      "Epoch 18: loss = 0.0260, val_loss = 0.0390, val_accuracy = 0.9874\n",
      "Epoch 19: loss = 0.0186, val_loss = 0.0315, val_accuracy = 0.9874\n",
      "Epoch 20: loss = 0.0385, val_loss = 0.0319, val_accuracy = 0.9937\n",
      "Epoch 21: loss = 0.0403, val_loss = 0.0474, val_accuracy = 0.9832\n",
      "Epoch 22: loss = 0.0465, val_loss = 0.0522, val_accuracy = 0.9832\n",
      "Epoch 23: loss = 0.0214, val_loss = 0.0245, val_accuracy = 0.9958\n",
      "Epoch 24: loss = 0.0050, val_loss = 0.0216, val_accuracy = 0.9895\n",
      "Epoch 25: loss = 0.0293, val_loss = 0.0248, val_accuracy = 0.9916\n",
      "Epoch 26: loss = 0.0060, val_loss = 0.0325, val_accuracy = 0.9853\n",
      "Epoch 27: loss = 0.0113, val_loss = 0.0206, val_accuracy = 0.9916\n",
      "Epoch 28: loss = 0.0015, val_loss = 0.0356, val_accuracy = 0.9853\n",
      "Epoch 29: loss = 0.0187, val_loss = 0.0234, val_accuracy = 0.9895\n",
      "Epoch 30: loss = 0.0133, val_loss = 0.0159, val_accuracy = 0.9937\n",
      "Epoch 31: loss = 0.0144, val_loss = 0.0155, val_accuracy = 0.9937\n",
      "Epoch 32: loss = 0.0288, val_loss = 0.0297, val_accuracy = 0.9874\n",
      "Epoch 33: loss = 0.0007, val_loss = 0.0105, val_accuracy = 0.9958\n",
      "Epoch 34: loss = 0.0009, val_loss = 0.0116, val_accuracy = 0.9937\n",
      "Epoch 35: loss = 0.0408, val_loss = 0.0174, val_accuracy = 0.9958\n",
      "Epoch 36: loss = 0.0035, val_loss = 0.0112, val_accuracy = 0.9937\n",
      "Epoch 37: loss = 0.1243, val_loss = 0.0494, val_accuracy = 0.9832\n",
      "Epoch 38: loss = 0.0041, val_loss = 0.0143, val_accuracy = 0.9916\n",
      "Epoch 39: loss = 0.0189, val_loss = 0.0139, val_accuracy = 0.9958\n",
      "Epoch 40: loss = 0.0015, val_loss = 0.0121, val_accuracy = 0.9958\n",
      "Epoch 41: loss = 0.0023, val_loss = 0.0201, val_accuracy = 0.9937\n",
      "Epoch 42: loss = 0.0013, val_loss = 0.0096, val_accuracy = 0.9958\n",
      "Epoch 43: loss = 0.0127, val_loss = 0.0193, val_accuracy = 0.9958\n",
      "Epoch 44: loss = 0.0103, val_loss = 0.0235, val_accuracy = 0.9937\n",
      "Epoch 45: loss = 0.0224, val_loss = 0.0172, val_accuracy = 0.9958\n",
      "Epoch 46: loss = 0.0065, val_loss = 0.0079, val_accuracy = 0.9979\n",
      "Epoch 47: loss = 0.0015, val_loss = 0.0047, val_accuracy = 0.9979\n",
      "Epoch 48: loss = 0.0003, val_loss = 0.0048, val_accuracy = 0.9979\n",
      "Epoch 49: loss = 0.0019, val_loss = 0.0062, val_accuracy = 0.9979\n",
      "Epoch 50: loss = 0.0008, val_loss = 0.0037, val_accuracy = 1.0000\n",
      "Epoch 51: loss = 0.0072, val_loss = 0.0048, val_accuracy = 0.9979\n",
      "Epoch 52: loss = 0.0003, val_loss = 0.0027, val_accuracy = 1.0000\n",
      "Epoch 53: loss = 0.0002, val_loss = 0.0157, val_accuracy = 0.9916\n",
      "Epoch 54: loss = 0.0016, val_loss = 0.0053, val_accuracy = 0.9979\n",
      "Epoch 55: loss = 0.0007, val_loss = 0.0045, val_accuracy = 1.0000\n",
      "Epoch 56: loss = 0.0077, val_loss = 0.0132, val_accuracy = 0.9958\n",
      "Epoch 57: loss = 0.0129, val_loss = 0.0098, val_accuracy = 0.9979\n",
      "Epoch 58: loss = 0.0016, val_loss = 0.0041, val_accuracy = 1.0000\n",
      "Epoch 59: loss = 0.0005, val_loss = 0.0035, val_accuracy = 1.0000\n",
      "Epoch 60: loss = 0.0045, val_loss = 0.0103, val_accuracy = 0.9958\n",
      "Epoch 61: loss = 0.0004, val_loss = 0.0033, val_accuracy = 0.9979\n",
      "Epoch 62: loss = 0.0004, val_loss = 0.0126, val_accuracy = 0.9958\n",
      "Epoch 63: loss = 0.0005, val_loss = 0.0076, val_accuracy = 0.9958\n",
      "Epoch 64: loss = 0.0009, val_loss = 0.0046, val_accuracy = 1.0000\n",
      "Epoch 65: loss = 0.0012, val_loss = 0.0068, val_accuracy = 0.9979\n",
      "Epoch 66: loss = 0.0014, val_loss = 0.0058, val_accuracy = 0.9979\n",
      "Epoch 67: loss = 0.0001, val_loss = 0.0028, val_accuracy = 1.0000\n",
      "Epoch 68: loss = 0.0007, val_loss = 0.0096, val_accuracy = 0.9958\n",
      "Epoch 69: loss = 0.0020, val_loss = 0.0148, val_accuracy = 0.9916\n",
      "Epoch 70: loss = 0.0003, val_loss = 0.0018, val_accuracy = 1.0000\n",
      "Epoch 71: loss = 0.0001, val_loss = 0.0014, val_accuracy = 1.0000\n",
      "Epoch 72: loss = 0.0004, val_loss = 0.0031, val_accuracy = 0.9979\n",
      "Epoch 73: loss = 0.0001, val_loss = 0.0012, val_accuracy = 1.0000\n",
      "Epoch 74: loss = 0.0003, val_loss = 0.0079, val_accuracy = 0.9958\n",
      "Epoch 75: loss = 0.0002, val_loss = 0.0109, val_accuracy = 0.9958\n",
      "Epoch 76: loss = 0.0000, val_loss = 0.0011, val_accuracy = 1.0000\n",
      "Epoch 77: loss = 0.0001, val_loss = 0.0050, val_accuracy = 0.9979\n",
      "Epoch 78: loss = 0.0001, val_loss = 0.0028, val_accuracy = 0.9979\n",
      "Epoch 79: loss = 0.0002, val_loss = 0.0055, val_accuracy = 0.9979\n",
      "Epoch 80: loss = 0.0001, val_loss = 0.0059, val_accuracy = 0.9979\n",
      "Epoch 81: loss = 0.0001, val_loss = 0.0022, val_accuracy = 1.0000\n",
      "Epoch 82: loss = 0.0006, val_loss = 0.0031, val_accuracy = 1.0000\n",
      "Epoch 83: loss = 0.0003, val_loss = 0.0025, val_accuracy = 1.0000\n",
      "Epoch 84: loss = 0.0003, val_loss = 0.0030, val_accuracy = 0.9979\n",
      "Epoch 85: loss = 0.0006, val_loss = 0.0052, val_accuracy = 0.9979\n",
      "Epoch 86: loss = 0.0022, val_loss = 0.0057, val_accuracy = 0.9979\n",
      "Epoch 87: loss = 0.0007, val_loss = 0.0039, val_accuracy = 0.9979\n",
      "Epoch 88: loss = 0.0018, val_loss = 0.0020, val_accuracy = 1.0000\n",
      "Epoch 89: loss = 0.0012, val_loss = 0.0024, val_accuracy = 1.0000\n",
      "Epoch 90: loss = 0.0004, val_loss = 0.0013, val_accuracy = 1.0000\n",
      "Epoch 91: loss = 0.0003, val_loss = 0.0023, val_accuracy = 1.0000\n",
      "Epoch 92: loss = 0.0002, val_loss = 0.0017, val_accuracy = 1.0000\n",
      "Epoch 93: loss = 0.0001, val_loss = 0.0016, val_accuracy = 1.0000\n",
      "Epoch 94: loss = 0.0001, val_loss = 0.0010, val_accuracy = 1.0000\n",
      "Epoch 95: loss = 0.0001, val_loss = 0.0012, val_accuracy = 1.0000\n",
      "Epoch 96: loss = 0.0001, val_loss = 0.0011, val_accuracy = 1.0000\n",
      "Epoch 97: loss = 0.0001, val_loss = 0.0013, val_accuracy = 1.0000\n",
      "Epoch 98: loss = 0.0000, val_loss = 0.0006, val_accuracy = 1.0000\n",
      "Epoch 99: loss = 0.0001, val_loss = 0.0009, val_accuracy = 1.0000\n",
      "Epoch 100: loss = 0.0001, val_loss = 0.0008, val_accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_C = train(modelC, dataset_C, num_epochs=100, batch_size=4, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.5196, val_loss = 0.4557, val_accuracy = 0.8859\n",
      "Epoch 2: loss = 0.2758, val_loss = 0.1008, val_accuracy = 0.9701\n",
      "Epoch 3: loss = 0.0770, val_loss = 0.0842, val_accuracy = 0.9728\n",
      "Epoch 4: loss = 0.0131, val_loss = 0.0895, val_accuracy = 0.9647\n",
      "Epoch 5: loss = 0.0144, val_loss = 0.0528, val_accuracy = 0.9810\n",
      "Epoch 6: loss = 0.0185, val_loss = 0.0590, val_accuracy = 0.9755\n",
      "Epoch 7: loss = 0.0105, val_loss = 0.0525, val_accuracy = 0.9755\n",
      "Epoch 8: loss = 0.0015, val_loss = 0.0478, val_accuracy = 0.9837\n",
      "Epoch 9: loss = 0.0311, val_loss = 0.1143, val_accuracy = 0.9620\n",
      "Epoch 10: loss = 0.0158, val_loss = 0.0586, val_accuracy = 0.9810\n",
      "Epoch 11: loss = 0.0306, val_loss = 0.0559, val_accuracy = 0.9837\n",
      "Epoch 12: loss = 0.0243, val_loss = 0.0824, val_accuracy = 0.9755\n",
      "Epoch 13: loss = 0.0198, val_loss = 0.0466, val_accuracy = 0.9918\n",
      "Epoch 14: loss = 0.0018, val_loss = 0.0624, val_accuracy = 0.9837\n",
      "Epoch 15: loss = 0.0063, val_loss = 0.0484, val_accuracy = 0.9837\n",
      "Epoch 16: loss = 0.0169, val_loss = 0.0399, val_accuracy = 0.9864\n",
      "Epoch 17: loss = 0.0581, val_loss = 0.0337, val_accuracy = 0.9864\n",
      "Epoch 18: loss = 0.0136, val_loss = 0.0387, val_accuracy = 0.9837\n",
      "Epoch 19: loss = 0.0403, val_loss = 0.0501, val_accuracy = 0.9837\n",
      "Epoch 20: loss = 0.0126, val_loss = 0.0251, val_accuracy = 0.9864\n",
      "Epoch 21: loss = 0.1043, val_loss = 0.0605, val_accuracy = 0.9864\n",
      "Epoch 22: loss = 0.0154, val_loss = 0.0458, val_accuracy = 0.9783\n",
      "Epoch 23: loss = 0.0138, val_loss = 0.0338, val_accuracy = 0.9783\n",
      "Epoch 24: loss = 0.0324, val_loss = 0.0359, val_accuracy = 0.9837\n",
      "Epoch 25: loss = 0.0404, val_loss = 0.0345, val_accuracy = 0.9837\n",
      "Epoch 26: loss = 0.0066, val_loss = 0.0432, val_accuracy = 0.9837\n",
      "Epoch 27: loss = 0.0455, val_loss = 0.0299, val_accuracy = 0.9946\n",
      "Epoch 28: loss = 0.0390, val_loss = 0.0334, val_accuracy = 0.9891\n",
      "Epoch 29: loss = 0.0135, val_loss = 0.0250, val_accuracy = 0.9918\n",
      "Epoch 30: loss = 0.0068, val_loss = 0.0216, val_accuracy = 0.9891\n",
      "Epoch 31: loss = 0.0177, val_loss = 0.0250, val_accuracy = 0.9891\n",
      "Epoch 32: loss = 0.0238, val_loss = 0.0200, val_accuracy = 0.9918\n",
      "Epoch 33: loss = 0.0134, val_loss = 0.0374, val_accuracy = 0.9891\n",
      "Epoch 34: loss = 0.0233, val_loss = 0.0340, val_accuracy = 0.9810\n",
      "Epoch 35: loss = 0.0537, val_loss = 0.0270, val_accuracy = 0.9918\n",
      "Epoch 36: loss = 0.0194, val_loss = 0.0246, val_accuracy = 0.9918\n",
      "Epoch 37: loss = 0.0262, val_loss = 0.0245, val_accuracy = 0.9837\n",
      "Epoch 38: loss = 0.0217, val_loss = 0.0250, val_accuracy = 0.9918\n",
      "Epoch 39: loss = 0.0438, val_loss = 0.0317, val_accuracy = 0.9837\n",
      "Epoch 40: loss = 0.0350, val_loss = 0.0301, val_accuracy = 0.9891\n",
      "Epoch 41: loss = 0.0171, val_loss = 0.0275, val_accuracy = 0.9891\n",
      "Epoch 42: loss = 0.0115, val_loss = 0.0359, val_accuracy = 0.9837\n",
      "Epoch 43: loss = 0.0204, val_loss = 0.0180, val_accuracy = 0.9918\n",
      "Epoch 44: loss = 0.0054, val_loss = 0.0183, val_accuracy = 0.9918\n",
      "Epoch 45: loss = 0.0211, val_loss = 0.0195, val_accuracy = 0.9946\n",
      "Epoch 46: loss = 0.0177, val_loss = 0.0130, val_accuracy = 0.9946\n",
      "Epoch 47: loss = 0.0041, val_loss = 0.0077, val_accuracy = 1.0000\n",
      "Epoch 48: loss = 0.0009, val_loss = 0.0220, val_accuracy = 0.9864\n",
      "Epoch 49: loss = 0.0972, val_loss = 0.0577, val_accuracy = 0.9810\n",
      "Epoch 50: loss = 0.0339, val_loss = 0.0151, val_accuracy = 0.9918\n",
      "Epoch 51: loss = 0.0143, val_loss = 0.0135, val_accuracy = 0.9973\n",
      "Epoch 52: loss = 0.0173, val_loss = 0.0114, val_accuracy = 0.9973\n",
      "Epoch 53: loss = 0.0058, val_loss = 0.0076, val_accuracy = 1.0000\n",
      "Epoch 54: loss = 0.0082, val_loss = 0.0109, val_accuracy = 0.9973\n",
      "Epoch 55: loss = 0.0047, val_loss = 0.0096, val_accuracy = 0.9973\n",
      "Epoch 56: loss = 0.0030, val_loss = 0.0057, val_accuracy = 1.0000\n",
      "Epoch 57: loss = 0.0073, val_loss = 0.0075, val_accuracy = 1.0000\n",
      "Epoch 58: loss = 0.0027, val_loss = 0.0050, val_accuracy = 1.0000\n",
      "Epoch 59: loss = 0.0024, val_loss = 0.0042, val_accuracy = 1.0000\n",
      "Epoch 60: loss = 0.0056, val_loss = 0.0059, val_accuracy = 0.9973\n",
      "Epoch 61: loss = 0.0025, val_loss = 0.0047, val_accuracy = 1.0000\n",
      "Epoch 62: loss = 0.0051, val_loss = 0.0081, val_accuracy = 1.0000\n",
      "Epoch 63: loss = 0.0017, val_loss = 0.0047, val_accuracy = 1.0000\n",
      "Epoch 64: loss = 0.0017, val_loss = 0.0049, val_accuracy = 1.0000\n",
      "Epoch 65: loss = 0.0011, val_loss = 0.0060, val_accuracy = 1.0000\n",
      "Epoch 66: loss = 0.0006, val_loss = 0.0053, val_accuracy = 1.0000\n",
      "Epoch 67: loss = 0.0004, val_loss = 0.0031, val_accuracy = 1.0000\n",
      "Epoch 68: loss = 0.0019, val_loss = 0.0071, val_accuracy = 0.9973\n",
      "Epoch 69: loss = 0.0016, val_loss = 0.0059, val_accuracy = 1.0000\n",
      "Epoch 70: loss = 0.0008, val_loss = 0.0048, val_accuracy = 1.0000\n",
      "Epoch 71: loss = 0.0028, val_loss = 0.0070, val_accuracy = 1.0000\n",
      "Epoch 72: loss = 0.0018, val_loss = 0.0061, val_accuracy = 0.9973\n",
      "Epoch 73: loss = 0.0024, val_loss = 0.0081, val_accuracy = 0.9946\n",
      "Epoch 74: loss = 0.0011, val_loss = 0.0079, val_accuracy = 0.9946\n",
      "Epoch 75: loss = 0.0012, val_loss = 0.0053, val_accuracy = 0.9973\n",
      "Epoch 76: loss = 0.0006, val_loss = 0.0037, val_accuracy = 1.0000\n",
      "Epoch 77: loss = 0.0010, val_loss = 0.0036, val_accuracy = 1.0000\n",
      "Epoch 78: loss = 0.0009, val_loss = 0.0035, val_accuracy = 1.0000\n",
      "Epoch 79: loss = 0.0003, val_loss = 0.0035, val_accuracy = 1.0000\n",
      "Epoch 80: loss = 0.0001, val_loss = 0.0046, val_accuracy = 0.9973\n",
      "Epoch 81: loss = 0.0002, val_loss = 0.0031, val_accuracy = 1.0000\n",
      "Epoch 82: loss = 0.0001, val_loss = 0.0023, val_accuracy = 1.0000\n",
      "Epoch 83: loss = 0.0002, val_loss = 0.0025, val_accuracy = 1.0000\n",
      "Epoch 84: loss = 0.0001, val_loss = 0.0025, val_accuracy = 1.0000\n",
      "Epoch 85: loss = 0.0007, val_loss = 0.0062, val_accuracy = 0.9973\n",
      "Epoch 86: loss = 0.0004, val_loss = 0.0066, val_accuracy = 0.9946\n",
      "Epoch 87: loss = 0.0001, val_loss = 0.0033, val_accuracy = 1.0000\n",
      "Epoch 88: loss = 0.0006, val_loss = 0.0085, val_accuracy = 0.9973\n",
      "Epoch 89: loss = 0.0003, val_loss = 0.0033, val_accuracy = 1.0000\n",
      "Epoch 90: loss = 0.0010, val_loss = 0.0041, val_accuracy = 1.0000\n",
      "Epoch 91: loss = 0.0008, val_loss = 0.0030, val_accuracy = 1.0000\n",
      "Epoch 92: loss = 0.0005, val_loss = 0.0030, val_accuracy = 1.0000\n",
      "Epoch 93: loss = 0.0005, val_loss = 0.0029, val_accuracy = 1.0000\n",
      "Epoch 94: loss = 0.0016, val_loss = 0.0047, val_accuracy = 1.0000\n",
      "Epoch 95: loss = 0.0008, val_loss = 0.0034, val_accuracy = 1.0000\n",
      "Epoch 96: loss = 0.0009, val_loss = 0.0033, val_accuracy = 1.0000\n",
      "Epoch 97: loss = 0.0020, val_loss = 0.0067, val_accuracy = 0.9973\n",
      "Epoch 98: loss = 0.0008, val_loss = 0.0028, val_accuracy = 1.0000\n",
      "Epoch 99: loss = 0.0015, val_loss = 0.0047, val_accuracy = 0.9973\n",
      "Epoch 100: loss = 0.0020, val_loss = 0.0044, val_accuracy = 1.0000\n",
      "Epoch 101: loss = 0.0018, val_loss = 0.0047, val_accuracy = 1.0000\n",
      "Epoch 102: loss = 0.0027, val_loss = 0.0052, val_accuracy = 1.0000\n",
      "Epoch 103: loss = 0.0018, val_loss = 0.0041, val_accuracy = 1.0000\n",
      "Epoch 104: loss = 0.0008, val_loss = 0.0032, val_accuracy = 1.0000\n",
      "Epoch 105: loss = 0.0009, val_loss = 0.0033, val_accuracy = 1.0000\n",
      "Epoch 106: loss = 0.0013, val_loss = 0.0043, val_accuracy = 1.0000\n",
      "Epoch 107: loss = 0.0007, val_loss = 0.0033, val_accuracy = 1.0000\n",
      "Epoch 108: loss = 0.0003, val_loss = 0.0034, val_accuracy = 0.9973\n",
      "Epoch 109: loss = 0.0008, val_loss = 0.0039, val_accuracy = 1.0000\n",
      "Epoch 110: loss = 0.0007, val_loss = 0.0040, val_accuracy = 1.0000\n",
      "Epoch 111: loss = 0.0003, val_loss = 0.0029, val_accuracy = 1.0000\n",
      "Epoch 112: loss = 0.0002, val_loss = 0.0028, val_accuracy = 1.0000\n",
      "Epoch 113: loss = 0.0006, val_loss = 0.0038, val_accuracy = 1.0000\n",
      "Epoch 114: loss = 0.0004, val_loss = 0.0032, val_accuracy = 1.0000\n",
      "Epoch 115: loss = 0.0002, val_loss = 0.0028, val_accuracy = 1.0000\n",
      "Epoch 116: loss = 0.0001, val_loss = 0.0028, val_accuracy = 1.0000\n",
      "Epoch 117: loss = 0.0001, val_loss = 0.0031, val_accuracy = 0.9973\n",
      "Epoch 118: loss = 0.0001, val_loss = 0.0038, val_accuracy = 0.9973\n",
      "Epoch 119: loss = 0.0001, val_loss = 0.0031, val_accuracy = 0.9973\n",
      "Epoch 120: loss = 0.0004, val_loss = 0.0044, val_accuracy = 1.0000\n",
      "Epoch 121: loss = 0.0003, val_loss = 0.0032, val_accuracy = 1.0000\n",
      "Epoch 122: loss = 0.0009, val_loss = 0.0052, val_accuracy = 0.9973\n",
      "Epoch 123: loss = 0.0004, val_loss = 0.0037, val_accuracy = 1.0000\n",
      "Epoch 124: loss = 0.0005, val_loss = 0.0039, val_accuracy = 1.0000\n",
      "Epoch 125: loss = 0.0006, val_loss = 0.0039, val_accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_BC = train(modelBC, dataset_BC, num_epochs=125, batch_size=4, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = one_hot_test.to(device)\n",
    "\n",
    "pred_A = torch.softmax(model_A(X_test), axis=1)[:,1].detach().cpu().numpy()\n",
    "pred_B = torch.softmax(model_B(X_test), axis=1)[:,1].detach().cpu().numpy()\n",
    "pred_C = torch.softmax(model_C(X_test), axis=1)[:,1].detach().cpu().numpy()\n",
    "pred_BC = torch.softmax(model_BC(X_test), axis=1)[:,1].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>BC_prob</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TEST_170</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TEST_171</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>TEST_172</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>TEST_173</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>TEST_174</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class  A_prob  B_prob  C_prob  BC_prob total\n",
       "0    TEST_000     A  1.0000  0.0000  0.0000   1.0000     A\n",
       "1    TEST_001     B  0.0000  1.0000  0.0000   0.0000     B\n",
       "2    TEST_002     C  0.0001  0.0000  1.0000   1.0000     C\n",
       "3    TEST_003     C  0.0000  0.7512  0.9843   0.0129     C\n",
       "4    TEST_004     A  1.0000  0.0000  0.0000   1.0000     A\n",
       "..        ...   ...     ...     ...     ...      ...   ...\n",
       "170  TEST_170     B  0.0000  1.0000  0.0000   0.0000     B\n",
       "171  TEST_171     C  0.0000  0.0000  1.0000   1.0000     C\n",
       "172  TEST_172     C  0.0000  0.0000  1.0000   1.0000     C\n",
       "173  TEST_173     B  0.0000  1.0000  0.0000   0.0000     B\n",
       "174  TEST_174     B  0.0000  1.0000  0.0000   0.0000     B\n",
       "\n",
       "[175 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(\"submit_high1.csv\")\n",
    "submit['A_prob'] = np.round(pred_A, 4)\n",
    "submit['B_prob'] = np.round(pred_B, 4)\n",
    "submit['C_prob'] = np.round(pred_C, 4)\n",
    "submit['BC_prob'] = np.round(pred_BC, 4)\n",
    "# submit['class'] = submit['class'].map(lambda x : 'A' if x==0 else ('B' if x==1 else 'C'))\n",
    "submit['total'] = np.argmax(submit[['A_prob', 'B_prob', 'C_prob']].values, axis=1)\n",
    "submit['total'] = submit['total'].map(lambda x : 'A' if x==0 else ('B' if x==1 else 'C'))\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>BC_prob</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST_005</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST_012</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>TEST_127</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>TEST_162</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class  A_prob  B_prob  C_prob  BC_prob total\n",
       "5    TEST_005     C     0.0  1.0000  0.0000   0.0000     B\n",
       "12   TEST_012     B     0.0  0.0000  0.4513   0.0001     C\n",
       "127  TEST_127     B     0.0  0.0000  0.0000   0.0000     A\n",
       "162  TEST_162     C     0.0  0.9983  0.0000   1.0000     B"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[submit['class'] != submit.total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>BC_prob</th>\n",
       "      <th>total</th>\n",
       "      <th>total2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TEST_005</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>TEST_103</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>TEST_126</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class  A_prob  B_prob  C_prob  BC_prob total total2\n",
       "3    TEST_003     C  0.0000  0.7512  0.9843   0.0129     C      B\n",
       "5    TEST_005     C  0.0000  1.0000  0.0000   0.0000     B      B\n",
       "103  TEST_103     C  0.0000  0.0000  1.0000   0.0000     C      B\n",
       "126  TEST_126     B  0.0001  0.9493  0.0000   1.0000     B      C"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['total2'] = 1\n",
    "submit.loc[submit.BC_prob >= 0.6, 'total2'] = 2\n",
    "submit.loc[submit.A_prob >= 0.5, 'total2'] = 0\n",
    "submit['total2'] = submit['total2'].map(lambda x : 'A' if x==0 else ('B' if x==1 else 'C'))\n",
    "submit[submit['class'] != submit.total2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    84\n",
       "A    52\n",
       "C    39\n",
       "Name: total, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['total'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>BC_prob</th>\n",
       "      <th>total</th>\n",
       "      <th>total2</th>\n",
       "      <th>last1</th>\n",
       "      <th>last2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>TEST_127</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class  A_prob  B_prob  C_prob  BC_prob total total2 last1 last2\n",
       "127  TEST_127     B     0.0     0.0     0.0      0.0     A      B     C     B"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['last1'] = pd.read_csv(\"submit_last1.csv\")['class']\n",
    "submit['last2'] = pd.read_csv(\"submit_last2.csv\")['class']\n",
    "\n",
    "submit[submit.total != submit.last2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       175 non-null    object \n",
      " 1   class    175 non-null    object \n",
      " 2   A_prob   175 non-null    float32\n",
      " 3   B_prob   175 non-null    float32\n",
      " 4   C_prob   175 non-null    float32\n",
      " 5   BC_prob  175 non-null    float32\n",
      " 6   total    175 non-null    object \n",
      " 7   total2   175 non-null    object \n",
      " 8   last1    175 non-null    object \n",
      " 9   last2    175 non-null    object \n",
      "dtypes: float32(4), object(6)\n",
      "memory usage: 11.1+ KB\n"
     ]
    }
   ],
   "source": [
    "submit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TEST_170</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TEST_171</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>TEST_172</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>TEST_173</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>TEST_174</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class\n",
       "0    TEST_000     A\n",
       "1    TEST_001     B\n",
       "2    TEST_002     C\n",
       "3    TEST_003     C\n",
       "4    TEST_004     A\n",
       "..        ...   ...\n",
       "170  TEST_170     B\n",
       "171  TEST_171     C\n",
       "172  TEST_172     C\n",
       "173  TEST_173     B\n",
       "174  TEST_174     B\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"submit_high1.csv\")\n",
    "df['class'] = submit['total']\n",
    "df.to_csv(\"submit_last011.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    84\n",
       "A    52\n",
       "C    39\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>TEST_170</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>TEST_171</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>TEST_172</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>TEST_173</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>TEST_174</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class\n",
       "0    TEST_000     A\n",
       "1    TEST_001     B\n",
       "2    TEST_002     C\n",
       "3    TEST_003     B\n",
       "4    TEST_004     A\n",
       "..        ...   ...\n",
       "170  TEST_170     B\n",
       "171  TEST_171     C\n",
       "172  TEST_172     C\n",
       "173  TEST_173     B\n",
       "174  TEST_174     B\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"submit_high1.csv\")\n",
    "df['class'] = submit['total2']\n",
    "df.to_csv(\"submit_last022.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    86\n",
       "A    51\n",
       "C    38\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
